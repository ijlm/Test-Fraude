2023-11-05 11:15:27,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-05 11:15:27,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-05 11:15:27,222:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-05 11:15:27,222:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-05 11:17:15,644:INFO:PyCaret ClassificationExperiment
2023-11-05 11:17:15,645:INFO:Logging name: clf-default-name
2023-11-05 11:17:15,645:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-05 11:17:15,645:INFO:version 3.1.0
2023-11-05 11:17:15,645:INFO:Initializing setup()
2023-11-05 11:17:15,645:INFO:self.USI: f55e
2023-11-05 11:17:15,645:INFO:self._variable_keys: {'target_param', 'fold_generator', 'y_test', 'html_param', 'X', 'USI', 'data', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'n_jobs_param', 'seed', 'memory', 'exp_id', 'fix_imbalance', 'y', 'X_train', 'is_multiclass', 'logging_param', 'fold_shuffle_param', 'idx', 'exp_name_log', 'y_train', 'fold_groups_param', 'gpu_param', '_available_plots', 'pipeline', 'X_test'}
2023-11-05 11:17:15,645:INFO:Checking environment
2023-11-05 11:17:15,645:INFO:python_version: 3.9.18
2023-11-05 11:17:15,645:INFO:python_build: ('main', 'Sep 11 2023 14:09:26')
2023-11-05 11:17:15,645:INFO:machine: AMD64
2023-11-05 11:17:15,645:INFO:platform: Windows-10-10.0.19041-SP0
2023-11-05 11:17:15,645:INFO:Memory: svmem(total=25692647424, available=16567799808, percent=35.5, used=9124847616, free=16567799808)
2023-11-05 11:17:15,645:INFO:Physical Core: 8
2023-11-05 11:17:15,645:INFO:Logical Core: 16
2023-11-05 11:17:15,646:INFO:Checking libraries
2023-11-05 11:17:15,646:INFO:System:
2023-11-05 11:17:15,646:INFO:    python: 3.9.18 (main, Sep 11 2023, 14:09:26) [MSC v.1916 64 bit (AMD64)]
2023-11-05 11:17:15,646:INFO:executable: d:\programas\Anaconda3\envs\meli_test2\python.exe
2023-11-05 11:17:15,646:INFO:   machine: Windows-10-10.0.19041-SP0
2023-11-05 11:17:15,646:INFO:PyCaret required dependencies:
2023-11-05 11:17:15,671:INFO:                 pip: 23.3
2023-11-05 11:17:15,671:INFO:          setuptools: 68.0.0
2023-11-05 11:17:15,671:INFO:             pycaret: 3.1.0
2023-11-05 11:17:15,671:INFO:             IPython: 8.17.2
2023-11-05 11:17:15,671:INFO:          ipywidgets: 8.1.1
2023-11-05 11:17:15,671:INFO:                tqdm: 4.66.1
2023-11-05 11:17:15,672:INFO:               numpy: 1.23.5
2023-11-05 11:17:15,672:INFO:              pandas: 1.5.3
2023-11-05 11:17:15,672:INFO:              jinja2: 3.1.2
2023-11-05 11:17:15,672:INFO:               scipy: 1.10.1
2023-11-05 11:17:15,672:INFO:              joblib: 1.3.2
2023-11-05 11:17:15,672:INFO:             sklearn: 1.2.2
2023-11-05 11:17:15,672:INFO:                pyod: 1.1.1
2023-11-05 11:17:15,672:INFO:            imblearn: 0.11.0
2023-11-05 11:17:15,672:INFO:   category_encoders: 2.6.3
2023-11-05 11:17:15,672:INFO:            lightgbm: 4.1.0
2023-11-05 11:17:15,672:INFO:               numba: 0.58.1
2023-11-05 11:17:15,672:INFO:            requests: 2.31.0
2023-11-05 11:17:15,672:INFO:          matplotlib: 3.8.1
2023-11-05 11:17:15,672:INFO:          scikitplot: 0.3.7
2023-11-05 11:17:15,672:INFO:         yellowbrick: 1.5
2023-11-05 11:17:15,672:INFO:              plotly: 5.18.0
2023-11-05 11:17:15,672:INFO:    plotly-resampler: Not installed
2023-11-05 11:17:15,672:INFO:             kaleido: 0.2.1
2023-11-05 11:17:15,672:INFO:           schemdraw: 0.15
2023-11-05 11:17:15,672:INFO:         statsmodels: 0.14.0
2023-11-05 11:17:15,672:INFO:              sktime: 0.21.1
2023-11-05 11:17:15,672:INFO:               tbats: 1.1.3
2023-11-05 11:17:15,672:INFO:            pmdarima: 2.0.4
2023-11-05 11:17:15,672:INFO:              psutil: 5.9.6
2023-11-05 11:17:15,673:INFO:          markupsafe: 2.1.3
2023-11-05 11:17:15,673:INFO:             pickle5: Not installed
2023-11-05 11:17:15,673:INFO:         cloudpickle: 3.0.0
2023-11-05 11:17:15,673:INFO:         deprecation: 2.1.0
2023-11-05 11:17:15,673:INFO:              xxhash: 3.4.1
2023-11-05 11:17:15,673:INFO:           wurlitzer: Not installed
2023-11-05 11:17:15,673:INFO:PyCaret optional dependencies:
2023-11-05 11:17:15,742:INFO:                shap: Not installed
2023-11-05 11:17:15,742:INFO:           interpret: Not installed
2023-11-05 11:17:15,742:INFO:                umap: Not installed
2023-11-05 11:17:15,742:INFO:     ydata_profiling: Not installed
2023-11-05 11:17:15,742:INFO:  explainerdashboard: Not installed
2023-11-05 11:17:15,742:INFO:             autoviz: Not installed
2023-11-05 11:17:15,742:INFO:           fairlearn: Not installed
2023-11-05 11:17:15,742:INFO:          deepchecks: Not installed
2023-11-05 11:17:15,742:INFO:             xgboost: 2.0.1
2023-11-05 11:17:15,742:INFO:            catboost: Not installed
2023-11-05 11:17:15,742:INFO:              kmodes: Not installed
2023-11-05 11:17:15,742:INFO:             mlxtend: Not installed
2023-11-05 11:17:15,743:INFO:       statsforecast: Not installed
2023-11-05 11:17:15,743:INFO:        tune_sklearn: Not installed
2023-11-05 11:17:15,743:INFO:                 ray: Not installed
2023-11-05 11:17:15,743:INFO:            hyperopt: Not installed
2023-11-05 11:17:15,743:INFO:              optuna: Not installed
2023-11-05 11:17:15,743:INFO:               skopt: Not installed
2023-11-05 11:17:15,743:INFO:              mlflow: Not installed
2023-11-05 11:17:15,743:INFO:              gradio: Not installed
2023-11-05 11:17:15,743:INFO:             fastapi: Not installed
2023-11-05 11:17:15,743:INFO:             uvicorn: Not installed
2023-11-05 11:17:15,743:INFO:              m2cgen: Not installed
2023-11-05 11:17:15,743:INFO:           evidently: Not installed
2023-11-05 11:17:15,743:INFO:               fugue: Not installed
2023-11-05 11:17:15,743:INFO:           streamlit: Not installed
2023-11-05 11:17:15,743:INFO:             prophet: Not installed
2023-11-05 11:17:15,743:INFO:None
2023-11-05 11:17:15,743:INFO:Set up data.
2023-11-05 11:17:31,375:INFO:PyCaret ClassificationExperiment
2023-11-05 11:17:31,375:INFO:Logging name: clf-default-name
2023-11-05 11:17:31,375:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-05 11:17:31,375:INFO:version 3.1.0
2023-11-05 11:17:31,375:INFO:Initializing setup()
2023-11-05 11:17:31,375:INFO:self.USI: bfe7
2023-11-05 11:17:31,375:INFO:self._variable_keys: {'target_param', 'fold_generator', 'y_test', 'html_param', 'X', 'USI', 'data', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'n_jobs_param', 'seed', 'memory', 'exp_id', 'fix_imbalance', 'y', 'X_train', 'is_multiclass', 'logging_param', 'fold_shuffle_param', 'idx', 'exp_name_log', 'y_train', 'fold_groups_param', 'gpu_param', '_available_plots', 'pipeline', 'X_test'}
2023-11-05 11:17:31,375:INFO:Checking environment
2023-11-05 11:17:31,375:INFO:python_version: 3.9.18
2023-11-05 11:17:31,375:INFO:python_build: ('main', 'Sep 11 2023 14:09:26')
2023-11-05 11:17:31,375:INFO:machine: AMD64
2023-11-05 11:17:31,376:INFO:platform: Windows-10-10.0.19041-SP0
2023-11-05 11:17:31,376:INFO:Memory: svmem(total=25692647424, available=16446713856, percent=36.0, used=9245933568, free=16446713856)
2023-11-05 11:17:31,376:INFO:Physical Core: 8
2023-11-05 11:17:31,376:INFO:Logical Core: 16
2023-11-05 11:17:31,376:INFO:Checking libraries
2023-11-05 11:17:31,376:INFO:System:
2023-11-05 11:17:31,376:INFO:    python: 3.9.18 (main, Sep 11 2023, 14:09:26) [MSC v.1916 64 bit (AMD64)]
2023-11-05 11:17:31,376:INFO:executable: d:\programas\Anaconda3\envs\meli_test2\python.exe
2023-11-05 11:17:31,376:INFO:   machine: Windows-10-10.0.19041-SP0
2023-11-05 11:17:31,376:INFO:PyCaret required dependencies:
2023-11-05 11:17:31,376:INFO:                 pip: 23.3
2023-11-05 11:17:31,376:INFO:          setuptools: 68.0.0
2023-11-05 11:17:31,376:INFO:             pycaret: 3.1.0
2023-11-05 11:17:31,376:INFO:             IPython: 8.17.2
2023-11-05 11:17:31,376:INFO:          ipywidgets: 8.1.1
2023-11-05 11:17:31,376:INFO:                tqdm: 4.66.1
2023-11-05 11:17:31,376:INFO:               numpy: 1.23.5
2023-11-05 11:17:31,376:INFO:              pandas: 1.5.3
2023-11-05 11:17:31,376:INFO:              jinja2: 3.1.2
2023-11-05 11:17:31,376:INFO:               scipy: 1.10.1
2023-11-05 11:17:31,377:INFO:              joblib: 1.3.2
2023-11-05 11:17:31,377:INFO:             sklearn: 1.2.2
2023-11-05 11:17:31,377:INFO:                pyod: 1.1.1
2023-11-05 11:17:31,377:INFO:            imblearn: 0.11.0
2023-11-05 11:17:31,377:INFO:   category_encoders: 2.6.3
2023-11-05 11:17:31,377:INFO:            lightgbm: 4.1.0
2023-11-05 11:17:31,377:INFO:               numba: 0.58.1
2023-11-05 11:17:31,377:INFO:            requests: 2.31.0
2023-11-05 11:17:31,377:INFO:          matplotlib: 3.8.1
2023-11-05 11:17:31,377:INFO:          scikitplot: 0.3.7
2023-11-05 11:17:31,377:INFO:         yellowbrick: 1.5
2023-11-05 11:17:31,377:INFO:              plotly: 5.18.0
2023-11-05 11:17:31,377:INFO:    plotly-resampler: Not installed
2023-11-05 11:17:31,377:INFO:             kaleido: 0.2.1
2023-11-05 11:17:31,377:INFO:           schemdraw: 0.15
2023-11-05 11:17:31,377:INFO:         statsmodels: 0.14.0
2023-11-05 11:17:31,377:INFO:              sktime: 0.21.1
2023-11-05 11:17:31,377:INFO:               tbats: 1.1.3
2023-11-05 11:17:31,377:INFO:            pmdarima: 2.0.4
2023-11-05 11:17:31,377:INFO:              psutil: 5.9.6
2023-11-05 11:17:31,377:INFO:          markupsafe: 2.1.3
2023-11-05 11:17:31,378:INFO:             pickle5: Not installed
2023-11-05 11:17:31,378:INFO:         cloudpickle: 3.0.0
2023-11-05 11:17:31,378:INFO:         deprecation: 2.1.0
2023-11-05 11:17:31,378:INFO:              xxhash: 3.4.1
2023-11-05 11:17:31,378:INFO:           wurlitzer: Not installed
2023-11-05 11:17:31,378:INFO:PyCaret optional dependencies:
2023-11-05 11:17:31,378:INFO:                shap: Not installed
2023-11-05 11:17:31,378:INFO:           interpret: Not installed
2023-11-05 11:17:31,378:INFO:                umap: Not installed
2023-11-05 11:17:31,378:INFO:     ydata_profiling: Not installed
2023-11-05 11:17:31,378:INFO:  explainerdashboard: Not installed
2023-11-05 11:17:31,378:INFO:             autoviz: Not installed
2023-11-05 11:17:31,378:INFO:           fairlearn: Not installed
2023-11-05 11:17:31,378:INFO:          deepchecks: Not installed
2023-11-05 11:17:31,378:INFO:             xgboost: 2.0.1
2023-11-05 11:17:31,378:INFO:            catboost: Not installed
2023-11-05 11:17:31,378:INFO:              kmodes: Not installed
2023-11-05 11:17:31,378:INFO:             mlxtend: Not installed
2023-11-05 11:17:31,378:INFO:       statsforecast: Not installed
2023-11-05 11:17:31,378:INFO:        tune_sklearn: Not installed
2023-11-05 11:17:31,378:INFO:                 ray: Not installed
2023-11-05 11:17:31,378:INFO:            hyperopt: Not installed
2023-11-05 11:17:31,378:INFO:              optuna: Not installed
2023-11-05 11:17:31,379:INFO:               skopt: Not installed
2023-11-05 11:17:31,379:INFO:              mlflow: Not installed
2023-11-05 11:17:31,379:INFO:              gradio: Not installed
2023-11-05 11:17:31,379:INFO:             fastapi: Not installed
2023-11-05 11:17:31,379:INFO:             uvicorn: Not installed
2023-11-05 11:17:31,379:INFO:              m2cgen: Not installed
2023-11-05 11:17:31,379:INFO:           evidently: Not installed
2023-11-05 11:17:31,379:INFO:               fugue: Not installed
2023-11-05 11:17:31,379:INFO:           streamlit: Not installed
2023-11-05 11:17:31,379:INFO:             prophet: Not installed
2023-11-05 11:17:31,379:INFO:None
2023-11-05 11:17:31,379:INFO:Set up data.
2023-11-05 11:17:31,427:INFO:Set up folding strategy.
2023-11-05 11:17:31,427:INFO:Set up train/test split.
2023-11-05 11:17:31,490:INFO:Set up index.
2023-11-05 11:17:31,494:INFO:Assigning column types.
2023-11-05 11:17:31,521:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-05 11:17:31,573:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-05 11:17:31,575:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 11:17:31,611:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:17:31,614:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:17:31,666:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-05 11:17:31,667:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 11:17:31,699:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:17:31,702:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:17:31,702:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-05 11:17:31,757:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 11:17:31,790:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:17:31,793:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:17:31,848:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 11:17:31,883:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:17:31,886:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:17:31,886:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-05 11:17:31,976:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:17:31,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:17:32,068:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:17:32,071:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:17:32,074:INFO:Preparing preprocessing pipeline...
2023-11-05 11:17:32,080:INFO:Set up simple imputation.
2023-11-05 11:17:32,161:INFO:Finished creating preprocessing pipeline.
2023-11-05 11:17:32,166:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['a', 'b', 'c', 'd', 'e', 'f', 'h',
                                             'k', 'l', 'm', 'n', 'p', 'monto',
                                             'score', 'Country_AR',
                                             'Country_BR', 'Country_US',
                                             'Country_UY', 'Country_otros'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-05 11:17:32,166:INFO:Creating final display dataframe.
2023-11-05 11:17:32,386:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            fraude
2                   Target type            Binary
3           Original data shape      (147013, 20)
4        Transformed data shape      (147013, 20)
5   Transformed train set shape      (102909, 20)
6    Transformed test set shape       (44104, 20)
7              Numeric features                19
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              bfe7
2023-11-05 11:17:32,485:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:17:32,488:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:17:32,578:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:17:32,581:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:17:32,582:INFO:setup() successfully completed in 1.21s...............
2023-11-05 11:18:08,044:INFO:Initializing compare_models()
2023-11-05 11:18:08,044:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD179250>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD179250>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-11-05 11:18:08,044:INFO:Checking exceptions
2023-11-05 11:18:08,068:INFO:Preparing display monitor
2023-11-05 11:18:08,091:INFO:Initializing Logistic Regression
2023-11-05 11:18:08,091:INFO:Total runtime is 0.0 minutes
2023-11-05 11:18:08,095:INFO:SubProcess create_model() called ==================================
2023-11-05 11:18:08,095:INFO:Initializing create_model()
2023-11-05 11:18:08,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD179250>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266BFDF9460>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:18:08,095:INFO:Checking exceptions
2023-11-05 11:18:08,096:INFO:Importing libraries
2023-11-05 11:18:08,096:INFO:Copying training dataset
2023-11-05 11:18:08,136:INFO:Defining folds
2023-11-05 11:18:08,136:INFO:Declaring metric variables
2023-11-05 11:18:08,139:INFO:Importing untrained model
2023-11-05 11:18:08,143:INFO:Logistic Regression Imported successfully
2023-11-05 11:18:08,149:INFO:Starting cross validation
2023-11-05 11:18:08,150:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:18:13,766:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:18:14,319:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:18:14,460:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:18:14,537:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:18:14,587:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:18:16,205:INFO:Calculating mean and std
2023-11-05 11:18:16,207:INFO:Creating metrics dataframe
2023-11-05 11:18:16,211:INFO:Uploading results into container
2023-11-05 11:18:16,212:INFO:Uploading model into container now
2023-11-05 11:18:16,213:INFO:_master_model_container: 1
2023-11-05 11:18:16,213:INFO:_display_container: 2
2023-11-05 11:18:16,213:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-05 11:18:16,213:INFO:create_model() successfully completed......................................
2023-11-05 11:18:16,291:INFO:SubProcess create_model() end ==================================
2023-11-05 11:18:16,291:INFO:Creating metrics dataframe
2023-11-05 11:18:16,299:INFO:Initializing K Neighbors Classifier
2023-11-05 11:18:16,300:INFO:Total runtime is 0.1368100682894389 minutes
2023-11-05 11:18:16,303:INFO:SubProcess create_model() called ==================================
2023-11-05 11:18:16,303:INFO:Initializing create_model()
2023-11-05 11:18:16,303:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD179250>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266BFDF9460>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:18:16,303:INFO:Checking exceptions
2023-11-05 11:18:16,303:INFO:Importing libraries
2023-11-05 11:18:16,304:INFO:Copying training dataset
2023-11-05 11:18:16,338:INFO:Defining folds
2023-11-05 11:18:16,338:INFO:Declaring metric variables
2023-11-05 11:18:16,341:INFO:Importing untrained model
2023-11-05 11:18:16,345:INFO:K Neighbors Classifier Imported successfully
2023-11-05 11:18:16,351:INFO:Starting cross validation
2023-11-05 11:18:16,352:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:18:27,155:INFO:Initializing compare_models()
2023-11-05 11:18:27,155:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD179250>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD179250>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-11-05 11:18:27,155:INFO:Checking exceptions
2023-11-05 11:18:27,169:INFO:Preparing display monitor
2023-11-05 11:18:27,192:INFO:Initializing Logistic Regression
2023-11-05 11:18:27,193:INFO:Total runtime is 1.666545867919922e-05 minutes
2023-11-05 11:18:27,196:INFO:SubProcess create_model() called ==================================
2023-11-05 11:18:27,197:INFO:Initializing create_model()
2023-11-05 11:18:27,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD179250>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CD1793A0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:18:27,197:INFO:Checking exceptions
2023-11-05 11:18:27,197:INFO:Importing libraries
2023-11-05 11:18:27,198:INFO:Copying training dataset
2023-11-05 11:18:27,235:INFO:Defining folds
2023-11-05 11:18:27,235:INFO:Declaring metric variables
2023-11-05 11:18:27,238:INFO:Importing untrained model
2023-11-05 11:18:27,242:INFO:Logistic Regression Imported successfully
2023-11-05 11:18:27,248:INFO:Starting cross validation
2023-11-05 11:18:27,249:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:18:32,593:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:18:33,112:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:18:33,193:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:18:33,371:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:18:33,461:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:18:34,830:INFO:Calculating mean and std
2023-11-05 11:18:34,831:INFO:Creating metrics dataframe
2023-11-05 11:18:34,835:INFO:Uploading results into container
2023-11-05 11:18:34,835:INFO:Uploading model into container now
2023-11-05 11:18:34,836:INFO:_master_model_container: 2
2023-11-05 11:18:34,836:INFO:_display_container: 2
2023-11-05 11:18:34,836:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-05 11:18:34,836:INFO:create_model() successfully completed......................................
2023-11-05 11:18:34,929:INFO:SubProcess create_model() end ==================================
2023-11-05 11:18:34,929:INFO:Creating metrics dataframe
2023-11-05 11:18:34,937:INFO:Initializing K Neighbors Classifier
2023-11-05 11:18:34,938:INFO:Total runtime is 0.12909475564956666 minutes
2023-11-05 11:18:34,941:INFO:SubProcess create_model() called ==================================
2023-11-05 11:18:34,941:INFO:Initializing create_model()
2023-11-05 11:18:34,941:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD179250>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CD1793A0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:18:34,941:INFO:Checking exceptions
2023-11-05 11:18:34,941:INFO:Importing libraries
2023-11-05 11:18:34,941:INFO:Copying training dataset
2023-11-05 11:18:34,975:INFO:Defining folds
2023-11-05 11:18:34,976:INFO:Declaring metric variables
2023-11-05 11:18:34,979:INFO:Importing untrained model
2023-11-05 11:18:34,982:INFO:K Neighbors Classifier Imported successfully
2023-11-05 11:18:34,988:INFO:Starting cross validation
2023-11-05 11:18:34,989:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:18:53,699:INFO:Calculating mean and std
2023-11-05 11:18:53,700:INFO:Creating metrics dataframe
2023-11-05 11:18:53,705:INFO:Uploading results into container
2023-11-05 11:18:53,706:INFO:Uploading model into container now
2023-11-05 11:18:53,706:INFO:_master_model_container: 3
2023-11-05 11:18:53,706:INFO:_display_container: 2
2023-11-05 11:18:53,707:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-05 11:18:53,707:INFO:create_model() successfully completed......................................
2023-11-05 11:18:53,800:INFO:SubProcess create_model() end ==================================
2023-11-05 11:18:53,800:INFO:Creating metrics dataframe
2023-11-05 11:18:53,809:INFO:Initializing Naive Bayes
2023-11-05 11:18:53,809:INFO:Total runtime is 0.4436183412869772 minutes
2023-11-05 11:18:53,812:INFO:SubProcess create_model() called ==================================
2023-11-05 11:18:53,812:INFO:Initializing create_model()
2023-11-05 11:18:53,812:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD179250>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CD1793A0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:18:53,813:INFO:Checking exceptions
2023-11-05 11:18:53,813:INFO:Importing libraries
2023-11-05 11:18:53,813:INFO:Copying training dataset
2023-11-05 11:18:53,848:INFO:Defining folds
2023-11-05 11:18:53,848:INFO:Declaring metric variables
2023-11-05 11:18:53,851:INFO:Importing untrained model
2023-11-05 11:18:53,854:INFO:Naive Bayes Imported successfully
2023-11-05 11:18:53,860:INFO:Starting cross validation
2023-11-05 11:18:53,861:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:18:54,367:INFO:Calculating mean and std
2023-11-05 11:18:54,368:INFO:Creating metrics dataframe
2023-11-05 11:18:54,372:INFO:Uploading results into container
2023-11-05 11:18:54,372:INFO:Uploading model into container now
2023-11-05 11:18:54,373:INFO:_master_model_container: 4
2023-11-05 11:18:54,373:INFO:_display_container: 2
2023-11-05 11:18:54,373:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-05 11:18:54,373:INFO:create_model() successfully completed......................................
2023-11-05 11:18:54,461:INFO:SubProcess create_model() end ==================================
2023-11-05 11:18:54,461:INFO:Creating metrics dataframe
2023-11-05 11:18:54,470:INFO:Initializing Decision Tree Classifier
2023-11-05 11:18:54,470:INFO:Total runtime is 0.4546280503273011 minutes
2023-11-05 11:18:54,474:INFO:SubProcess create_model() called ==================================
2023-11-05 11:18:54,474:INFO:Initializing create_model()
2023-11-05 11:18:54,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD179250>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CD1793A0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:18:54,474:INFO:Checking exceptions
2023-11-05 11:18:54,475:INFO:Importing libraries
2023-11-05 11:18:54,475:INFO:Copying training dataset
2023-11-05 11:18:54,514:INFO:Defining folds
2023-11-05 11:18:54,514:INFO:Declaring metric variables
2023-11-05 11:18:54,519:INFO:Importing untrained model
2023-11-05 11:18:54,522:INFO:Decision Tree Classifier Imported successfully
2023-11-05 11:18:54,529:INFO:Starting cross validation
2023-11-05 11:18:54,530:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:18:56,928:INFO:Calculating mean and std
2023-11-05 11:18:56,930:INFO:Creating metrics dataframe
2023-11-05 11:18:56,933:INFO:Uploading results into container
2023-11-05 11:18:56,934:INFO:Uploading model into container now
2023-11-05 11:18:56,934:INFO:_master_model_container: 5
2023-11-05 11:18:56,934:INFO:_display_container: 2
2023-11-05 11:18:56,935:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-11-05 11:18:56,935:INFO:create_model() successfully completed......................................
2023-11-05 11:18:57,027:INFO:SubProcess create_model() end ==================================
2023-11-05 11:18:57,027:INFO:Creating metrics dataframe
2023-11-05 11:18:57,038:INFO:Initializing SVM - Linear Kernel
2023-11-05 11:18:57,038:INFO:Total runtime is 0.49742813507715866 minutes
2023-11-05 11:18:57,041:INFO:SubProcess create_model() called ==================================
2023-11-05 11:18:57,041:INFO:Initializing create_model()
2023-11-05 11:18:57,041:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD179250>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CD1793A0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:18:57,041:INFO:Checking exceptions
2023-11-05 11:18:57,042:INFO:Importing libraries
2023-11-05 11:18:57,042:INFO:Copying training dataset
2023-11-05 11:18:57,080:INFO:Defining folds
2023-11-05 11:18:57,080:INFO:Declaring metric variables
2023-11-05 11:18:57,083:INFO:Importing untrained model
2023-11-05 11:18:57,087:INFO:SVM - Linear Kernel Imported successfully
2023-11-05 11:18:57,093:INFO:Starting cross validation
2023-11-05 11:18:57,094:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:18:58,501:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:18:59,117:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:18:59,397:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:18:59,591:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:18:59,653:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:18:59,681:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:18:59,685:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:18:59,923:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:19:00,073:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:19:00,188:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:19:00,317:INFO:Calculating mean and std
2023-11-05 11:19:00,318:INFO:Creating metrics dataframe
2023-11-05 11:19:00,321:INFO:Uploading results into container
2023-11-05 11:19:00,322:INFO:Uploading model into container now
2023-11-05 11:19:00,322:INFO:_master_model_container: 6
2023-11-05 11:19:00,322:INFO:_display_container: 2
2023-11-05 11:19:00,323:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-05 11:19:00,323:INFO:create_model() successfully completed......................................
2023-11-05 11:19:00,414:INFO:SubProcess create_model() end ==================================
2023-11-05 11:19:00,414:INFO:Creating metrics dataframe
2023-11-05 11:19:00,424:INFO:Initializing Ridge Classifier
2023-11-05 11:19:00,424:INFO:Total runtime is 0.5538656910260519 minutes
2023-11-05 11:19:00,427:INFO:SubProcess create_model() called ==================================
2023-11-05 11:19:00,427:INFO:Initializing create_model()
2023-11-05 11:19:00,428:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD179250>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CD1793A0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:19:00,428:INFO:Checking exceptions
2023-11-05 11:19:00,428:INFO:Importing libraries
2023-11-05 11:19:00,428:INFO:Copying training dataset
2023-11-05 11:19:00,466:INFO:Defining folds
2023-11-05 11:19:00,467:INFO:Declaring metric variables
2023-11-05 11:19:00,470:INFO:Importing untrained model
2023-11-05 11:19:00,473:INFO:Ridge Classifier Imported successfully
2023-11-05 11:19:00,479:INFO:Starting cross validation
2023-11-05 11:19:00,479:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:19:00,638:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.63433e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:19:00,664:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:19:00,676:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:19:00,683:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.66232e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:19:00,704:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:19:00,715:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:19:00,719:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.62991e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:19:00,720:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.64749e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:19:00,743:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:19:00,745:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:19:00,752:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.65659e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:19:00,753:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.64771e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:19:00,756:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:19:00,772:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:19:00,772:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:19:00,777:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.65243e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:19:00,780:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:19:00,783:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:19:00,791:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:19:00,792:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.58453e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:19:00,803:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:19:00,812:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.59697e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:19:00,823:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:19:00,826:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.67615e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:19:00,831:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:19:00,836:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:19:00,843:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:19:00,969:INFO:Calculating mean and std
2023-11-05 11:19:00,971:INFO:Creating metrics dataframe
2023-11-05 11:19:00,975:INFO:Uploading results into container
2023-11-05 11:19:00,976:INFO:Uploading model into container now
2023-11-05 11:19:00,976:INFO:_master_model_container: 7
2023-11-05 11:19:00,977:INFO:_display_container: 2
2023-11-05 11:19:00,977:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-11-05 11:19:00,977:INFO:create_model() successfully completed......................................
2023-11-05 11:19:01,067:INFO:SubProcess create_model() end ==================================
2023-11-05 11:19:01,068:INFO:Creating metrics dataframe
2023-11-05 11:19:01,078:INFO:Initializing Random Forest Classifier
2023-11-05 11:19:01,078:INFO:Total runtime is 0.5647656718889873 minutes
2023-11-05 11:19:01,081:INFO:SubProcess create_model() called ==================================
2023-11-05 11:19:01,081:INFO:Initializing create_model()
2023-11-05 11:19:01,081:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD179250>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CD1793A0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:19:01,081:INFO:Checking exceptions
2023-11-05 11:19:01,081:INFO:Importing libraries
2023-11-05 11:19:01,081:INFO:Copying training dataset
2023-11-05 11:19:01,116:INFO:Defining folds
2023-11-05 11:19:01,116:INFO:Declaring metric variables
2023-11-05 11:19:01,120:INFO:Importing untrained model
2023-11-05 11:19:01,123:INFO:Random Forest Classifier Imported successfully
2023-11-05 11:19:01,129:INFO:Starting cross validation
2023-11-05 11:19:01,130:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:19:30,819:INFO:Calculating mean and std
2023-11-05 11:19:30,821:INFO:Creating metrics dataframe
2023-11-05 11:19:30,825:INFO:Uploading results into container
2023-11-05 11:19:30,826:INFO:Uploading model into container now
2023-11-05 11:19:30,826:INFO:_master_model_container: 8
2023-11-05 11:19:30,826:INFO:_display_container: 2
2023-11-05 11:19:30,827:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-11-05 11:19:30,827:INFO:create_model() successfully completed......................................
2023-11-05 11:19:30,918:INFO:SubProcess create_model() end ==================================
2023-11-05 11:19:30,919:INFO:Creating metrics dataframe
2023-11-05 11:19:30,929:INFO:Initializing Quadratic Discriminant Analysis
2023-11-05 11:19:30,929:INFO:Total runtime is 1.0622823635737102 minutes
2023-11-05 11:19:30,933:INFO:SubProcess create_model() called ==================================
2023-11-05 11:19:30,933:INFO:Initializing create_model()
2023-11-05 11:19:30,933:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD179250>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CD1793A0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:19:30,933:INFO:Checking exceptions
2023-11-05 11:19:30,933:INFO:Importing libraries
2023-11-05 11:19:30,934:INFO:Copying training dataset
2023-11-05 11:19:30,969:INFO:Defining folds
2023-11-05 11:19:30,969:INFO:Declaring metric variables
2023-11-05 11:19:30,973:INFO:Importing untrained model
2023-11-05 11:19:30,976:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-05 11:19:30,982:INFO:Starting cross validation
2023-11-05 11:19:30,983:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:19:31,424:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:19:31,483:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:19:31,608:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:19:31,644:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:19:31,688:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:19:31,767:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:19:31,805:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:19:31,809:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:19:31,828:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:19:31,841:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:19:32,005:INFO:Calculating mean and std
2023-11-05 11:19:32,006:INFO:Creating metrics dataframe
2023-11-05 11:19:32,010:INFO:Uploading results into container
2023-11-05 11:19:32,010:INFO:Uploading model into container now
2023-11-05 11:19:32,011:INFO:_master_model_container: 9
2023-11-05 11:19:32,011:INFO:_display_container: 2
2023-11-05 11:19:32,011:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-05 11:19:32,011:INFO:create_model() successfully completed......................................
2023-11-05 11:19:32,106:INFO:SubProcess create_model() end ==================================
2023-11-05 11:19:32,106:INFO:Creating metrics dataframe
2023-11-05 11:19:32,119:INFO:Initializing Ada Boost Classifier
2023-11-05 11:19:32,119:INFO:Total runtime is 1.0821157137552897 minutes
2023-11-05 11:19:32,122:INFO:SubProcess create_model() called ==================================
2023-11-05 11:19:32,123:INFO:Initializing create_model()
2023-11-05 11:19:32,123:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD179250>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CD1793A0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:19:32,123:INFO:Checking exceptions
2023-11-05 11:19:32,123:INFO:Importing libraries
2023-11-05 11:19:32,123:INFO:Copying training dataset
2023-11-05 11:19:32,157:INFO:Defining folds
2023-11-05 11:19:32,158:INFO:Declaring metric variables
2023-11-05 11:19:32,162:INFO:Importing untrained model
2023-11-05 11:19:32,165:INFO:Ada Boost Classifier Imported successfully
2023-11-05 11:19:32,171:INFO:Starting cross validation
2023-11-05 11:19:32,172:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:19:40,897:INFO:Calculating mean and std
2023-11-05 11:19:40,898:INFO:Creating metrics dataframe
2023-11-05 11:19:40,902:INFO:Uploading results into container
2023-11-05 11:19:40,902:INFO:Uploading model into container now
2023-11-05 11:19:40,902:INFO:_master_model_container: 10
2023-11-05 11:19:40,903:INFO:_display_container: 2
2023-11-05 11:19:40,903:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-11-05 11:19:40,903:INFO:create_model() successfully completed......................................
2023-11-05 11:19:40,991:INFO:SubProcess create_model() end ==================================
2023-11-05 11:19:40,992:INFO:Creating metrics dataframe
2023-11-05 11:19:41,002:INFO:Initializing Gradient Boosting Classifier
2023-11-05 11:19:41,003:INFO:Total runtime is 1.2301809708277385 minutes
2023-11-05 11:19:41,006:INFO:SubProcess create_model() called ==================================
2023-11-05 11:19:41,006:INFO:Initializing create_model()
2023-11-05 11:19:41,006:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD179250>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CD1793A0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:19:41,006:INFO:Checking exceptions
2023-11-05 11:19:41,006:INFO:Importing libraries
2023-11-05 11:19:41,006:INFO:Copying training dataset
2023-11-05 11:19:41,042:INFO:Defining folds
2023-11-05 11:19:41,042:INFO:Declaring metric variables
2023-11-05 11:19:41,047:INFO:Importing untrained model
2023-11-05 11:19:41,050:INFO:Gradient Boosting Classifier Imported successfully
2023-11-05 11:19:41,056:INFO:Starting cross validation
2023-11-05 11:19:41,057:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:20:19,281:INFO:Calculating mean and std
2023-11-05 11:20:19,282:INFO:Creating metrics dataframe
2023-11-05 11:20:19,285:INFO:Uploading results into container
2023-11-05 11:20:19,286:INFO:Uploading model into container now
2023-11-05 11:20:19,286:INFO:_master_model_container: 11
2023-11-05 11:20:19,286:INFO:_display_container: 2
2023-11-05 11:20:19,287:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-11-05 11:20:19,287:INFO:create_model() successfully completed......................................
2023-11-05 11:20:19,376:INFO:SubProcess create_model() end ==================================
2023-11-05 11:20:19,376:INFO:Creating metrics dataframe
2023-11-05 11:20:19,387:INFO:Initializing Linear Discriminant Analysis
2023-11-05 11:20:19,388:INFO:Total runtime is 1.8699159820874534 minutes
2023-11-05 11:20:19,390:INFO:SubProcess create_model() called ==================================
2023-11-05 11:20:19,391:INFO:Initializing create_model()
2023-11-05 11:20:19,391:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD179250>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CD1793A0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:20:19,391:INFO:Checking exceptions
2023-11-05 11:20:19,391:INFO:Importing libraries
2023-11-05 11:20:19,391:INFO:Copying training dataset
2023-11-05 11:20:19,429:INFO:Defining folds
2023-11-05 11:20:19,429:INFO:Declaring metric variables
2023-11-05 11:20:19,432:INFO:Importing untrained model
2023-11-05 11:20:19,436:INFO:Linear Discriminant Analysis Imported successfully
2023-11-05 11:20:19,442:INFO:Starting cross validation
2023-11-05 11:20:19,443:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:20:20,625:INFO:Calculating mean and std
2023-11-05 11:20:20,626:INFO:Creating metrics dataframe
2023-11-05 11:20:20,630:INFO:Uploading results into container
2023-11-05 11:20:20,630:INFO:Uploading model into container now
2023-11-05 11:20:20,631:INFO:_master_model_container: 12
2023-11-05 11:20:20,631:INFO:_display_container: 2
2023-11-05 11:20:20,631:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-05 11:20:20,631:INFO:create_model() successfully completed......................................
2023-11-05 11:20:20,720:INFO:SubProcess create_model() end ==================================
2023-11-05 11:20:20,721:INFO:Creating metrics dataframe
2023-11-05 11:20:20,732:INFO:Initializing Extra Trees Classifier
2023-11-05 11:20:20,732:INFO:Total runtime is 1.892332661151886 minutes
2023-11-05 11:20:20,735:INFO:SubProcess create_model() called ==================================
2023-11-05 11:20:20,736:INFO:Initializing create_model()
2023-11-05 11:20:20,736:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD179250>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CD1793A0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:20:20,736:INFO:Checking exceptions
2023-11-05 11:20:20,736:INFO:Importing libraries
2023-11-05 11:20:20,736:INFO:Copying training dataset
2023-11-05 11:20:20,770:INFO:Defining folds
2023-11-05 11:20:20,770:INFO:Declaring metric variables
2023-11-05 11:20:20,774:INFO:Importing untrained model
2023-11-05 11:20:20,777:INFO:Extra Trees Classifier Imported successfully
2023-11-05 11:20:20,783:INFO:Starting cross validation
2023-11-05 11:20:20,784:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:21:39,336:INFO:PyCaret ClassificationExperiment
2023-11-05 11:21:39,336:INFO:Logging name: clf-default-name
2023-11-05 11:21:39,336:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-05 11:21:39,336:INFO:version 3.1.0
2023-11-05 11:21:39,336:INFO:Initializing setup()
2023-11-05 11:21:39,336:INFO:self.USI: c778
2023-11-05 11:21:39,336:INFO:self._variable_keys: {'target_param', 'fold_generator', 'y_test', 'html_param', 'X', 'USI', 'data', '_ml_usecase', 'gpu_n_jobs_param', 'log_plots_param', 'n_jobs_param', 'seed', 'memory', 'exp_id', 'fix_imbalance', 'y', 'X_train', 'is_multiclass', 'logging_param', 'fold_shuffle_param', 'idx', 'exp_name_log', 'y_train', 'fold_groups_param', 'gpu_param', '_available_plots', 'pipeline', 'X_test'}
2023-11-05 11:21:39,336:INFO:Checking environment
2023-11-05 11:21:39,337:INFO:python_version: 3.9.18
2023-11-05 11:21:39,337:INFO:python_build: ('main', 'Sep 11 2023 14:09:26')
2023-11-05 11:21:39,337:INFO:machine: AMD64
2023-11-05 11:21:39,337:INFO:platform: Windows-10-10.0.19041-SP0
2023-11-05 11:21:39,337:INFO:Memory: svmem(total=25692647424, available=15972257792, percent=37.8, used=9720389632, free=15972257792)
2023-11-05 11:21:39,337:INFO:Physical Core: 8
2023-11-05 11:21:39,337:INFO:Logical Core: 16
2023-11-05 11:21:39,337:INFO:Checking libraries
2023-11-05 11:21:39,337:INFO:System:
2023-11-05 11:21:39,337:INFO:    python: 3.9.18 (main, Sep 11 2023, 14:09:26) [MSC v.1916 64 bit (AMD64)]
2023-11-05 11:21:39,337:INFO:executable: d:\programas\Anaconda3\envs\meli_test2\python.exe
2023-11-05 11:21:39,337:INFO:   machine: Windows-10-10.0.19041-SP0
2023-11-05 11:21:39,337:INFO:PyCaret required dependencies:
2023-11-05 11:21:39,337:INFO:                 pip: 23.3
2023-11-05 11:21:39,337:INFO:          setuptools: 68.0.0
2023-11-05 11:21:39,337:INFO:             pycaret: 3.1.0
2023-11-05 11:21:39,337:INFO:             IPython: 8.17.2
2023-11-05 11:21:39,337:INFO:          ipywidgets: 8.1.1
2023-11-05 11:21:39,337:INFO:                tqdm: 4.66.1
2023-11-05 11:21:39,337:INFO:               numpy: 1.23.5
2023-11-05 11:21:39,338:INFO:              pandas: 1.5.3
2023-11-05 11:21:39,338:INFO:              jinja2: 3.1.2
2023-11-05 11:21:39,338:INFO:               scipy: 1.10.1
2023-11-05 11:21:39,338:INFO:              joblib: 1.3.2
2023-11-05 11:21:39,338:INFO:             sklearn: 1.2.2
2023-11-05 11:21:39,338:INFO:                pyod: 1.1.1
2023-11-05 11:21:39,338:INFO:            imblearn: 0.11.0
2023-11-05 11:21:39,338:INFO:   category_encoders: 2.6.3
2023-11-05 11:21:39,338:INFO:            lightgbm: 4.1.0
2023-11-05 11:21:39,338:INFO:               numba: 0.58.1
2023-11-05 11:21:39,338:INFO:            requests: 2.31.0
2023-11-05 11:21:39,338:INFO:          matplotlib: 3.8.1
2023-11-05 11:21:39,338:INFO:          scikitplot: 0.3.7
2023-11-05 11:21:39,338:INFO:         yellowbrick: 1.5
2023-11-05 11:21:39,338:INFO:              plotly: 5.18.0
2023-11-05 11:21:39,338:INFO:    plotly-resampler: Not installed
2023-11-05 11:21:39,338:INFO:             kaleido: 0.2.1
2023-11-05 11:21:39,338:INFO:           schemdraw: 0.15
2023-11-05 11:21:39,338:INFO:         statsmodels: 0.14.0
2023-11-05 11:21:39,338:INFO:              sktime: 0.21.1
2023-11-05 11:21:39,338:INFO:               tbats: 1.1.3
2023-11-05 11:21:39,338:INFO:            pmdarima: 2.0.4
2023-11-05 11:21:39,338:INFO:              psutil: 5.9.6
2023-11-05 11:21:39,338:INFO:          markupsafe: 2.1.3
2023-11-05 11:21:39,339:INFO:             pickle5: Not installed
2023-11-05 11:21:39,339:INFO:         cloudpickle: 3.0.0
2023-11-05 11:21:39,339:INFO:         deprecation: 2.1.0
2023-11-05 11:21:39,339:INFO:              xxhash: 3.4.1
2023-11-05 11:21:39,339:INFO:           wurlitzer: Not installed
2023-11-05 11:21:39,339:INFO:PyCaret optional dependencies:
2023-11-05 11:21:39,339:INFO:                shap: Not installed
2023-11-05 11:21:39,339:INFO:           interpret: Not installed
2023-11-05 11:21:39,339:INFO:                umap: Not installed
2023-11-05 11:21:39,339:INFO:     ydata_profiling: Not installed
2023-11-05 11:21:39,339:INFO:  explainerdashboard: Not installed
2023-11-05 11:21:39,339:INFO:             autoviz: Not installed
2023-11-05 11:21:39,339:INFO:           fairlearn: Not installed
2023-11-05 11:21:39,339:INFO:          deepchecks: Not installed
2023-11-05 11:21:39,339:INFO:             xgboost: 2.0.1
2023-11-05 11:21:39,339:INFO:            catboost: Not installed
2023-11-05 11:21:39,339:INFO:              kmodes: Not installed
2023-11-05 11:21:39,339:INFO:             mlxtend: Not installed
2023-11-05 11:21:39,339:INFO:       statsforecast: Not installed
2023-11-05 11:21:39,339:INFO:        tune_sklearn: Not installed
2023-11-05 11:21:39,339:INFO:                 ray: Not installed
2023-11-05 11:21:39,339:INFO:            hyperopt: Not installed
2023-11-05 11:21:39,339:INFO:              optuna: Not installed
2023-11-05 11:21:39,340:INFO:               skopt: Not installed
2023-11-05 11:21:39,340:INFO:              mlflow: Not installed
2023-11-05 11:21:39,340:INFO:              gradio: Not installed
2023-11-05 11:21:39,340:INFO:             fastapi: Not installed
2023-11-05 11:21:39,340:INFO:             uvicorn: Not installed
2023-11-05 11:21:39,340:INFO:              m2cgen: Not installed
2023-11-05 11:21:39,340:INFO:           evidently: Not installed
2023-11-05 11:21:39,340:INFO:               fugue: Not installed
2023-11-05 11:21:39,340:INFO:           streamlit: Not installed
2023-11-05 11:21:39,340:INFO:             prophet: Not installed
2023-11-05 11:21:39,340:INFO:None
2023-11-05 11:21:39,340:INFO:Set up data.
2023-11-05 11:21:39,408:INFO:Set up folding strategy.
2023-11-05 11:21:39,408:INFO:Set up train/test split.
2023-11-05 11:21:39,487:INFO:Set up index.
2023-11-05 11:21:39,491:INFO:Assigning column types.
2023-11-05 11:21:39,528:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-05 11:21:39,581:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-05 11:21:39,582:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 11:21:39,616:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:21:39,619:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:21:39,670:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-05 11:21:39,671:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 11:21:39,703:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:21:39,706:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:21:39,707:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-05 11:21:39,759:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 11:21:39,791:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:21:39,794:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:21:39,847:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 11:21:39,878:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:21:39,881:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:21:39,882:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-05 11:21:39,967:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:21:39,970:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:21:40,056:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:21:40,059:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:21:40,060:INFO:Preparing preprocessing pipeline...
2023-11-05 11:21:40,066:INFO:Set up simple imputation.
2023-11-05 11:21:40,156:INFO:Finished creating preprocessing pipeline.
2023-11-05 11:21:40,159:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['a', 'b', 'c', 'd', 'e', 'f', 'h',
                                             'k', 'l', 'm', 'n', 'p', 'monto',
                                             'score', 'Country_AR',
                                             'Country_BR', 'Country_US',
                                             'Country_UY', 'Country_otros'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-05 11:21:40,159:INFO:Creating final display dataframe.
2023-11-05 11:21:40,422:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            fraude
2                   Target type            Binary
3           Original data shape      (181519, 20)
4        Transformed data shape      (181519, 20)
5   Transformed train set shape      (127063, 20)
6    Transformed test set shape       (54456, 20)
7              Numeric features                19
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              c778
2023-11-05 11:21:40,515:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:21:40,518:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:21:40,606:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:21:40,609:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:21:40,610:INFO:setup() successfully completed in 1.28s...............
2023-11-05 11:21:43,258:INFO:Initializing compare_models()
2023-11-05 11:21:43,258:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-11-05 11:21:43,259:INFO:Checking exceptions
2023-11-05 11:21:43,292:INFO:Preparing display monitor
2023-11-05 11:21:43,315:INFO:Initializing Logistic Regression
2023-11-05 11:21:43,315:INFO:Total runtime is 0.0 minutes
2023-11-05 11:21:43,318:INFO:SubProcess create_model() called ==================================
2023-11-05 11:21:43,318:INFO:Initializing create_model()
2023-11-05 11:21:43,318:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1D9DE20>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:21:43,319:INFO:Checking exceptions
2023-11-05 11:21:43,319:INFO:Importing libraries
2023-11-05 11:21:43,319:INFO:Copying training dataset
2023-11-05 11:21:43,363:INFO:Defining folds
2023-11-05 11:21:43,363:INFO:Declaring metric variables
2023-11-05 11:21:43,366:INFO:Importing untrained model
2023-11-05 11:21:43,370:INFO:Logistic Regression Imported successfully
2023-11-05 11:21:43,376:INFO:Starting cross validation
2023-11-05 11:21:43,376:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:21:50,726:INFO:Calculating mean and std
2023-11-05 11:21:50,728:INFO:Creating metrics dataframe
2023-11-05 11:21:50,731:INFO:Uploading results into container
2023-11-05 11:21:50,731:INFO:Uploading model into container now
2023-11-05 11:21:50,732:INFO:_master_model_container: 1
2023-11-05 11:21:50,732:INFO:_display_container: 2
2023-11-05 11:21:50,732:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-05 11:21:50,732:INFO:create_model() successfully completed......................................
2023-11-05 11:21:50,834:INFO:SubProcess create_model() end ==================================
2023-11-05 11:21:50,834:INFO:Creating metrics dataframe
2023-11-05 11:21:50,843:INFO:Initializing K Neighbors Classifier
2023-11-05 11:21:50,843:INFO:Total runtime is 0.12546661694844563 minutes
2023-11-05 11:21:50,846:INFO:SubProcess create_model() called ==================================
2023-11-05 11:21:50,846:INFO:Initializing create_model()
2023-11-05 11:21:50,846:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1D9DE20>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:21:50,847:INFO:Checking exceptions
2023-11-05 11:21:50,847:INFO:Importing libraries
2023-11-05 11:21:50,847:INFO:Copying training dataset
2023-11-05 11:21:50,892:INFO:Defining folds
2023-11-05 11:21:50,892:INFO:Declaring metric variables
2023-11-05 11:21:50,895:INFO:Importing untrained model
2023-11-05 11:21:50,898:INFO:K Neighbors Classifier Imported successfully
2023-11-05 11:21:50,904:INFO:Starting cross validation
2023-11-05 11:21:50,905:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:22:18,682:INFO:Calculating mean and std
2023-11-05 11:22:18,684:INFO:Creating metrics dataframe
2023-11-05 11:22:18,687:INFO:Uploading results into container
2023-11-05 11:22:18,687:INFO:Uploading model into container now
2023-11-05 11:22:18,688:INFO:_master_model_container: 2
2023-11-05 11:22:18,688:INFO:_display_container: 2
2023-11-05 11:22:18,688:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-05 11:22:18,688:INFO:create_model() successfully completed......................................
2023-11-05 11:22:18,779:INFO:SubProcess create_model() end ==================================
2023-11-05 11:22:18,779:INFO:Creating metrics dataframe
2023-11-05 11:22:18,788:INFO:Initializing Naive Bayes
2023-11-05 11:22:18,788:INFO:Total runtime is 0.5912170728047689 minutes
2023-11-05 11:22:18,791:INFO:SubProcess create_model() called ==================================
2023-11-05 11:22:18,791:INFO:Initializing create_model()
2023-11-05 11:22:18,791:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1D9DE20>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:22:18,791:INFO:Checking exceptions
2023-11-05 11:22:18,791:INFO:Importing libraries
2023-11-05 11:22:18,792:INFO:Copying training dataset
2023-11-05 11:22:18,836:INFO:Defining folds
2023-11-05 11:22:18,836:INFO:Declaring metric variables
2023-11-05 11:22:18,839:INFO:Importing untrained model
2023-11-05 11:22:18,843:INFO:Naive Bayes Imported successfully
2023-11-05 11:22:18,848:INFO:Starting cross validation
2023-11-05 11:22:18,849:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:22:19,452:INFO:Calculating mean and std
2023-11-05 11:22:19,453:INFO:Creating metrics dataframe
2023-11-05 11:22:19,457:INFO:Uploading results into container
2023-11-05 11:22:19,457:INFO:Uploading model into container now
2023-11-05 11:22:19,458:INFO:_master_model_container: 3
2023-11-05 11:22:19,458:INFO:_display_container: 2
2023-11-05 11:22:19,458:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-05 11:22:19,458:INFO:create_model() successfully completed......................................
2023-11-05 11:22:19,550:INFO:SubProcess create_model() end ==================================
2023-11-05 11:22:19,550:INFO:Creating metrics dataframe
2023-11-05 11:22:19,560:INFO:Initializing Decision Tree Classifier
2023-11-05 11:22:19,561:INFO:Total runtime is 0.6040976524353028 minutes
2023-11-05 11:22:19,564:INFO:SubProcess create_model() called ==================================
2023-11-05 11:22:19,564:INFO:Initializing create_model()
2023-11-05 11:22:19,564:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1D9DE20>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:22:19,564:INFO:Checking exceptions
2023-11-05 11:22:19,564:INFO:Importing libraries
2023-11-05 11:22:19,565:INFO:Copying training dataset
2023-11-05 11:22:19,619:INFO:Defining folds
2023-11-05 11:22:19,620:INFO:Declaring metric variables
2023-11-05 11:22:19,623:INFO:Importing untrained model
2023-11-05 11:22:19,626:INFO:Decision Tree Classifier Imported successfully
2023-11-05 11:22:19,632:INFO:Starting cross validation
2023-11-05 11:22:19,633:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:22:22,433:INFO:Calculating mean and std
2023-11-05 11:22:22,435:INFO:Creating metrics dataframe
2023-11-05 11:22:22,440:INFO:Uploading results into container
2023-11-05 11:22:22,440:INFO:Uploading model into container now
2023-11-05 11:22:22,441:INFO:_master_model_container: 4
2023-11-05 11:22:22,441:INFO:_display_container: 2
2023-11-05 11:22:22,441:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-11-05 11:22:22,441:INFO:create_model() successfully completed......................................
2023-11-05 11:22:22,535:INFO:SubProcess create_model() end ==================================
2023-11-05 11:22:22,535:INFO:Creating metrics dataframe
2023-11-05 11:22:22,545:INFO:Initializing SVM - Linear Kernel
2023-11-05 11:22:22,545:INFO:Total runtime is 0.6538309812545777 minutes
2023-11-05 11:22:22,548:INFO:SubProcess create_model() called ==================================
2023-11-05 11:22:22,548:INFO:Initializing create_model()
2023-11-05 11:22:22,548:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1D9DE20>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:22:22,549:INFO:Checking exceptions
2023-11-05 11:22:22,549:INFO:Importing libraries
2023-11-05 11:22:22,549:INFO:Copying training dataset
2023-11-05 11:22:22,593:INFO:Defining folds
2023-11-05 11:22:22,594:INFO:Declaring metric variables
2023-11-05 11:22:22,598:INFO:Importing untrained model
2023-11-05 11:22:22,601:INFO:SVM - Linear Kernel Imported successfully
2023-11-05 11:22:22,606:INFO:Starting cross validation
2023-11-05 11:22:22,607:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:22:26,453:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:22:26,472:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:22:26,702:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:22:26,708:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:22:26,817:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:22:26,917:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:22:27,238:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:22:27,490:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:22:27,822:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:22:29,219:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:22:29,360:INFO:Calculating mean and std
2023-11-05 11:22:29,361:INFO:Creating metrics dataframe
2023-11-05 11:22:29,364:INFO:Uploading results into container
2023-11-05 11:22:29,365:INFO:Uploading model into container now
2023-11-05 11:22:29,365:INFO:_master_model_container: 5
2023-11-05 11:22:29,365:INFO:_display_container: 2
2023-11-05 11:22:29,366:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-05 11:22:29,366:INFO:create_model() successfully completed......................................
2023-11-05 11:22:29,471:INFO:SubProcess create_model() end ==================================
2023-11-05 11:22:29,472:INFO:Creating metrics dataframe
2023-11-05 11:22:29,482:INFO:Initializing Ridge Classifier
2023-11-05 11:22:29,482:INFO:Total runtime is 0.76944766441981 minutes
2023-11-05 11:22:29,486:INFO:SubProcess create_model() called ==================================
2023-11-05 11:22:29,486:INFO:Initializing create_model()
2023-11-05 11:22:29,486:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1D9DE20>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:22:29,486:INFO:Checking exceptions
2023-11-05 11:22:29,486:INFO:Importing libraries
2023-11-05 11:22:29,486:INFO:Copying training dataset
2023-11-05 11:22:29,541:INFO:Defining folds
2023-11-05 11:22:29,541:INFO:Declaring metric variables
2023-11-05 11:22:29,544:INFO:Importing untrained model
2023-11-05 11:22:29,549:INFO:Ridge Classifier Imported successfully
2023-11-05 11:22:29,555:INFO:Starting cross validation
2023-11-05 11:22:29,556:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:22:29,853:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.13719e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:22:29,888:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.02642e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:22:29,890:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.19282e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:22:29,891:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:22:29,926:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:22:29,932:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.11761e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:22:29,933:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:22:29,946:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.04676e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:22:29,962:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:22:29,970:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.21583e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:22:29,973:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.20541e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:22:29,977:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:22:29,998:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:22:30,000:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:22:30,010:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.16596e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:22:30,017:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.20378e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:22:30,026:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:22:30,027:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.11314e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:22:30,031:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:22:30,038:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:22:30,172:INFO:Calculating mean and std
2023-11-05 11:22:30,173:INFO:Creating metrics dataframe
2023-11-05 11:22:30,176:INFO:Uploading results into container
2023-11-05 11:22:30,177:INFO:Uploading model into container now
2023-11-05 11:22:30,177:INFO:_master_model_container: 6
2023-11-05 11:22:30,177:INFO:_display_container: 2
2023-11-05 11:22:30,178:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-11-05 11:22:30,178:INFO:create_model() successfully completed......................................
2023-11-05 11:22:30,282:INFO:SubProcess create_model() end ==================================
2023-11-05 11:22:30,282:INFO:Creating metrics dataframe
2023-11-05 11:22:30,292:INFO:Initializing Random Forest Classifier
2023-11-05 11:22:30,293:INFO:Total runtime is 0.7829643527666729 minutes
2023-11-05 11:22:30,296:INFO:SubProcess create_model() called ==================================
2023-11-05 11:22:30,297:INFO:Initializing create_model()
2023-11-05 11:22:30,297:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1D9DE20>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:22:30,297:INFO:Checking exceptions
2023-11-05 11:22:30,297:INFO:Importing libraries
2023-11-05 11:22:30,297:INFO:Copying training dataset
2023-11-05 11:22:30,351:INFO:Defining folds
2023-11-05 11:22:30,351:INFO:Declaring metric variables
2023-11-05 11:22:30,354:INFO:Importing untrained model
2023-11-05 11:22:30,358:INFO:Random Forest Classifier Imported successfully
2023-11-05 11:22:30,366:INFO:Starting cross validation
2023-11-05 11:22:30,367:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:23:10,786:INFO:Calculating mean and std
2023-11-05 11:23:10,788:INFO:Creating metrics dataframe
2023-11-05 11:23:10,791:INFO:Uploading results into container
2023-11-05 11:23:10,792:INFO:Uploading model into container now
2023-11-05 11:23:10,792:INFO:_master_model_container: 7
2023-11-05 11:23:10,793:INFO:_display_container: 2
2023-11-05 11:23:10,793:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-11-05 11:23:10,793:INFO:create_model() successfully completed......................................
2023-11-05 11:23:10,915:INFO:SubProcess create_model() end ==================================
2023-11-05 11:23:10,916:INFO:Creating metrics dataframe
2023-11-05 11:23:10,928:INFO:Initializing Quadratic Discriminant Analysis
2023-11-05 11:23:10,928:INFO:Total runtime is 1.4602143287658693 minutes
2023-11-05 11:23:10,931:INFO:SubProcess create_model() called ==================================
2023-11-05 11:23:10,932:INFO:Initializing create_model()
2023-11-05 11:23:10,932:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1D9DE20>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:23:10,932:INFO:Checking exceptions
2023-11-05 11:23:10,932:INFO:Importing libraries
2023-11-05 11:23:10,933:INFO:Copying training dataset
2023-11-05 11:23:10,979:INFO:Defining folds
2023-11-05 11:23:10,979:INFO:Declaring metric variables
2023-11-05 11:23:10,983:INFO:Importing untrained model
2023-11-05 11:23:10,986:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-05 11:23:10,993:INFO:Starting cross validation
2023-11-05 11:23:10,994:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:23:11,585:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:23:11,707:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:23:11,722:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:23:11,789:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:23:11,826:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:23:11,835:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:23:11,911:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:23:11,935:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:23:11,949:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:23:12,000:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:23:12,217:INFO:Calculating mean and std
2023-11-05 11:23:12,219:INFO:Creating metrics dataframe
2023-11-05 11:23:12,222:INFO:Uploading results into container
2023-11-05 11:23:12,223:INFO:Uploading model into container now
2023-11-05 11:23:12,223:INFO:_master_model_container: 8
2023-11-05 11:23:12,223:INFO:_display_container: 2
2023-11-05 11:23:12,224:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-05 11:23:12,224:INFO:create_model() successfully completed......................................
2023-11-05 11:23:12,329:INFO:SubProcess create_model() end ==================================
2023-11-05 11:23:12,329:INFO:Creating metrics dataframe
2023-11-05 11:23:12,340:INFO:Initializing Ada Boost Classifier
2023-11-05 11:23:12,340:INFO:Total runtime is 1.4837476611137392 minutes
2023-11-05 11:23:12,344:INFO:SubProcess create_model() called ==================================
2023-11-05 11:23:12,344:INFO:Initializing create_model()
2023-11-05 11:23:12,344:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1D9DE20>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:23:12,344:INFO:Checking exceptions
2023-11-05 11:23:12,344:INFO:Importing libraries
2023-11-05 11:23:12,345:INFO:Copying training dataset
2023-11-05 11:23:12,387:INFO:Defining folds
2023-11-05 11:23:12,388:INFO:Declaring metric variables
2023-11-05 11:23:12,391:INFO:Importing untrained model
2023-11-05 11:23:12,394:INFO:Ada Boost Classifier Imported successfully
2023-11-05 11:23:12,401:INFO:Starting cross validation
2023-11-05 11:23:12,402:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:23:24,839:INFO:Calculating mean and std
2023-11-05 11:23:24,840:INFO:Creating metrics dataframe
2023-11-05 11:23:24,844:INFO:Uploading results into container
2023-11-05 11:23:24,844:INFO:Uploading model into container now
2023-11-05 11:23:24,844:INFO:_master_model_container: 9
2023-11-05 11:23:24,845:INFO:_display_container: 2
2023-11-05 11:23:24,845:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-11-05 11:23:24,845:INFO:create_model() successfully completed......................................
2023-11-05 11:23:24,952:INFO:SubProcess create_model() end ==================================
2023-11-05 11:23:24,952:INFO:Creating metrics dataframe
2023-11-05 11:23:24,966:INFO:Initializing Gradient Boosting Classifier
2023-11-05 11:23:24,966:INFO:Total runtime is 1.694180993239085 minutes
2023-11-05 11:23:24,969:INFO:SubProcess create_model() called ==================================
2023-11-05 11:23:24,970:INFO:Initializing create_model()
2023-11-05 11:23:24,970:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1D9DE20>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:23:24,970:INFO:Checking exceptions
2023-11-05 11:23:24,970:INFO:Importing libraries
2023-11-05 11:23:24,971:INFO:Copying training dataset
2023-11-05 11:23:25,026:INFO:Defining folds
2023-11-05 11:23:25,026:INFO:Declaring metric variables
2023-11-05 11:23:25,030:INFO:Importing untrained model
2023-11-05 11:23:25,033:INFO:Gradient Boosting Classifier Imported successfully
2023-11-05 11:23:25,040:INFO:Starting cross validation
2023-11-05 11:23:25,041:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:24:18,451:INFO:Calculating mean and std
2023-11-05 11:24:18,453:INFO:Creating metrics dataframe
2023-11-05 11:24:18,456:INFO:Uploading results into container
2023-11-05 11:24:18,457:INFO:Uploading model into container now
2023-11-05 11:24:18,457:INFO:_master_model_container: 10
2023-11-05 11:24:18,457:INFO:_display_container: 2
2023-11-05 11:24:18,458:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-11-05 11:24:18,458:INFO:create_model() successfully completed......................................
2023-11-05 11:24:18,551:INFO:SubProcess create_model() end ==================================
2023-11-05 11:24:18,551:INFO:Creating metrics dataframe
2023-11-05 11:24:18,563:INFO:Initializing Linear Discriminant Analysis
2023-11-05 11:24:18,563:INFO:Total runtime is 2.5874643166859945 minutes
2023-11-05 11:24:18,566:INFO:SubProcess create_model() called ==================================
2023-11-05 11:24:18,567:INFO:Initializing create_model()
2023-11-05 11:24:18,567:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1D9DE20>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:24:18,567:INFO:Checking exceptions
2023-11-05 11:24:18,567:INFO:Importing libraries
2023-11-05 11:24:18,567:INFO:Copying training dataset
2023-11-05 11:24:18,609:INFO:Defining folds
2023-11-05 11:24:18,609:INFO:Declaring metric variables
2023-11-05 11:24:18,613:INFO:Importing untrained model
2023-11-05 11:24:18,616:INFO:Linear Discriminant Analysis Imported successfully
2023-11-05 11:24:18,622:INFO:Starting cross validation
2023-11-05 11:24:18,623:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:24:20,152:INFO:Calculating mean and std
2023-11-05 11:24:20,153:INFO:Creating metrics dataframe
2023-11-05 11:24:20,156:INFO:Uploading results into container
2023-11-05 11:24:20,157:INFO:Uploading model into container now
2023-11-05 11:24:20,157:INFO:_master_model_container: 11
2023-11-05 11:24:20,157:INFO:_display_container: 2
2023-11-05 11:24:20,158:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-05 11:24:20,158:INFO:create_model() successfully completed......................................
2023-11-05 11:24:20,259:INFO:SubProcess create_model() end ==================================
2023-11-05 11:24:20,259:INFO:Creating metrics dataframe
2023-11-05 11:24:20,271:INFO:Initializing Extra Trees Classifier
2023-11-05 11:24:20,271:INFO:Total runtime is 2.615930954615275 minutes
2023-11-05 11:24:20,274:INFO:SubProcess create_model() called ==================================
2023-11-05 11:24:20,274:INFO:Initializing create_model()
2023-11-05 11:24:20,274:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1D9DE20>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:24:20,275:INFO:Checking exceptions
2023-11-05 11:24:20,275:INFO:Importing libraries
2023-11-05 11:24:20,275:INFO:Copying training dataset
2023-11-05 11:24:20,325:INFO:Defining folds
2023-11-05 11:24:20,325:INFO:Declaring metric variables
2023-11-05 11:24:20,329:INFO:Importing untrained model
2023-11-05 11:24:20,333:INFO:Extra Trees Classifier Imported successfully
2023-11-05 11:24:20,339:INFO:Starting cross validation
2023-11-05 11:24:20,340:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:24:44,849:INFO:Calculating mean and std
2023-11-05 11:24:44,850:INFO:Creating metrics dataframe
2023-11-05 11:24:44,854:INFO:Uploading results into container
2023-11-05 11:24:44,855:INFO:Uploading model into container now
2023-11-05 11:24:44,855:INFO:_master_model_container: 12
2023-11-05 11:24:44,855:INFO:_display_container: 2
2023-11-05 11:24:44,856:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-11-05 11:24:44,856:INFO:create_model() successfully completed......................................
2023-11-05 11:24:44,958:INFO:SubProcess create_model() end ==================================
2023-11-05 11:24:44,959:INFO:Creating metrics dataframe
2023-11-05 11:24:44,971:INFO:Initializing Extreme Gradient Boosting
2023-11-05 11:24:44,971:INFO:Total runtime is 3.0275976141293843 minutes
2023-11-05 11:24:44,975:INFO:SubProcess create_model() called ==================================
2023-11-05 11:24:44,975:INFO:Initializing create_model()
2023-11-05 11:24:44,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1D9DE20>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:24:44,975:INFO:Checking exceptions
2023-11-05 11:24:44,975:INFO:Importing libraries
2023-11-05 11:24:44,975:INFO:Copying training dataset
2023-11-05 11:24:45,022:INFO:Defining folds
2023-11-05 11:24:45,022:INFO:Declaring metric variables
2023-11-05 11:24:45,026:INFO:Importing untrained model
2023-11-05 11:24:45,030:INFO:Extreme Gradient Boosting Imported successfully
2023-11-05 11:24:45,036:INFO:Starting cross validation
2023-11-05 11:24:45,037:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:24:48,451:INFO:Calculating mean and std
2023-11-05 11:24:48,452:INFO:Creating metrics dataframe
2023-11-05 11:24:48,456:INFO:Uploading results into container
2023-11-05 11:24:48,456:INFO:Uploading model into container now
2023-11-05 11:24:48,457:INFO:_master_model_container: 13
2023-11-05 11:24:48,457:INFO:_display_container: 2
2023-11-05 11:24:48,458:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2023-11-05 11:24:48,458:INFO:create_model() successfully completed......................................
2023-11-05 11:24:48,550:INFO:SubProcess create_model() end ==================================
2023-11-05 11:24:48,551:INFO:Creating metrics dataframe
2023-11-05 11:24:48,564:INFO:Initializing Light Gradient Boosting Machine
2023-11-05 11:24:48,564:INFO:Total runtime is 3.0874809781710306 minutes
2023-11-05 11:24:48,567:INFO:SubProcess create_model() called ==================================
2023-11-05 11:24:48,568:INFO:Initializing create_model()
2023-11-05 11:24:48,568:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1D9DE20>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:24:48,568:INFO:Checking exceptions
2023-11-05 11:24:48,568:INFO:Importing libraries
2023-11-05 11:24:48,568:INFO:Copying training dataset
2023-11-05 11:24:48,612:INFO:Defining folds
2023-11-05 11:24:48,613:INFO:Declaring metric variables
2023-11-05 11:24:48,616:INFO:Importing untrained model
2023-11-05 11:24:48,620:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-05 11:24:48,627:INFO:Starting cross validation
2023-11-05 11:24:48,628:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:24:53,955:INFO:Calculating mean and std
2023-11-05 11:24:53,957:INFO:Creating metrics dataframe
2023-11-05 11:24:53,960:INFO:Uploading results into container
2023-11-05 11:24:53,961:INFO:Uploading model into container now
2023-11-05 11:24:53,961:INFO:_master_model_container: 14
2023-11-05 11:24:53,961:INFO:_display_container: 2
2023-11-05 11:24:53,962:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 11:24:53,962:INFO:create_model() successfully completed......................................
2023-11-05 11:24:54,059:INFO:SubProcess create_model() end ==================================
2023-11-05 11:24:54,059:INFO:Creating metrics dataframe
2023-11-05 11:24:54,074:INFO:Initializing Dummy Classifier
2023-11-05 11:24:54,074:INFO:Total runtime is 3.179314311345418 minutes
2023-11-05 11:24:54,078:INFO:SubProcess create_model() called ==================================
2023-11-05 11:24:54,079:INFO:Initializing create_model()
2023-11-05 11:24:54,079:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1D9DE20>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:24:54,079:INFO:Checking exceptions
2023-11-05 11:24:54,079:INFO:Importing libraries
2023-11-05 11:24:54,079:INFO:Copying training dataset
2023-11-05 11:24:54,125:INFO:Defining folds
2023-11-05 11:24:54,125:INFO:Declaring metric variables
2023-11-05 11:24:54,129:INFO:Importing untrained model
2023-11-05 11:24:54,132:INFO:Dummy Classifier Imported successfully
2023-11-05 11:24:54,138:INFO:Starting cross validation
2023-11-05 11:24:54,139:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:24:54,323:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:24:54,327:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:24:54,348:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:24:54,350:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:24:54,374:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:24:54,386:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:24:54,391:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:24:54,401:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:24:54,414:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:24:54,424:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:24:54,555:INFO:Calculating mean and std
2023-11-05 11:24:54,557:INFO:Creating metrics dataframe
2023-11-05 11:24:54,561:INFO:Uploading results into container
2023-11-05 11:24:54,562:INFO:Uploading model into container now
2023-11-05 11:24:54,563:INFO:_master_model_container: 15
2023-11-05 11:24:54,563:INFO:_display_container: 2
2023-11-05 11:24:54,563:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-11-05 11:24:54,563:INFO:create_model() successfully completed......................................
2023-11-05 11:24:54,654:INFO:SubProcess create_model() end ==================================
2023-11-05 11:24:54,654:INFO:Creating metrics dataframe
2023-11-05 11:24:54,677:INFO:Initializing create_model()
2023-11-05 11:24:54,677:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:24:54,677:INFO:Checking exceptions
2023-11-05 11:24:54,679:INFO:Importing libraries
2023-11-05 11:24:54,679:INFO:Copying training dataset
2023-11-05 11:24:54,720:INFO:Defining folds
2023-11-05 11:24:54,720:INFO:Declaring metric variables
2023-11-05 11:24:54,721:INFO:Importing untrained model
2023-11-05 11:24:54,721:INFO:Declaring custom model
2023-11-05 11:24:54,721:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-05 11:24:54,722:INFO:Cross validation set to False
2023-11-05 11:24:54,722:INFO:Fitting Model
2023-11-05 11:24:54,888:INFO:[LightGBM] [Info] Number of positive: 29322, number of negative: 97741
2023-11-05 11:24:54,911:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004458 seconds.
2023-11-05 11:24:54,911:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-05 11:24:54,911:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-05 11:24:54,912:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-05 11:24:54,912:INFO:[LightGBM] [Info] Number of data points in the train set: 127063, number of used features: 19
2023-11-05 11:24:54,913:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230767 -> initscore=-1.203983
2023-11-05 11:24:54,913:INFO:[LightGBM] [Info] Start training from score -1.203983
2023-11-05 11:24:55,303:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 11:24:55,303:INFO:create_model() successfully completed......................................
2023-11-05 11:24:55,441:INFO:_master_model_container: 15
2023-11-05 11:24:55,442:INFO:_display_container: 2
2023-11-05 11:24:55,442:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 11:24:55,442:INFO:compare_models() successfully completed......................................
2023-11-05 11:29:37,701:INFO:Initializing compare_models()
2023-11-05 11:29:37,701:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-11-05 11:29:37,701:INFO:Checking exceptions
2023-11-05 11:29:37,720:INFO:Preparing display monitor
2023-11-05 11:29:37,743:INFO:Initializing Logistic Regression
2023-11-05 11:29:37,743:INFO:Total runtime is 0.0 minutes
2023-11-05 11:29:37,748:INFO:SubProcess create_model() called ==================================
2023-11-05 11:29:37,749:INFO:Initializing create_model()
2023-11-05 11:29:37,749:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1F33880>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:29:37,749:INFO:Checking exceptions
2023-11-05 11:29:37,749:INFO:Importing libraries
2023-11-05 11:29:37,750:INFO:Copying training dataset
2023-11-05 11:29:37,819:INFO:Defining folds
2023-11-05 11:29:37,820:INFO:Declaring metric variables
2023-11-05 11:29:37,823:INFO:Importing untrained model
2023-11-05 11:29:37,827:INFO:Logistic Regression Imported successfully
2023-11-05 11:29:37,833:INFO:Starting cross validation
2023-11-05 11:29:37,834:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:29:40,982:INFO:Calculating mean and std
2023-11-05 11:29:40,984:INFO:Creating metrics dataframe
2023-11-05 11:29:40,987:INFO:Uploading results into container
2023-11-05 11:29:40,988:INFO:Uploading model into container now
2023-11-05 11:29:40,988:INFO:_master_model_container: 16
2023-11-05 11:29:40,988:INFO:_display_container: 3
2023-11-05 11:29:40,988:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-05 11:29:40,989:INFO:create_model() successfully completed......................................
2023-11-05 11:29:41,085:INFO:SubProcess create_model() end ==================================
2023-11-05 11:29:41,085:INFO:Creating metrics dataframe
2023-11-05 11:29:41,094:INFO:Initializing K Neighbors Classifier
2023-11-05 11:29:41,094:INFO:Total runtime is 0.05584389368693034 minutes
2023-11-05 11:29:41,097:INFO:SubProcess create_model() called ==================================
2023-11-05 11:29:41,098:INFO:Initializing create_model()
2023-11-05 11:29:41,098:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1F33880>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:29:41,099:INFO:Checking exceptions
2023-11-05 11:29:41,099:INFO:Importing libraries
2023-11-05 11:29:41,099:INFO:Copying training dataset
2023-11-05 11:29:41,139:INFO:Defining folds
2023-11-05 11:29:41,139:INFO:Declaring metric variables
2023-11-05 11:29:41,142:INFO:Importing untrained model
2023-11-05 11:29:41,145:INFO:K Neighbors Classifier Imported successfully
2023-11-05 11:29:41,151:INFO:Starting cross validation
2023-11-05 11:29:41,152:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:30:12,891:INFO:Calculating mean and std
2023-11-05 11:30:12,893:INFO:Creating metrics dataframe
2023-11-05 11:30:12,897:INFO:Uploading results into container
2023-11-05 11:30:12,897:INFO:Uploading model into container now
2023-11-05 11:30:12,898:INFO:_master_model_container: 17
2023-11-05 11:30:12,898:INFO:_display_container: 3
2023-11-05 11:30:12,898:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-05 11:30:12,898:INFO:create_model() successfully completed......................................
2023-11-05 11:30:12,987:INFO:SubProcess create_model() end ==================================
2023-11-05 11:30:12,987:INFO:Creating metrics dataframe
2023-11-05 11:30:12,996:INFO:Initializing Naive Bayes
2023-11-05 11:30:12,996:INFO:Total runtime is 0.5875399390856425 minutes
2023-11-05 11:30:13,000:INFO:SubProcess create_model() called ==================================
2023-11-05 11:30:13,000:INFO:Initializing create_model()
2023-11-05 11:30:13,000:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1F33880>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:30:13,001:INFO:Checking exceptions
2023-11-05 11:30:13,001:INFO:Importing libraries
2023-11-05 11:30:13,001:INFO:Copying training dataset
2023-11-05 11:30:13,042:INFO:Defining folds
2023-11-05 11:30:13,042:INFO:Declaring metric variables
2023-11-05 11:30:13,045:INFO:Importing untrained model
2023-11-05 11:30:13,049:INFO:Naive Bayes Imported successfully
2023-11-05 11:30:13,054:INFO:Starting cross validation
2023-11-05 11:30:13,055:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:30:13,568:INFO:Calculating mean and std
2023-11-05 11:30:13,569:INFO:Creating metrics dataframe
2023-11-05 11:30:13,573:INFO:Uploading results into container
2023-11-05 11:30:13,573:INFO:Uploading model into container now
2023-11-05 11:30:13,573:INFO:_master_model_container: 18
2023-11-05 11:30:13,574:INFO:_display_container: 3
2023-11-05 11:30:13,574:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-05 11:30:13,574:INFO:create_model() successfully completed......................................
2023-11-05 11:30:13,664:INFO:SubProcess create_model() end ==================================
2023-11-05 11:30:13,665:INFO:Creating metrics dataframe
2023-11-05 11:30:13,675:INFO:Initializing Decision Tree Classifier
2023-11-05 11:30:13,675:INFO:Total runtime is 0.5988555312156677 minutes
2023-11-05 11:30:13,678:INFO:SubProcess create_model() called ==================================
2023-11-05 11:30:13,678:INFO:Initializing create_model()
2023-11-05 11:30:13,678:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1F33880>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:30:13,679:INFO:Checking exceptions
2023-11-05 11:30:13,679:INFO:Importing libraries
2023-11-05 11:30:13,679:INFO:Copying training dataset
2023-11-05 11:30:13,718:INFO:Defining folds
2023-11-05 11:30:13,718:INFO:Declaring metric variables
2023-11-05 11:30:13,721:INFO:Importing untrained model
2023-11-05 11:30:13,724:INFO:Decision Tree Classifier Imported successfully
2023-11-05 11:30:13,731:INFO:Starting cross validation
2023-11-05 11:30:13,732:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:30:16,296:INFO:Calculating mean and std
2023-11-05 11:30:16,297:INFO:Creating metrics dataframe
2023-11-05 11:30:16,301:INFO:Uploading results into container
2023-11-05 11:30:16,301:INFO:Uploading model into container now
2023-11-05 11:30:16,302:INFO:_master_model_container: 19
2023-11-05 11:30:16,302:INFO:_display_container: 3
2023-11-05 11:30:16,302:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-11-05 11:30:16,302:INFO:create_model() successfully completed......................................
2023-11-05 11:30:16,391:INFO:SubProcess create_model() end ==================================
2023-11-05 11:30:16,391:INFO:Creating metrics dataframe
2023-11-05 11:30:16,400:INFO:Initializing SVM - Linear Kernel
2023-11-05 11:30:16,400:INFO:Total runtime is 0.6442838589350383 minutes
2023-11-05 11:30:16,403:INFO:SubProcess create_model() called ==================================
2023-11-05 11:30:16,403:INFO:Initializing create_model()
2023-11-05 11:30:16,403:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1F33880>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:30:16,404:INFO:Checking exceptions
2023-11-05 11:30:16,404:INFO:Importing libraries
2023-11-05 11:30:16,404:INFO:Copying training dataset
2023-11-05 11:30:16,444:INFO:Defining folds
2023-11-05 11:30:16,445:INFO:Declaring metric variables
2023-11-05 11:30:16,448:INFO:Importing untrained model
2023-11-05 11:30:16,452:INFO:SVM - Linear Kernel Imported successfully
2023-11-05 11:30:16,457:INFO:Starting cross validation
2023-11-05 11:30:16,458:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:30:20,156:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:30:20,167:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:30:20,353:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:30:20,359:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:30:20,455:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:30:20,576:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:30:20,874:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:30:21,081:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:30:21,312:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:30:22,427:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:30:22,564:INFO:Calculating mean and std
2023-11-05 11:30:22,565:INFO:Creating metrics dataframe
2023-11-05 11:30:22,569:INFO:Uploading results into container
2023-11-05 11:30:22,569:INFO:Uploading model into container now
2023-11-05 11:30:22,570:INFO:_master_model_container: 20
2023-11-05 11:30:22,570:INFO:_display_container: 3
2023-11-05 11:30:22,570:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-05 11:30:22,570:INFO:create_model() successfully completed......................................
2023-11-05 11:30:22,659:INFO:SubProcess create_model() end ==================================
2023-11-05 11:30:22,659:INFO:Creating metrics dataframe
2023-11-05 11:30:22,668:INFO:Initializing Ridge Classifier
2023-11-05 11:30:22,669:INFO:Total runtime is 0.748762305577596 minutes
2023-11-05 11:30:22,671:INFO:SubProcess create_model() called ==================================
2023-11-05 11:30:22,672:INFO:Initializing create_model()
2023-11-05 11:30:22,672:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1F33880>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:30:22,672:INFO:Checking exceptions
2023-11-05 11:30:22,672:INFO:Importing libraries
2023-11-05 11:30:22,672:INFO:Copying training dataset
2023-11-05 11:30:22,712:INFO:Defining folds
2023-11-05 11:30:22,712:INFO:Declaring metric variables
2023-11-05 11:30:22,717:INFO:Importing untrained model
2023-11-05 11:30:22,721:INFO:Ridge Classifier Imported successfully
2023-11-05 11:30:22,726:INFO:Starting cross validation
2023-11-05 11:30:22,727:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:30:23,284:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.02642e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:30:23,290:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.13719e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:30:23,306:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:30:23,316:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:30:23,334:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.11761e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:30:23,336:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.19282e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:30:23,356:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.04676e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

 returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:30:23,361:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:30:23,365:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.20541e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:30:23,375:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:30:23,379:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:30:23,383:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.21583e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:30:23,398:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.16596e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:30:23,402:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:30:23,409:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:30:23,417:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.20378e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:30:23,422:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.11314e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:30:23,427:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:30:23,432:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:30:23,576:INFO:Calculating mean and std
2023-11-05 11:30:23,577:INFO:Creating metrics dataframe
2023-11-05 11:30:23,580:INFO:Uploading results into container
2023-11-05 11:30:23,581:INFO:Uploading model into container now
2023-11-05 11:30:23,581:INFO:_master_model_container: 21
2023-11-05 11:30:23,581:INFO:_display_container: 3
2023-11-05 11:30:23,582:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-11-05 11:30:23,582:INFO:create_model() successfully completed......................................
2023-11-05 11:30:23,670:INFO:SubProcess create_model() end ==================================
2023-11-05 11:30:23,671:INFO:Creating metrics dataframe
2023-11-05 11:30:23,681:INFO:Initializing Random Forest Classifier
2023-11-05 11:30:23,681:INFO:Total runtime is 0.7656315445899964 minutes
2023-11-05 11:30:23,684:INFO:SubProcess create_model() called ==================================
2023-11-05 11:30:23,684:INFO:Initializing create_model()
2023-11-05 11:30:23,684:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1F33880>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:30:23,685:INFO:Checking exceptions
2023-11-05 11:30:23,685:INFO:Importing libraries
2023-11-05 11:30:23,685:INFO:Copying training dataset
2023-11-05 11:30:23,725:INFO:Defining folds
2023-11-05 11:30:23,725:INFO:Declaring metric variables
2023-11-05 11:30:23,728:INFO:Importing untrained model
2023-11-05 11:30:23,731:INFO:Random Forest Classifier Imported successfully
2023-11-05 11:30:23,737:INFO:Starting cross validation
2023-11-05 11:30:23,738:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:31:03,397:INFO:Calculating mean and std
2023-11-05 11:31:03,399:INFO:Creating metrics dataframe
2023-11-05 11:31:03,402:INFO:Uploading results into container
2023-11-05 11:31:03,403:INFO:Uploading model into container now
2023-11-05 11:31:03,403:INFO:_master_model_container: 22
2023-11-05 11:31:03,404:INFO:_display_container: 3
2023-11-05 11:31:03,404:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-11-05 11:31:03,404:INFO:create_model() successfully completed......................................
2023-11-05 11:31:03,516:INFO:SubProcess create_model() end ==================================
2023-11-05 11:31:03,516:INFO:Creating metrics dataframe
2023-11-05 11:31:03,529:INFO:Initializing Quadratic Discriminant Analysis
2023-11-05 11:31:03,529:INFO:Total runtime is 1.429767115910848 minutes
2023-11-05 11:31:03,533:INFO:SubProcess create_model() called ==================================
2023-11-05 11:31:03,533:INFO:Initializing create_model()
2023-11-05 11:31:03,534:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1F33880>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:31:03,534:INFO:Checking exceptions
2023-11-05 11:31:03,534:INFO:Importing libraries
2023-11-05 11:31:03,534:INFO:Copying training dataset
2023-11-05 11:31:03,582:INFO:Defining folds
2023-11-05 11:31:03,582:INFO:Declaring metric variables
2023-11-05 11:31:03,586:INFO:Importing untrained model
2023-11-05 11:31:03,589:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-05 11:31:03,596:INFO:Starting cross validation
2023-11-05 11:31:03,596:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:31:04,026:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:31:04,117:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:31:04,142:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:31:04,223:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:31:04,239:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:31:04,283:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:31:04,359:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:31:04,362:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:31:04,384:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:31:04,422:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:31:04,604:INFO:Calculating mean and std
2023-11-05 11:31:04,605:INFO:Creating metrics dataframe
2023-11-05 11:31:04,609:INFO:Uploading results into container
2023-11-05 11:31:04,609:INFO:Uploading model into container now
2023-11-05 11:31:04,610:INFO:_master_model_container: 23
2023-11-05 11:31:04,610:INFO:_display_container: 3
2023-11-05 11:31:04,610:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-05 11:31:04,610:INFO:create_model() successfully completed......................................
2023-11-05 11:31:04,700:INFO:SubProcess create_model() end ==================================
2023-11-05 11:31:04,700:INFO:Creating metrics dataframe
2023-11-05 11:31:04,711:INFO:Initializing Ada Boost Classifier
2023-11-05 11:31:04,711:INFO:Total runtime is 1.449456254641215 minutes
2023-11-05 11:31:04,714:INFO:SubProcess create_model() called ==================================
2023-11-05 11:31:04,714:INFO:Initializing create_model()
2023-11-05 11:31:04,714:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1F33880>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:31:04,715:INFO:Checking exceptions
2023-11-05 11:31:04,715:INFO:Importing libraries
2023-11-05 11:31:04,715:INFO:Copying training dataset
2023-11-05 11:31:04,755:INFO:Defining folds
2023-11-05 11:31:04,755:INFO:Declaring metric variables
2023-11-05 11:31:04,758:INFO:Importing untrained model
2023-11-05 11:31:04,761:INFO:Ada Boost Classifier Imported successfully
2023-11-05 11:31:04,767:INFO:Starting cross validation
2023-11-05 11:31:04,768:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:31:17,273:INFO:Calculating mean and std
2023-11-05 11:31:17,274:INFO:Creating metrics dataframe
2023-11-05 11:31:17,278:INFO:Uploading results into container
2023-11-05 11:31:17,278:INFO:Uploading model into container now
2023-11-05 11:31:17,279:INFO:_master_model_container: 24
2023-11-05 11:31:17,279:INFO:_display_container: 3
2023-11-05 11:31:17,279:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-11-05 11:31:17,279:INFO:create_model() successfully completed......................................
2023-11-05 11:31:17,371:INFO:SubProcess create_model() end ==================================
2023-11-05 11:31:17,371:INFO:Creating metrics dataframe
2023-11-05 11:31:17,382:INFO:Initializing Gradient Boosting Classifier
2023-11-05 11:31:17,382:INFO:Total runtime is 1.660642413298289 minutes
2023-11-05 11:31:17,386:INFO:SubProcess create_model() called ==================================
2023-11-05 11:31:17,386:INFO:Initializing create_model()
2023-11-05 11:31:17,386:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1F33880>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:31:17,386:INFO:Checking exceptions
2023-11-05 11:31:17,386:INFO:Importing libraries
2023-11-05 11:31:17,387:INFO:Copying training dataset
2023-11-05 11:31:17,425:INFO:Defining folds
2023-11-05 11:31:17,425:INFO:Declaring metric variables
2023-11-05 11:31:17,429:INFO:Importing untrained model
2023-11-05 11:31:17,432:INFO:Gradient Boosting Classifier Imported successfully
2023-11-05 11:31:17,439:INFO:Starting cross validation
2023-11-05 11:31:17,440:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:32:11,674:INFO:Calculating mean and std
2023-11-05 11:32:11,676:INFO:Creating metrics dataframe
2023-11-05 11:32:11,679:INFO:Uploading results into container
2023-11-05 11:32:11,679:INFO:Uploading model into container now
2023-11-05 11:32:11,680:INFO:_master_model_container: 25
2023-11-05 11:32:11,680:INFO:_display_container: 3
2023-11-05 11:32:11,680:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-11-05 11:32:11,680:INFO:create_model() successfully completed......................................
2023-11-05 11:32:11,770:INFO:SubProcess create_model() end ==================================
2023-11-05 11:32:11,770:INFO:Creating metrics dataframe
2023-11-05 11:32:11,782:INFO:Initializing Linear Discriminant Analysis
2023-11-05 11:32:11,782:INFO:Total runtime is 2.5673176884651188 minutes
2023-11-05 11:32:11,785:INFO:SubProcess create_model() called ==================================
2023-11-05 11:32:11,785:INFO:Initializing create_model()
2023-11-05 11:32:11,785:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1F33880>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:32:11,785:INFO:Checking exceptions
2023-11-05 11:32:11,786:INFO:Importing libraries
2023-11-05 11:32:11,786:INFO:Copying training dataset
2023-11-05 11:32:11,825:INFO:Defining folds
2023-11-05 11:32:11,825:INFO:Declaring metric variables
2023-11-05 11:32:11,829:INFO:Importing untrained model
2023-11-05 11:32:11,832:INFO:Linear Discriminant Analysis Imported successfully
2023-11-05 11:32:11,838:INFO:Starting cross validation
2023-11-05 11:32:11,839:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:32:13,107:INFO:Calculating mean and std
2023-11-05 11:32:13,108:INFO:Creating metrics dataframe
2023-11-05 11:32:13,112:INFO:Uploading results into container
2023-11-05 11:32:13,112:INFO:Uploading model into container now
2023-11-05 11:32:13,113:INFO:_master_model_container: 26
2023-11-05 11:32:13,113:INFO:_display_container: 3
2023-11-05 11:32:13,113:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-05 11:32:13,113:INFO:create_model() successfully completed......................................
2023-11-05 11:32:13,210:INFO:SubProcess create_model() end ==================================
2023-11-05 11:32:13,210:INFO:Creating metrics dataframe
2023-11-05 11:32:13,222:INFO:Initializing Extra Trees Classifier
2023-11-05 11:32:13,223:INFO:Total runtime is 2.591329658031464 minutes
2023-11-05 11:32:13,226:INFO:SubProcess create_model() called ==================================
2023-11-05 11:32:13,226:INFO:Initializing create_model()
2023-11-05 11:32:13,226:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1F33880>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:32:13,226:INFO:Checking exceptions
2023-11-05 11:32:13,226:INFO:Importing libraries
2023-11-05 11:32:13,226:INFO:Copying training dataset
2023-11-05 11:32:13,265:INFO:Defining folds
2023-11-05 11:32:13,265:INFO:Declaring metric variables
2023-11-05 11:32:13,268:INFO:Importing untrained model
2023-11-05 11:32:13,271:INFO:Extra Trees Classifier Imported successfully
2023-11-05 11:32:13,277:INFO:Starting cross validation
2023-11-05 11:32:13,278:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:32:36,172:INFO:Calculating mean and std
2023-11-05 11:32:36,174:INFO:Creating metrics dataframe
2023-11-05 11:32:36,177:INFO:Uploading results into container
2023-11-05 11:32:36,177:INFO:Uploading model into container now
2023-11-05 11:32:36,178:INFO:_master_model_container: 27
2023-11-05 11:32:36,178:INFO:_display_container: 3
2023-11-05 11:32:36,178:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-11-05 11:32:36,178:INFO:create_model() successfully completed......................................
2023-11-05 11:32:36,285:INFO:SubProcess create_model() end ==================================
2023-11-05 11:32:36,286:INFO:Creating metrics dataframe
2023-11-05 11:32:36,298:INFO:Initializing Extreme Gradient Boosting
2023-11-05 11:32:36,298:INFO:Total runtime is 2.975913008054098 minutes
2023-11-05 11:32:36,302:INFO:SubProcess create_model() called ==================================
2023-11-05 11:32:36,302:INFO:Initializing create_model()
2023-11-05 11:32:36,302:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1F33880>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:32:36,302:INFO:Checking exceptions
2023-11-05 11:32:36,302:INFO:Importing libraries
2023-11-05 11:32:36,302:INFO:Copying training dataset
2023-11-05 11:32:36,352:INFO:Defining folds
2023-11-05 11:32:36,353:INFO:Declaring metric variables
2023-11-05 11:32:36,356:INFO:Importing untrained model
2023-11-05 11:32:36,360:INFO:Extreme Gradient Boosting Imported successfully
2023-11-05 11:32:36,367:INFO:Starting cross validation
2023-11-05 11:32:36,368:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:32:40,387:INFO:Calculating mean and std
2023-11-05 11:32:40,388:INFO:Creating metrics dataframe
2023-11-05 11:32:40,392:INFO:Uploading results into container
2023-11-05 11:32:40,392:INFO:Uploading model into container now
2023-11-05 11:32:40,393:INFO:_master_model_container: 28
2023-11-05 11:32:40,393:INFO:_display_container: 3
2023-11-05 11:32:40,394:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2023-11-05 11:32:40,394:INFO:create_model() successfully completed......................................
2023-11-05 11:32:40,515:INFO:SubProcess create_model() end ==================================
2023-11-05 11:32:40,515:INFO:Creating metrics dataframe
2023-11-05 11:32:40,528:INFO:Initializing Light Gradient Boosting Machine
2023-11-05 11:32:40,528:INFO:Total runtime is 3.0464130043983464 minutes
2023-11-05 11:32:40,532:INFO:SubProcess create_model() called ==================================
2023-11-05 11:32:40,532:INFO:Initializing create_model()
2023-11-05 11:32:40,532:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1F33880>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:32:40,532:INFO:Checking exceptions
2023-11-05 11:32:40,533:INFO:Importing libraries
2023-11-05 11:32:40,533:INFO:Copying training dataset
2023-11-05 11:32:40,608:INFO:Defining folds
2023-11-05 11:32:40,609:INFO:Declaring metric variables
2023-11-05 11:32:40,612:INFO:Importing untrained model
2023-11-05 11:32:40,617:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-05 11:32:40,624:INFO:Starting cross validation
2023-11-05 11:32:40,626:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:32:46,029:INFO:Calculating mean and std
2023-11-05 11:32:46,030:INFO:Creating metrics dataframe
2023-11-05 11:32:46,034:INFO:Uploading results into container
2023-11-05 11:32:46,035:INFO:Uploading model into container now
2023-11-05 11:32:46,035:INFO:_master_model_container: 29
2023-11-05 11:32:46,036:INFO:_display_container: 3
2023-11-05 11:32:46,036:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 11:32:46,036:INFO:create_model() successfully completed......................................
2023-11-05 11:32:46,162:INFO:SubProcess create_model() end ==================================
2023-11-05 11:32:46,163:INFO:Creating metrics dataframe
2023-11-05 11:32:46,175:INFO:Initializing Dummy Classifier
2023-11-05 11:32:46,175:INFO:Total runtime is 3.140529660383861 minutes
2023-11-05 11:32:46,178:INFO:SubProcess create_model() called ==================================
2023-11-05 11:32:46,178:INFO:Initializing create_model()
2023-11-05 11:32:46,178:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266F1F33880>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:32:46,179:INFO:Checking exceptions
2023-11-05 11:32:46,179:INFO:Importing libraries
2023-11-05 11:32:46,179:INFO:Copying training dataset
2023-11-05 11:32:46,219:INFO:Defining folds
2023-11-05 11:32:46,219:INFO:Declaring metric variables
2023-11-05 11:32:46,222:INFO:Importing untrained model
2023-11-05 11:32:46,225:INFO:Dummy Classifier Imported successfully
2023-11-05 11:32:46,231:INFO:Starting cross validation
2023-11-05 11:32:46,232:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:32:46,402:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:32:46,424:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:32:46,449:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:32:46,454:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:32:46,470:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:32:46,492:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:32:46,498:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:32:46,501:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:32:46,516:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:32:46,522:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:32:46,646:INFO:Calculating mean and std
2023-11-05 11:32:46,647:INFO:Creating metrics dataframe
2023-11-05 11:32:46,651:INFO:Uploading results into container
2023-11-05 11:32:46,651:INFO:Uploading model into container now
2023-11-05 11:32:46,651:INFO:_master_model_container: 30
2023-11-05 11:32:46,652:INFO:_display_container: 3
2023-11-05 11:32:46,652:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-11-05 11:32:46,652:INFO:create_model() successfully completed......................................
2023-11-05 11:32:46,740:INFO:SubProcess create_model() end ==================================
2023-11-05 11:32:46,740:INFO:Creating metrics dataframe
2023-11-05 11:32:46,762:INFO:Initializing create_model()
2023-11-05 11:32:46,762:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:32:46,762:INFO:Checking exceptions
2023-11-05 11:32:46,763:INFO:Importing libraries
2023-11-05 11:32:46,764:INFO:Copying training dataset
2023-11-05 11:32:46,802:INFO:Defining folds
2023-11-05 11:32:46,802:INFO:Declaring metric variables
2023-11-05 11:32:46,803:INFO:Importing untrained model
2023-11-05 11:32:46,803:INFO:Declaring custom model
2023-11-05 11:32:46,803:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-05 11:32:46,804:INFO:Cross validation set to False
2023-11-05 11:32:46,804:INFO:Fitting Model
2023-11-05 11:32:46,940:INFO:[LightGBM] [Info] Number of positive: 29322, number of negative: 97741
2023-11-05 11:32:46,962:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004095 seconds.
2023-11-05 11:32:46,962:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-05 11:32:46,962:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-05 11:32:46,962:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-05 11:32:46,963:INFO:[LightGBM] [Info] Number of data points in the train set: 127063, number of used features: 19
2023-11-05 11:32:46,963:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230767 -> initscore=-1.203983
2023-11-05 11:32:46,964:INFO:[LightGBM] [Info] Start training from score -1.203983
2023-11-05 11:32:47,368:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 11:32:47,368:INFO:create_model() successfully completed......................................
2023-11-05 11:32:47,505:INFO:_master_model_container: 30
2023-11-05 11:32:47,505:INFO:_display_container: 3
2023-11-05 11:32:47,506:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 11:32:47,506:INFO:compare_models() successfully completed......................................
2023-11-05 11:33:38,995:INFO:Initializing compare_models()
2023-11-05 11:33:38,995:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-11-05 11:33:38,995:INFO:Checking exceptions
2023-11-05 11:33:39,018:INFO:Preparing display monitor
2023-11-05 11:33:39,043:INFO:Initializing Logistic Regression
2023-11-05 11:33:39,043:INFO:Total runtime is 0.0 minutes
2023-11-05 11:33:39,046:INFO:SubProcess create_model() called ==================================
2023-11-05 11:33:39,046:INFO:Initializing create_model()
2023-11-05 11:33:39,046:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CF5B1370>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:33:39,046:INFO:Checking exceptions
2023-11-05 11:33:39,047:INFO:Importing libraries
2023-11-05 11:33:39,047:INFO:Copying training dataset
2023-11-05 11:33:39,105:INFO:Defining folds
2023-11-05 11:33:39,105:INFO:Declaring metric variables
2023-11-05 11:33:39,109:INFO:Importing untrained model
2023-11-05 11:33:39,113:INFO:Logistic Regression Imported successfully
2023-11-05 11:33:39,119:INFO:Starting cross validation
2023-11-05 11:33:39,120:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:33:42,523:INFO:Calculating mean and std
2023-11-05 11:33:42,525:INFO:Creating metrics dataframe
2023-11-05 11:33:42,529:INFO:Uploading results into container
2023-11-05 11:33:42,529:INFO:Uploading model into container now
2023-11-05 11:33:42,530:INFO:_master_model_container: 31
2023-11-05 11:33:42,530:INFO:_display_container: 4
2023-11-05 11:33:42,531:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-05 11:33:42,531:INFO:create_model() successfully completed......................................
2023-11-05 11:33:42,621:INFO:SubProcess create_model() end ==================================
2023-11-05 11:33:42,621:INFO:Creating metrics dataframe
2023-11-05 11:33:42,629:INFO:Initializing K Neighbors Classifier
2023-11-05 11:33:42,629:INFO:Total runtime is 0.05976661443710327 minutes
2023-11-05 11:33:42,633:INFO:SubProcess create_model() called ==================================
2023-11-05 11:33:42,633:INFO:Initializing create_model()
2023-11-05 11:33:42,633:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CF5B1370>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:33:42,633:INFO:Checking exceptions
2023-11-05 11:33:42,634:INFO:Importing libraries
2023-11-05 11:33:42,634:INFO:Copying training dataset
2023-11-05 11:33:42,675:INFO:Defining folds
2023-11-05 11:33:42,675:INFO:Declaring metric variables
2023-11-05 11:33:42,678:INFO:Importing untrained model
2023-11-05 11:33:42,682:INFO:K Neighbors Classifier Imported successfully
2023-11-05 11:33:42,687:INFO:Starting cross validation
2023-11-05 11:33:42,688:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:34:14,703:INFO:Calculating mean and std
2023-11-05 11:34:14,705:INFO:Creating metrics dataframe
2023-11-05 11:34:14,708:INFO:Uploading results into container
2023-11-05 11:34:14,709:INFO:Uploading model into container now
2023-11-05 11:34:14,709:INFO:_master_model_container: 32
2023-11-05 11:34:14,710:INFO:_display_container: 4
2023-11-05 11:34:14,710:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-05 11:34:14,710:INFO:create_model() successfully completed......................................
2023-11-05 11:34:14,806:INFO:SubProcess create_model() end ==================================
2023-11-05 11:34:14,806:INFO:Creating metrics dataframe
2023-11-05 11:34:14,815:INFO:Initializing Naive Bayes
2023-11-05 11:34:14,815:INFO:Total runtime is 0.5961985270182292 minutes
2023-11-05 11:34:14,818:INFO:SubProcess create_model() called ==================================
2023-11-05 11:34:14,819:INFO:Initializing create_model()
2023-11-05 11:34:14,819:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CF5B1370>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:34:14,819:INFO:Checking exceptions
2023-11-05 11:34:14,819:INFO:Importing libraries
2023-11-05 11:34:14,819:INFO:Copying training dataset
2023-11-05 11:34:14,861:INFO:Defining folds
2023-11-05 11:34:14,861:INFO:Declaring metric variables
2023-11-05 11:34:14,865:INFO:Importing untrained model
2023-11-05 11:34:14,868:INFO:Naive Bayes Imported successfully
2023-11-05 11:34:14,874:INFO:Starting cross validation
2023-11-05 11:34:14,875:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:34:15,432:INFO:Calculating mean and std
2023-11-05 11:34:15,433:INFO:Creating metrics dataframe
2023-11-05 11:34:15,437:INFO:Uploading results into container
2023-11-05 11:34:15,438:INFO:Uploading model into container now
2023-11-05 11:34:15,438:INFO:_master_model_container: 33
2023-11-05 11:34:15,438:INFO:_display_container: 4
2023-11-05 11:34:15,438:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-05 11:34:15,439:INFO:create_model() successfully completed......................................
2023-11-05 11:34:15,535:INFO:SubProcess create_model() end ==================================
2023-11-05 11:34:15,535:INFO:Creating metrics dataframe
2023-11-05 11:34:15,545:INFO:Initializing Decision Tree Classifier
2023-11-05 11:34:15,545:INFO:Total runtime is 0.6083624760309855 minutes
2023-11-05 11:34:15,549:INFO:SubProcess create_model() called ==================================
2023-11-05 11:34:15,549:INFO:Initializing create_model()
2023-11-05 11:34:15,549:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CF5B1370>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:34:15,549:INFO:Checking exceptions
2023-11-05 11:34:15,549:INFO:Importing libraries
2023-11-05 11:34:15,549:INFO:Copying training dataset
2023-11-05 11:34:15,592:INFO:Defining folds
2023-11-05 11:34:15,593:INFO:Declaring metric variables
2023-11-05 11:34:15,596:INFO:Importing untrained model
2023-11-05 11:34:15,599:INFO:Decision Tree Classifier Imported successfully
2023-11-05 11:34:15,605:INFO:Starting cross validation
2023-11-05 11:34:15,606:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:34:18,235:INFO:Calculating mean and std
2023-11-05 11:34:18,236:INFO:Creating metrics dataframe
2023-11-05 11:34:18,240:INFO:Uploading results into container
2023-11-05 11:34:18,240:INFO:Uploading model into container now
2023-11-05 11:34:18,240:INFO:_master_model_container: 34
2023-11-05 11:34:18,240:INFO:_display_container: 4
2023-11-05 11:34:18,241:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-11-05 11:34:18,241:INFO:create_model() successfully completed......................................
2023-11-05 11:34:18,331:INFO:SubProcess create_model() end ==================================
2023-11-05 11:34:18,331:INFO:Creating metrics dataframe
2023-11-05 11:34:18,340:INFO:Initializing SVM - Linear Kernel
2023-11-05 11:34:18,340:INFO:Total runtime is 0.6549408038457234 minutes
2023-11-05 11:34:18,344:INFO:SubProcess create_model() called ==================================
2023-11-05 11:34:18,344:INFO:Initializing create_model()
2023-11-05 11:34:18,344:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CF5B1370>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:34:18,344:INFO:Checking exceptions
2023-11-05 11:34:18,344:INFO:Importing libraries
2023-11-05 11:34:18,344:INFO:Copying training dataset
2023-11-05 11:34:18,385:INFO:Defining folds
2023-11-05 11:34:18,385:INFO:Declaring metric variables
2023-11-05 11:34:18,388:INFO:Importing untrained model
2023-11-05 11:34:18,391:INFO:SVM - Linear Kernel Imported successfully
2023-11-05 11:34:18,397:INFO:Starting cross validation
2023-11-05 11:34:18,398:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:34:22,438:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:34:22,494:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:34:22,716:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:34:22,728:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:34:22,764:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:34:22,873:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:34:23,193:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:34:23,395:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:34:23,699:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:34:24,755:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:34:24,899:INFO:Calculating mean and std
2023-11-05 11:34:24,900:INFO:Creating metrics dataframe
2023-11-05 11:34:24,904:INFO:Uploading results into container
2023-11-05 11:34:24,904:INFO:Uploading model into container now
2023-11-05 11:34:24,905:INFO:_master_model_container: 35
2023-11-05 11:34:24,905:INFO:_display_container: 4
2023-11-05 11:34:24,905:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-05 11:34:24,906:INFO:create_model() successfully completed......................................
2023-11-05 11:34:24,997:INFO:SubProcess create_model() end ==================================
2023-11-05 11:34:24,997:INFO:Creating metrics dataframe
2023-11-05 11:34:25,007:INFO:Initializing Ridge Classifier
2023-11-05 11:34:25,007:INFO:Total runtime is 0.7660653313000996 minutes
2023-11-05 11:34:25,010:INFO:SubProcess create_model() called ==================================
2023-11-05 11:34:25,010:INFO:Initializing create_model()
2023-11-05 11:34:25,010:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CF5B1370>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:34:25,010:INFO:Checking exceptions
2023-11-05 11:34:25,011:INFO:Importing libraries
2023-11-05 11:34:25,011:INFO:Copying training dataset
2023-11-05 11:34:25,054:INFO:Defining folds
2023-11-05 11:34:25,054:INFO:Declaring metric variables
2023-11-05 11:34:25,057:INFO:Importing untrained model
2023-11-05 11:34:25,060:INFO:Ridge Classifier Imported successfully
2023-11-05 11:34:25,066:INFO:Starting cross validation
2023-11-05 11:34:25,067:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:34:25,447:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.02642e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:34:25,447:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.13719e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:34:25,470:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:34:25,473:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:34:25,488:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.19282e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:34:25,517:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.04676e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:34:25,520:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:34:25,521:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.11761e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:34:25,527:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.21583e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:34:25,538:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:34:25,542:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:34:25,547:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:34:25,554:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.16596e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:34:25,562:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.20541e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:34:25,567:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:34:25,575:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:34:25,583:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.20378e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:34:25,592:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.11314e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:34:25,593:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:34:25,601:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:34:25,742:INFO:Calculating mean and std
2023-11-05 11:34:25,744:INFO:Creating metrics dataframe
2023-11-05 11:34:25,749:INFO:Uploading results into container
2023-11-05 11:34:25,750:INFO:Uploading model into container now
2023-11-05 11:34:25,750:INFO:_master_model_container: 36
2023-11-05 11:34:25,751:INFO:_display_container: 4
2023-11-05 11:34:25,751:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-11-05 11:34:25,751:INFO:create_model() successfully completed......................................
2023-11-05 11:34:25,840:INFO:SubProcess create_model() end ==================================
2023-11-05 11:34:25,841:INFO:Creating metrics dataframe
2023-11-05 11:34:25,851:INFO:Initializing Random Forest Classifier
2023-11-05 11:34:25,851:INFO:Total runtime is 0.7801255623499551 minutes
2023-11-05 11:34:25,854:INFO:SubProcess create_model() called ==================================
2023-11-05 11:34:25,854:INFO:Initializing create_model()
2023-11-05 11:34:25,854:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CF5B1370>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:34:25,854:INFO:Checking exceptions
2023-11-05 11:34:25,855:INFO:Importing libraries
2023-11-05 11:34:25,855:INFO:Copying training dataset
2023-11-05 11:34:25,894:INFO:Defining folds
2023-11-05 11:34:25,895:INFO:Declaring metric variables
2023-11-05 11:34:25,898:INFO:Importing untrained model
2023-11-05 11:34:25,901:INFO:Random Forest Classifier Imported successfully
2023-11-05 11:34:25,907:INFO:Starting cross validation
2023-11-05 11:34:25,908:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:35:04,284:INFO:Calculating mean and std
2023-11-05 11:35:04,286:INFO:Creating metrics dataframe
2023-11-05 11:35:04,289:INFO:Uploading results into container
2023-11-05 11:35:04,290:INFO:Uploading model into container now
2023-11-05 11:35:04,290:INFO:_master_model_container: 37
2023-11-05 11:35:04,290:INFO:_display_container: 4
2023-11-05 11:35:04,291:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-11-05 11:35:04,291:INFO:create_model() successfully completed......................................
2023-11-05 11:35:04,401:INFO:SubProcess create_model() end ==================================
2023-11-05 11:35:04,402:INFO:Creating metrics dataframe
2023-11-05 11:35:04,415:INFO:Initializing Quadratic Discriminant Analysis
2023-11-05 11:35:04,415:INFO:Total runtime is 1.4228596329689025 minutes
2023-11-05 11:35:04,419:INFO:SubProcess create_model() called ==================================
2023-11-05 11:35:04,419:INFO:Initializing create_model()
2023-11-05 11:35:04,419:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CF5B1370>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:35:04,419:INFO:Checking exceptions
2023-11-05 11:35:04,419:INFO:Importing libraries
2023-11-05 11:35:04,420:INFO:Copying training dataset
2023-11-05 11:35:04,485:INFO:Defining folds
2023-11-05 11:35:04,485:INFO:Declaring metric variables
2023-11-05 11:35:04,493:INFO:Importing untrained model
2023-11-05 11:35:04,497:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-05 11:35:04,506:INFO:Starting cross validation
2023-11-05 11:35:04,507:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:35:05,162:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:35:05,191:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:35:05,212:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:35:05,381:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:35:05,441:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:35:05,464:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:35:05,559:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:35:05,580:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:35:05,593:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:35:05,643:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:35:05,843:INFO:Calculating mean and std
2023-11-05 11:35:05,844:INFO:Creating metrics dataframe
2023-11-05 11:35:05,849:INFO:Uploading results into container
2023-11-05 11:35:05,850:INFO:Uploading model into container now
2023-11-05 11:35:05,850:INFO:_master_model_container: 38
2023-11-05 11:35:05,850:INFO:_display_container: 4
2023-11-05 11:35:05,850:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-05 11:35:05,850:INFO:create_model() successfully completed......................................
2023-11-05 11:35:05,949:INFO:SubProcess create_model() end ==================================
2023-11-05 11:35:05,949:INFO:Creating metrics dataframe
2023-11-05 11:35:05,961:INFO:Initializing Ada Boost Classifier
2023-11-05 11:35:05,961:INFO:Total runtime is 1.4486263354619344 minutes
2023-11-05 11:35:05,964:INFO:SubProcess create_model() called ==================================
2023-11-05 11:35:05,964:INFO:Initializing create_model()
2023-11-05 11:35:05,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CF5B1370>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:35:05,965:INFO:Checking exceptions
2023-11-05 11:35:05,965:INFO:Importing libraries
2023-11-05 11:35:05,965:INFO:Copying training dataset
2023-11-05 11:35:06,007:INFO:Defining folds
2023-11-05 11:35:06,007:INFO:Declaring metric variables
2023-11-05 11:35:06,011:INFO:Importing untrained model
2023-11-05 11:35:06,014:INFO:Ada Boost Classifier Imported successfully
2023-11-05 11:35:06,021:INFO:Starting cross validation
2023-11-05 11:35:06,022:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:35:19,139:INFO:Calculating mean and std
2023-11-05 11:35:19,140:INFO:Creating metrics dataframe
2023-11-05 11:35:19,144:INFO:Uploading results into container
2023-11-05 11:35:19,145:INFO:Uploading model into container now
2023-11-05 11:35:19,145:INFO:_master_model_container: 39
2023-11-05 11:35:19,145:INFO:_display_container: 4
2023-11-05 11:35:19,146:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-11-05 11:35:19,146:INFO:create_model() successfully completed......................................
2023-11-05 11:35:19,238:INFO:SubProcess create_model() end ==================================
2023-11-05 11:35:19,238:INFO:Creating metrics dataframe
2023-11-05 11:35:19,249:INFO:Initializing Gradient Boosting Classifier
2023-11-05 11:35:19,249:INFO:Total runtime is 1.670094887415568 minutes
2023-11-05 11:35:19,253:INFO:SubProcess create_model() called ==================================
2023-11-05 11:35:19,253:INFO:Initializing create_model()
2023-11-05 11:35:19,253:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CF5B1370>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:35:19,253:INFO:Checking exceptions
2023-11-05 11:35:19,253:INFO:Importing libraries
2023-11-05 11:35:19,253:INFO:Copying training dataset
2023-11-05 11:35:19,297:INFO:Defining folds
2023-11-05 11:35:19,297:INFO:Declaring metric variables
2023-11-05 11:35:19,301:INFO:Importing untrained model
2023-11-05 11:35:19,304:INFO:Gradient Boosting Classifier Imported successfully
2023-11-05 11:35:19,310:INFO:Starting cross validation
2023-11-05 11:35:19,311:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:36:15,801:INFO:Calculating mean and std
2023-11-05 11:36:15,803:INFO:Creating metrics dataframe
2023-11-05 11:36:15,806:INFO:Uploading results into container
2023-11-05 11:36:15,806:INFO:Uploading model into container now
2023-11-05 11:36:15,807:INFO:_master_model_container: 40
2023-11-05 11:36:15,807:INFO:_display_container: 4
2023-11-05 11:36:15,808:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-11-05 11:36:15,808:INFO:create_model() successfully completed......................................
2023-11-05 11:36:15,898:INFO:SubProcess create_model() end ==================================
2023-11-05 11:36:15,898:INFO:Creating metrics dataframe
2023-11-05 11:36:15,910:INFO:Initializing Linear Discriminant Analysis
2023-11-05 11:36:15,910:INFO:Total runtime is 2.6144448280334474 minutes
2023-11-05 11:36:15,915:INFO:SubProcess create_model() called ==================================
2023-11-05 11:36:15,915:INFO:Initializing create_model()
2023-11-05 11:36:15,915:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CF5B1370>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:36:15,915:INFO:Checking exceptions
2023-11-05 11:36:15,915:INFO:Importing libraries
2023-11-05 11:36:15,915:INFO:Copying training dataset
2023-11-05 11:36:15,963:INFO:Defining folds
2023-11-05 11:36:15,963:INFO:Declaring metric variables
2023-11-05 11:36:15,966:INFO:Importing untrained model
2023-11-05 11:36:15,970:INFO:Linear Discriminant Analysis Imported successfully
2023-11-05 11:36:15,975:INFO:Starting cross validation
2023-11-05 11:36:15,976:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:36:17,616:INFO:Calculating mean and std
2023-11-05 11:36:17,618:INFO:Creating metrics dataframe
2023-11-05 11:36:17,621:INFO:Uploading results into container
2023-11-05 11:36:17,622:INFO:Uploading model into container now
2023-11-05 11:36:17,623:INFO:_master_model_container: 41
2023-11-05 11:36:17,623:INFO:_display_container: 4
2023-11-05 11:36:17,623:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-05 11:36:17,623:INFO:create_model() successfully completed......................................
2023-11-05 11:36:17,712:INFO:SubProcess create_model() end ==================================
2023-11-05 11:36:17,712:INFO:Creating metrics dataframe
2023-11-05 11:36:17,724:INFO:Initializing Extra Trees Classifier
2023-11-05 11:36:17,724:INFO:Total runtime is 2.6446781714757286 minutes
2023-11-05 11:36:17,727:INFO:SubProcess create_model() called ==================================
2023-11-05 11:36:17,727:INFO:Initializing create_model()
2023-11-05 11:36:17,727:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CF5B1370>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:36:17,727:INFO:Checking exceptions
2023-11-05 11:36:17,727:INFO:Importing libraries
2023-11-05 11:36:17,727:INFO:Copying training dataset
2023-11-05 11:36:17,768:INFO:Defining folds
2023-11-05 11:36:17,768:INFO:Declaring metric variables
2023-11-05 11:36:17,771:INFO:Importing untrained model
2023-11-05 11:36:17,774:INFO:Extra Trees Classifier Imported successfully
2023-11-05 11:36:17,780:INFO:Starting cross validation
2023-11-05 11:36:17,781:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:36:42,751:INFO:Calculating mean and std
2023-11-05 11:36:42,753:INFO:Creating metrics dataframe
2023-11-05 11:36:42,756:INFO:Uploading results into container
2023-11-05 11:36:42,757:INFO:Uploading model into container now
2023-11-05 11:36:42,757:INFO:_master_model_container: 42
2023-11-05 11:36:42,757:INFO:_display_container: 4
2023-11-05 11:36:42,758:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-11-05 11:36:42,758:INFO:create_model() successfully completed......................................
2023-11-05 11:36:42,871:INFO:SubProcess create_model() end ==================================
2023-11-05 11:36:42,871:INFO:Creating metrics dataframe
2023-11-05 11:36:42,884:INFO:Initializing Extreme Gradient Boosting
2023-11-05 11:36:42,884:INFO:Total runtime is 3.0640115261077883 minutes
2023-11-05 11:36:42,887:INFO:SubProcess create_model() called ==================================
2023-11-05 11:36:42,888:INFO:Initializing create_model()
2023-11-05 11:36:42,888:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CF5B1370>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:36:42,888:INFO:Checking exceptions
2023-11-05 11:36:42,888:INFO:Importing libraries
2023-11-05 11:36:42,888:INFO:Copying training dataset
2023-11-05 11:36:42,965:INFO:Defining folds
2023-11-05 11:36:42,966:INFO:Declaring metric variables
2023-11-05 11:36:42,971:INFO:Importing untrained model
2023-11-05 11:36:42,978:INFO:Extreme Gradient Boosting Imported successfully
2023-11-05 11:36:42,990:INFO:Starting cross validation
2023-11-05 11:36:42,992:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:36:47,905:INFO:Calculating mean and std
2023-11-05 11:36:47,906:INFO:Creating metrics dataframe
2023-11-05 11:36:47,910:INFO:Uploading results into container
2023-11-05 11:36:47,911:INFO:Uploading model into container now
2023-11-05 11:36:47,911:INFO:_master_model_container: 43
2023-11-05 11:36:47,911:INFO:_display_container: 4
2023-11-05 11:36:47,912:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2023-11-05 11:36:47,912:INFO:create_model() successfully completed......................................
2023-11-05 11:36:48,013:INFO:SubProcess create_model() end ==================================
2023-11-05 11:36:48,013:INFO:Creating metrics dataframe
2023-11-05 11:36:48,026:INFO:Initializing Light Gradient Boosting Machine
2023-11-05 11:36:48,026:INFO:Total runtime is 3.149711497624715 minutes
2023-11-05 11:36:48,029:INFO:SubProcess create_model() called ==================================
2023-11-05 11:36:48,030:INFO:Initializing create_model()
2023-11-05 11:36:48,030:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CF5B1370>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:36:48,030:INFO:Checking exceptions
2023-11-05 11:36:48,030:INFO:Importing libraries
2023-11-05 11:36:48,030:INFO:Copying training dataset
2023-11-05 11:36:48,074:INFO:Defining folds
2023-11-05 11:36:48,074:INFO:Declaring metric variables
2023-11-05 11:36:48,077:INFO:Importing untrained model
2023-11-05 11:36:48,081:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-05 11:36:48,087:INFO:Starting cross validation
2023-11-05 11:36:48,088:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:36:53,133:INFO:Calculating mean and std
2023-11-05 11:36:53,134:INFO:Creating metrics dataframe
2023-11-05 11:36:53,140:INFO:Uploading results into container
2023-11-05 11:36:53,140:INFO:Uploading model into container now
2023-11-05 11:36:53,141:INFO:_master_model_container: 44
2023-11-05 11:36:53,141:INFO:_display_container: 4
2023-11-05 11:36:53,141:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 11:36:53,142:INFO:create_model() successfully completed......................................
2023-11-05 11:36:53,240:INFO:SubProcess create_model() end ==================================
2023-11-05 11:36:53,241:INFO:Creating metrics dataframe
2023-11-05 11:36:53,254:INFO:Initializing Dummy Classifier
2023-11-05 11:36:53,254:INFO:Total runtime is 3.2368448257446287 minutes
2023-11-05 11:36:53,258:INFO:SubProcess create_model() called ==================================
2023-11-05 11:36:53,258:INFO:Initializing create_model()
2023-11-05 11:36:53,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000266CF5B1370>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:36:53,258:INFO:Checking exceptions
2023-11-05 11:36:53,258:INFO:Importing libraries
2023-11-05 11:36:53,258:INFO:Copying training dataset
2023-11-05 11:36:53,299:INFO:Defining folds
2023-11-05 11:36:53,300:INFO:Declaring metric variables
2023-11-05 11:36:53,303:INFO:Importing untrained model
2023-11-05 11:36:53,306:INFO:Dummy Classifier Imported successfully
2023-11-05 11:36:53,313:INFO:Starting cross validation
2023-11-05 11:36:53,314:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:36:53,574:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:36:53,580:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:36:53,586:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:36:53,639:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:36:53,650:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:36:53,659:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:36:53,672:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:36:53,679:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:36:53,687:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:36:53,693:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:36:53,827:INFO:Calculating mean and std
2023-11-05 11:36:53,828:INFO:Creating metrics dataframe
2023-11-05 11:36:53,831:INFO:Uploading results into container
2023-11-05 11:36:53,832:INFO:Uploading model into container now
2023-11-05 11:36:53,832:INFO:_master_model_container: 45
2023-11-05 11:36:53,832:INFO:_display_container: 4
2023-11-05 11:36:53,833:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-11-05 11:36:53,833:INFO:create_model() successfully completed......................................
2023-11-05 11:36:53,937:INFO:SubProcess create_model() end ==================================
2023-11-05 11:36:53,938:INFO:Creating metrics dataframe
2023-11-05 11:36:53,966:INFO:Initializing create_model()
2023-11-05 11:36:53,966:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:36:53,967:INFO:Checking exceptions
2023-11-05 11:36:53,969:INFO:Importing libraries
2023-11-05 11:36:53,970:INFO:Copying training dataset
2023-11-05 11:36:54,035:INFO:Defining folds
2023-11-05 11:36:54,035:INFO:Declaring metric variables
2023-11-05 11:36:54,035:INFO:Importing untrained model
2023-11-05 11:36:54,035:INFO:Declaring custom model
2023-11-05 11:36:54,036:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-05 11:36:54,037:INFO:Cross validation set to False
2023-11-05 11:36:54,037:INFO:Fitting Model
2023-11-05 11:36:54,188:INFO:[LightGBM] [Info] Number of positive: 29322, number of negative: 97741
2023-11-05 11:36:54,207:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003905 seconds.
2023-11-05 11:36:54,207:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-05 11:36:54,207:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-05 11:36:54,207:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-05 11:36:54,208:INFO:[LightGBM] [Info] Number of data points in the train set: 127063, number of used features: 19
2023-11-05 11:36:54,208:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230767 -> initscore=-1.203983
2023-11-05 11:36:54,209:INFO:[LightGBM] [Info] Start training from score -1.203983
2023-11-05 11:36:54,732:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 11:36:54,732:INFO:create_model() successfully completed......................................
2023-11-05 11:36:54,883:INFO:_master_model_container: 45
2023-11-05 11:36:54,883:INFO:_display_container: 4
2023-11-05 11:36:54,884:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 11:36:54,884:INFO:compare_models() successfully completed......................................
2023-11-05 11:38:02,443:INFO:Initializing create_model()
2023-11-05 11:38:02,443:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000266CD16B4C0>, estimator=xgb, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:38:02,443:INFO:Checking exceptions
2023-11-05 11:39:42,068:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-05 11:39:42,068:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-05 11:39:42,069:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-05 11:39:42,069:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-05 11:39:42,348:INFO:PyCaret ClassificationExperiment
2023-11-05 11:39:42,349:INFO:Logging name: clf-default-name
2023-11-05 11:39:42,349:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-05 11:39:42,349:INFO:version 3.1.0
2023-11-05 11:39:42,349:INFO:Initializing setup()
2023-11-05 11:39:42,349:INFO:self.USI: c19e
2023-11-05 11:39:42,349:INFO:self._variable_keys: {'idx', 'y_test', 'target_param', 'fold_generator', 'fix_imbalance', 'X', 'is_multiclass', 'fold_shuffle_param', 'USI', 'data', '_available_plots', 'html_param', '_ml_usecase', 'memory', 'gpu_n_jobs_param', 'exp_name_log', 'n_jobs_param', 'fold_groups_param', 'X_train', 'exp_id', 'pipeline', 'seed', 'y_train', 'log_plots_param', 'y', 'X_test', 'gpu_param', 'logging_param'}
2023-11-05 11:39:42,349:INFO:Checking environment
2023-11-05 11:39:42,349:INFO:python_version: 3.9.18
2023-11-05 11:39:42,349:INFO:python_build: ('main', 'Sep 11 2023 14:09:26')
2023-11-05 11:39:42,349:INFO:machine: AMD64
2023-11-05 11:39:42,349:INFO:platform: Windows-10-10.0.19041-SP0
2023-11-05 11:39:42,349:INFO:Memory: svmem(total=25692647424, available=16348184576, percent=36.4, used=9344462848, free=16348184576)
2023-11-05 11:39:42,349:INFO:Physical Core: 8
2023-11-05 11:39:42,349:INFO:Logical Core: 16
2023-11-05 11:39:42,349:INFO:Checking libraries
2023-11-05 11:39:42,349:INFO:System:
2023-11-05 11:39:42,349:INFO:    python: 3.9.18 (main, Sep 11 2023, 14:09:26) [MSC v.1916 64 bit (AMD64)]
2023-11-05 11:39:42,349:INFO:executable: d:\programas\Anaconda3\envs\meli_test2\python.exe
2023-11-05 11:39:42,349:INFO:   machine: Windows-10-10.0.19041-SP0
2023-11-05 11:39:42,349:INFO:PyCaret required dependencies:
2023-11-05 11:39:42,371:INFO:                 pip: 23.3
2023-11-05 11:39:42,371:INFO:          setuptools: 68.0.0
2023-11-05 11:39:42,371:INFO:             pycaret: 3.1.0
2023-11-05 11:39:42,371:INFO:             IPython: 8.17.2
2023-11-05 11:39:42,371:INFO:          ipywidgets: 8.1.1
2023-11-05 11:39:42,371:INFO:                tqdm: 4.66.1
2023-11-05 11:39:42,371:INFO:               numpy: 1.23.5
2023-11-05 11:39:42,372:INFO:              pandas: 1.5.3
2023-11-05 11:39:42,372:INFO:              jinja2: 3.1.2
2023-11-05 11:39:42,372:INFO:               scipy: 1.10.1
2023-11-05 11:39:42,372:INFO:              joblib: 1.3.2
2023-11-05 11:39:42,372:INFO:             sklearn: 1.2.2
2023-11-05 11:39:42,372:INFO:                pyod: 1.1.1
2023-11-05 11:39:42,372:INFO:            imblearn: 0.11.0
2023-11-05 11:39:42,372:INFO:   category_encoders: 2.6.3
2023-11-05 11:39:42,372:INFO:            lightgbm: 4.1.0
2023-11-05 11:39:42,372:INFO:               numba: 0.58.1
2023-11-05 11:39:42,372:INFO:            requests: 2.31.0
2023-11-05 11:39:42,372:INFO:          matplotlib: 3.8.1
2023-11-05 11:39:42,372:INFO:          scikitplot: 0.3.7
2023-11-05 11:39:42,372:INFO:         yellowbrick: 1.5
2023-11-05 11:39:42,372:INFO:              plotly: 5.18.0
2023-11-05 11:39:42,372:INFO:    plotly-resampler: Not installed
2023-11-05 11:39:42,372:INFO:             kaleido: 0.2.1
2023-11-05 11:39:42,372:INFO:           schemdraw: 0.15
2023-11-05 11:39:42,372:INFO:         statsmodels: 0.14.0
2023-11-05 11:39:42,372:INFO:              sktime: 0.21.1
2023-11-05 11:39:42,372:INFO:               tbats: 1.1.3
2023-11-05 11:39:42,372:INFO:            pmdarima: 2.0.4
2023-11-05 11:39:42,372:INFO:              psutil: 5.9.6
2023-11-05 11:39:42,372:INFO:          markupsafe: 2.1.3
2023-11-05 11:39:42,372:INFO:             pickle5: Not installed
2023-11-05 11:39:42,373:INFO:         cloudpickle: 3.0.0
2023-11-05 11:39:42,373:INFO:         deprecation: 2.1.0
2023-11-05 11:39:42,373:INFO:              xxhash: 3.4.1
2023-11-05 11:39:42,373:INFO:           wurlitzer: Not installed
2023-11-05 11:39:42,373:INFO:PyCaret optional dependencies:
2023-11-05 11:39:42,417:INFO:                shap: Not installed
2023-11-05 11:39:42,417:INFO:           interpret: Not installed
2023-11-05 11:39:42,417:INFO:                umap: Not installed
2023-11-05 11:39:42,417:INFO:     ydata_profiling: Not installed
2023-11-05 11:39:42,417:INFO:  explainerdashboard: Not installed
2023-11-05 11:39:42,417:INFO:             autoviz: Not installed
2023-11-05 11:39:42,417:INFO:           fairlearn: Not installed
2023-11-05 11:39:42,417:INFO:          deepchecks: Not installed
2023-11-05 11:39:42,417:INFO:             xgboost: 2.0.1
2023-11-05 11:39:42,417:INFO:            catboost: Not installed
2023-11-05 11:39:42,418:INFO:              kmodes: Not installed
2023-11-05 11:39:42,418:INFO:             mlxtend: Not installed
2023-11-05 11:39:42,418:INFO:       statsforecast: Not installed
2023-11-05 11:39:42,418:INFO:        tune_sklearn: Not installed
2023-11-05 11:39:42,418:INFO:                 ray: Not installed
2023-11-05 11:39:42,418:INFO:            hyperopt: Not installed
2023-11-05 11:39:42,418:INFO:              optuna: Not installed
2023-11-05 11:39:42,418:INFO:               skopt: Not installed
2023-11-05 11:39:42,418:INFO:              mlflow: Not installed
2023-11-05 11:39:42,418:INFO:              gradio: Not installed
2023-11-05 11:39:42,418:INFO:             fastapi: Not installed
2023-11-05 11:39:42,418:INFO:             uvicorn: Not installed
2023-11-05 11:39:42,418:INFO:              m2cgen: Not installed
2023-11-05 11:39:42,418:INFO:           evidently: Not installed
2023-11-05 11:39:42,418:INFO:               fugue: Not installed
2023-11-05 11:39:42,418:INFO:           streamlit: Not installed
2023-11-05 11:39:42,418:INFO:             prophet: Not installed
2023-11-05 11:39:42,418:INFO:None
2023-11-05 11:39:42,418:INFO:Set up data.
2023-11-05 11:39:42,428:INFO:Set up folding strategy.
2023-11-05 11:39:42,429:INFO:Set up train/test split.
2023-11-05 11:39:42,436:INFO:Set up index.
2023-11-05 11:39:42,436:INFO:Assigning column types.
2023-11-05 11:39:42,441:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-05 11:39:42,494:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-05 11:39:42,496:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 11:39:42,533:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:39:42,537:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:39:42,590:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-05 11:39:42,591:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 11:39:42,624:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:39:42,627:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:39:42,627:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-05 11:39:42,682:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 11:39:42,716:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:39:42,719:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:39:42,774:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 11:39:42,808:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:39:42,811:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:39:42,812:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-05 11:39:42,900:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:39:42,903:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:39:42,992:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:39:42,995:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:39:42,997:INFO:Preparing preprocessing pipeline...
2023-11-05 11:39:42,998:INFO:Set up simple imputation.
2023-11-05 11:39:43,018:INFO:Finished creating preprocessing pipeline.
2023-11-05 11:39:43,023:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['a', 'b', 'c', 'd', 'e', 'f', 'h',
                                             'k', 'l', 'm', 'n', 'p', 'monto',
                                             'score', 'Country_AR',
                                             'Country_BR', 'Country_US',
                                             'Country_UY', 'Country_otros'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-05 11:39:43,023:INFO:Creating final display dataframe.
2023-11-05 11:39:43,088:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            fraude
2                   Target type            Binary
3           Original data shape       (10000, 20)
4        Transformed data shape       (10000, 20)
5   Transformed train set shape        (7000, 20)
6    Transformed test set shape        (3000, 20)
7              Numeric features                19
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              c19e
2023-11-05 11:39:43,183:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:39:43,186:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:39:43,275:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:39:43,278:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:39:43,279:INFO:setup() successfully completed in 0.93s...............
2023-11-05 11:39:46,123:INFO:Initializing compare_models()
2023-11-05 11:39:46,123:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-11-05 11:39:46,123:INFO:Checking exceptions
2023-11-05 11:39:46,128:INFO:Preparing display monitor
2023-11-05 11:39:46,151:INFO:Initializing Logistic Regression
2023-11-05 11:39:46,152:INFO:Total runtime is 1.668532689412435e-05 minutes
2023-11-05 11:39:46,156:INFO:SubProcess create_model() called ==================================
2023-11-05 11:39:46,156:INFO:Initializing create_model()
2023-11-05 11:39:46,156:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CAB877F5B0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:39:46,157:INFO:Checking exceptions
2023-11-05 11:39:46,157:INFO:Importing libraries
2023-11-05 11:39:46,157:INFO:Copying training dataset
2023-11-05 11:39:46,163:INFO:Defining folds
2023-11-05 11:39:46,163:INFO:Declaring metric variables
2023-11-05 11:39:46,167:INFO:Importing untrained model
2023-11-05 11:39:46,174:INFO:Logistic Regression Imported successfully
2023-11-05 11:39:46,182:INFO:Starting cross validation
2023-11-05 11:39:46,183:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:39:49,874:INFO:Calculating mean and std
2023-11-05 11:39:49,876:INFO:Creating metrics dataframe
2023-11-05 11:39:49,882:INFO:Uploading results into container
2023-11-05 11:39:49,883:INFO:Uploading model into container now
2023-11-05 11:39:49,884:INFO:_master_model_container: 1
2023-11-05 11:39:49,884:INFO:_display_container: 2
2023-11-05 11:39:49,885:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-05 11:39:49,885:INFO:create_model() successfully completed......................................
2023-11-05 11:39:49,979:INFO:SubProcess create_model() end ==================================
2023-11-05 11:39:49,980:INFO:Creating metrics dataframe
2023-11-05 11:39:49,989:INFO:Initializing K Neighbors Classifier
2023-11-05 11:39:49,989:INFO:Total runtime is 0.06396670341491699 minutes
2023-11-05 11:39:49,992:INFO:SubProcess create_model() called ==================================
2023-11-05 11:39:49,993:INFO:Initializing create_model()
2023-11-05 11:39:49,993:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CAB877F5B0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:39:49,993:INFO:Checking exceptions
2023-11-05 11:39:49,993:INFO:Importing libraries
2023-11-05 11:39:49,993:INFO:Copying training dataset
2023-11-05 11:39:49,998:INFO:Defining folds
2023-11-05 11:39:49,998:INFO:Declaring metric variables
2023-11-05 11:39:50,002:INFO:Importing untrained model
2023-11-05 11:39:50,005:INFO:K Neighbors Classifier Imported successfully
2023-11-05 11:39:50,011:INFO:Starting cross validation
2023-11-05 11:39:50,012:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:39:52,617:INFO:Calculating mean and std
2023-11-05 11:39:52,619:INFO:Creating metrics dataframe
2023-11-05 11:39:52,623:INFO:Uploading results into container
2023-11-05 11:39:52,624:INFO:Uploading model into container now
2023-11-05 11:39:52,624:INFO:_master_model_container: 2
2023-11-05 11:39:52,624:INFO:_display_container: 2
2023-11-05 11:39:52,625:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-05 11:39:52,625:INFO:create_model() successfully completed......................................
2023-11-05 11:39:52,709:INFO:SubProcess create_model() end ==================================
2023-11-05 11:39:52,709:INFO:Creating metrics dataframe
2023-11-05 11:39:52,718:INFO:Initializing Naive Bayes
2023-11-05 11:39:52,718:INFO:Total runtime is 0.10944999853769938 minutes
2023-11-05 11:39:52,721:INFO:SubProcess create_model() called ==================================
2023-11-05 11:39:52,721:INFO:Initializing create_model()
2023-11-05 11:39:52,721:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CAB877F5B0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:39:52,722:INFO:Checking exceptions
2023-11-05 11:39:52,722:INFO:Importing libraries
2023-11-05 11:39:52,722:INFO:Copying training dataset
2023-11-05 11:39:52,727:INFO:Defining folds
2023-11-05 11:39:52,727:INFO:Declaring metric variables
2023-11-05 11:39:52,731:INFO:Importing untrained model
2023-11-05 11:39:52,734:INFO:Naive Bayes Imported successfully
2023-11-05 11:39:52,741:INFO:Starting cross validation
2023-11-05 11:39:52,742:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:39:52,838:INFO:Calculating mean and std
2023-11-05 11:39:52,839:INFO:Creating metrics dataframe
2023-11-05 11:39:52,843:INFO:Uploading results into container
2023-11-05 11:39:52,843:INFO:Uploading model into container now
2023-11-05 11:39:52,844:INFO:_master_model_container: 3
2023-11-05 11:39:52,844:INFO:_display_container: 2
2023-11-05 11:39:52,844:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-05 11:39:52,844:INFO:create_model() successfully completed......................................
2023-11-05 11:39:52,912:INFO:SubProcess create_model() end ==================================
2023-11-05 11:39:52,912:INFO:Creating metrics dataframe
2023-11-05 11:39:52,921:INFO:Initializing Decision Tree Classifier
2023-11-05 11:39:52,921:INFO:Total runtime is 0.11283331314722697 minutes
2023-11-05 11:39:52,925:INFO:SubProcess create_model() called ==================================
2023-11-05 11:39:52,925:INFO:Initializing create_model()
2023-11-05 11:39:52,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CAB877F5B0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:39:52,925:INFO:Checking exceptions
2023-11-05 11:39:52,925:INFO:Importing libraries
2023-11-05 11:39:52,926:INFO:Copying training dataset
2023-11-05 11:39:52,930:INFO:Defining folds
2023-11-05 11:39:52,930:INFO:Declaring metric variables
2023-11-05 11:39:52,933:INFO:Importing untrained model
2023-11-05 11:39:52,937:INFO:Decision Tree Classifier Imported successfully
2023-11-05 11:39:52,943:INFO:Starting cross validation
2023-11-05 11:39:52,944:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:39:53,088:INFO:Calculating mean and std
2023-11-05 11:39:53,089:INFO:Creating metrics dataframe
2023-11-05 11:39:53,093:INFO:Uploading results into container
2023-11-05 11:39:53,093:INFO:Uploading model into container now
2023-11-05 11:39:53,093:INFO:_master_model_container: 4
2023-11-05 11:39:53,094:INFO:_display_container: 2
2023-11-05 11:39:53,094:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-11-05 11:39:53,094:INFO:create_model() successfully completed......................................
2023-11-05 11:39:53,163:INFO:SubProcess create_model() end ==================================
2023-11-05 11:39:53,163:INFO:Creating metrics dataframe
2023-11-05 11:39:53,173:INFO:Initializing SVM - Linear Kernel
2023-11-05 11:39:53,173:INFO:Total runtime is 0.11703333059946697 minutes
2023-11-05 11:39:53,176:INFO:SubProcess create_model() called ==================================
2023-11-05 11:39:53,177:INFO:Initializing create_model()
2023-11-05 11:39:53,177:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CAB877F5B0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:39:53,177:INFO:Checking exceptions
2023-11-05 11:39:53,177:INFO:Importing libraries
2023-11-05 11:39:53,177:INFO:Copying training dataset
2023-11-05 11:39:53,182:INFO:Defining folds
2023-11-05 11:39:53,182:INFO:Declaring metric variables
2023-11-05 11:39:53,185:INFO:Importing untrained model
2023-11-05 11:39:53,188:INFO:SVM - Linear Kernel Imported successfully
2023-11-05 11:39:53,197:INFO:Starting cross validation
2023-11-05 11:39:53,198:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:39:53,266:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:39:53,267:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:39:53,270:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:39:53,275:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:39:53,276:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:39:53,277:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:39:53,277:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:39:53,281:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:39:53,283:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:39:53,283:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:39:53,284:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:39:53,289:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:39:53,290:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:39:53,310:INFO:Calculating mean and std
2023-11-05 11:39:53,311:INFO:Creating metrics dataframe
2023-11-05 11:39:53,317:INFO:Uploading results into container
2023-11-05 11:39:53,318:INFO:Uploading model into container now
2023-11-05 11:39:53,319:INFO:_master_model_container: 5
2023-11-05 11:39:53,319:INFO:_display_container: 2
2023-11-05 11:39:53,320:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-05 11:39:53,320:INFO:create_model() successfully completed......................................
2023-11-05 11:39:53,397:INFO:SubProcess create_model() end ==================================
2023-11-05 11:39:53,397:INFO:Creating metrics dataframe
2023-11-05 11:39:53,411:INFO:Initializing Ridge Classifier
2023-11-05 11:39:53,411:INFO:Total runtime is 0.12099999189376832 minutes
2023-11-05 11:39:53,414:INFO:SubProcess create_model() called ==================================
2023-11-05 11:39:53,414:INFO:Initializing create_model()
2023-11-05 11:39:53,415:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CAB877F5B0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:39:53,415:INFO:Checking exceptions
2023-11-05 11:39:53,415:INFO:Importing libraries
2023-11-05 11:39:53,415:INFO:Copying training dataset
2023-11-05 11:39:53,420:INFO:Defining folds
2023-11-05 11:39:53,421:INFO:Declaring metric variables
2023-11-05 11:39:53,424:INFO:Importing untrained model
2023-11-05 11:39:53,427:INFO:Ridge Classifier Imported successfully
2023-11-05 11:39:53,434:INFO:Starting cross validation
2023-11-05 11:39:53,435:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:39:53,465:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.63131e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:39:53,473:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.7381e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:39:53,473:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.83846e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:39:53,476:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.00082e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:39:53,476:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.35371e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:39:53,477:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:39:53,481:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.55764e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:39:53,481:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.69407e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:39:53,481:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:39:53,484:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:39:53,487:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:39:53,489:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.65325e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:39:53,489:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.48563e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:39:53,490:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.86743e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:39:53,490:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:39:53,491:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:39:53,494:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:39:53,497:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:39:53,498:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:39:53,516:INFO:Calculating mean and std
2023-11-05 11:39:53,516:INFO:Creating metrics dataframe
2023-11-05 11:39:53,520:INFO:Uploading results into container
2023-11-05 11:39:53,520:INFO:Uploading model into container now
2023-11-05 11:39:53,520:INFO:_master_model_container: 6
2023-11-05 11:39:53,521:INFO:_display_container: 2
2023-11-05 11:39:53,521:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-11-05 11:39:53,521:INFO:create_model() successfully completed......................................
2023-11-05 11:39:53,592:INFO:SubProcess create_model() end ==================================
2023-11-05 11:39:53,592:INFO:Creating metrics dataframe
2023-11-05 11:39:53,602:INFO:Initializing Random Forest Classifier
2023-11-05 11:39:53,602:INFO:Total runtime is 0.1241833527882894 minutes
2023-11-05 11:39:53,606:INFO:SubProcess create_model() called ==================================
2023-11-05 11:39:53,606:INFO:Initializing create_model()
2023-11-05 11:39:53,607:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CAB877F5B0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:39:53,607:INFO:Checking exceptions
2023-11-05 11:39:53,607:INFO:Importing libraries
2023-11-05 11:39:53,607:INFO:Copying training dataset
2023-11-05 11:39:53,612:INFO:Defining folds
2023-11-05 11:39:53,612:INFO:Declaring metric variables
2023-11-05 11:39:53,616:INFO:Importing untrained model
2023-11-05 11:39:53,620:INFO:Random Forest Classifier Imported successfully
2023-11-05 11:39:53,626:INFO:Starting cross validation
2023-11-05 11:39:53,627:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:39:55,251:INFO:Calculating mean and std
2023-11-05 11:39:55,252:INFO:Creating metrics dataframe
2023-11-05 11:39:55,255:INFO:Uploading results into container
2023-11-05 11:39:55,256:INFO:Uploading model into container now
2023-11-05 11:39:55,256:INFO:_master_model_container: 7
2023-11-05 11:39:55,256:INFO:_display_container: 2
2023-11-05 11:39:55,257:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-11-05 11:39:55,257:INFO:create_model() successfully completed......................................
2023-11-05 11:39:55,326:INFO:SubProcess create_model() end ==================================
2023-11-05 11:39:55,327:INFO:Creating metrics dataframe
2023-11-05 11:39:55,337:INFO:Initializing Quadratic Discriminant Analysis
2023-11-05 11:39:55,337:INFO:Total runtime is 0.15309174060821534 minutes
2023-11-05 11:39:55,341:INFO:SubProcess create_model() called ==================================
2023-11-05 11:39:55,341:INFO:Initializing create_model()
2023-11-05 11:39:55,341:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CAB877F5B0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:39:55,341:INFO:Checking exceptions
2023-11-05 11:39:55,341:INFO:Importing libraries
2023-11-05 11:39:55,342:INFO:Copying training dataset
2023-11-05 11:39:55,346:INFO:Defining folds
2023-11-05 11:39:55,346:INFO:Declaring metric variables
2023-11-05 11:39:55,349:INFO:Importing untrained model
2023-11-05 11:39:55,353:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-05 11:39:55,361:INFO:Starting cross validation
2023-11-05 11:39:55,362:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:39:55,393:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:39:55,394:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:39:55,403:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:39:55,403:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:39:55,403:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:39:55,405:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:39:55,410:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:39:55,414:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:39:55,417:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:39:55,418:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:39:55,418:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:39:55,418:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-11-05 11:39:55,420:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:39:55,420:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:39:55,421:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-11-05 11:39:55,423:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:39:55,423:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-11-05 11:39:55,456:INFO:Calculating mean and std
2023-11-05 11:39:55,457:INFO:Creating metrics dataframe
2023-11-05 11:39:55,461:INFO:Uploading results into container
2023-11-05 11:39:55,462:INFO:Uploading model into container now
2023-11-05 11:39:55,462:INFO:_master_model_container: 8
2023-11-05 11:39:55,462:INFO:_display_container: 2
2023-11-05 11:39:55,462:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-05 11:39:55,462:INFO:create_model() successfully completed......................................
2023-11-05 11:39:55,535:INFO:SubProcess create_model() end ==================================
2023-11-05 11:39:55,535:INFO:Creating metrics dataframe
2023-11-05 11:39:55,547:INFO:Initializing Ada Boost Classifier
2023-11-05 11:39:55,547:INFO:Total runtime is 0.1565916895866394 minutes
2023-11-05 11:39:55,550:INFO:SubProcess create_model() called ==================================
2023-11-05 11:39:55,551:INFO:Initializing create_model()
2023-11-05 11:39:55,551:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CAB877F5B0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:39:55,551:INFO:Checking exceptions
2023-11-05 11:39:55,551:INFO:Importing libraries
2023-11-05 11:39:55,551:INFO:Copying training dataset
2023-11-05 11:39:55,556:INFO:Defining folds
2023-11-05 11:39:55,556:INFO:Declaring metric variables
2023-11-05 11:39:55,559:INFO:Importing untrained model
2023-11-05 11:39:55,562:INFO:Ada Boost Classifier Imported successfully
2023-11-05 11:39:55,569:INFO:Starting cross validation
2023-11-05 11:39:55,570:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:39:56,301:INFO:Calculating mean and std
2023-11-05 11:39:56,301:INFO:Creating metrics dataframe
2023-11-05 11:39:56,305:INFO:Uploading results into container
2023-11-05 11:39:56,306:INFO:Uploading model into container now
2023-11-05 11:39:56,306:INFO:_master_model_container: 9
2023-11-05 11:39:56,306:INFO:_display_container: 2
2023-11-05 11:39:56,307:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-11-05 11:39:56,307:INFO:create_model() successfully completed......................................
2023-11-05 11:39:56,376:INFO:SubProcess create_model() end ==================================
2023-11-05 11:39:56,376:INFO:Creating metrics dataframe
2023-11-05 11:39:56,387:INFO:Initializing Gradient Boosting Classifier
2023-11-05 11:39:56,387:INFO:Total runtime is 0.17059168020884197 minutes
2023-11-05 11:39:56,391:INFO:SubProcess create_model() called ==================================
2023-11-05 11:39:56,391:INFO:Initializing create_model()
2023-11-05 11:39:56,391:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CAB877F5B0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:39:56,391:INFO:Checking exceptions
2023-11-05 11:39:56,391:INFO:Importing libraries
2023-11-05 11:39:56,391:INFO:Copying training dataset
2023-11-05 11:39:56,396:INFO:Defining folds
2023-11-05 11:39:56,396:INFO:Declaring metric variables
2023-11-05 11:39:56,399:INFO:Importing untrained model
2023-11-05 11:39:56,402:INFO:Gradient Boosting Classifier Imported successfully
2023-11-05 11:39:56,408:INFO:Starting cross validation
2023-11-05 11:39:56,409:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:39:59,025:INFO:Calculating mean and std
2023-11-05 11:39:59,026:INFO:Creating metrics dataframe
2023-11-05 11:39:59,030:INFO:Uploading results into container
2023-11-05 11:39:59,030:INFO:Uploading model into container now
2023-11-05 11:39:59,031:INFO:_master_model_container: 10
2023-11-05 11:39:59,031:INFO:_display_container: 2
2023-11-05 11:39:59,031:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-11-05 11:39:59,032:INFO:create_model() successfully completed......................................
2023-11-05 11:39:59,113:INFO:SubProcess create_model() end ==================================
2023-11-05 11:39:59,113:INFO:Creating metrics dataframe
2023-11-05 11:39:59,126:INFO:Initializing Linear Discriminant Analysis
2023-11-05 11:39:59,126:INFO:Total runtime is 0.2162416934967041 minutes
2023-11-05 11:39:59,129:INFO:SubProcess create_model() called ==================================
2023-11-05 11:39:59,129:INFO:Initializing create_model()
2023-11-05 11:39:59,129:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CAB877F5B0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:39:59,130:INFO:Checking exceptions
2023-11-05 11:39:59,130:INFO:Importing libraries
2023-11-05 11:39:59,130:INFO:Copying training dataset
2023-11-05 11:39:59,135:INFO:Defining folds
2023-11-05 11:39:59,135:INFO:Declaring metric variables
2023-11-05 11:39:59,139:INFO:Importing untrained model
2023-11-05 11:39:59,143:INFO:Linear Discriminant Analysis Imported successfully
2023-11-05 11:39:59,151:INFO:Starting cross validation
2023-11-05 11:39:59,152:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:39:59,263:INFO:Calculating mean and std
2023-11-05 11:39:59,264:INFO:Creating metrics dataframe
2023-11-05 11:39:59,268:INFO:Uploading results into container
2023-11-05 11:39:59,268:INFO:Uploading model into container now
2023-11-05 11:39:59,269:INFO:_master_model_container: 11
2023-11-05 11:39:59,269:INFO:_display_container: 2
2023-11-05 11:39:59,269:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-05 11:39:59,269:INFO:create_model() successfully completed......................................
2023-11-05 11:39:59,343:INFO:SubProcess create_model() end ==================================
2023-11-05 11:39:59,343:INFO:Creating metrics dataframe
2023-11-05 11:39:59,357:INFO:Initializing Extra Trees Classifier
2023-11-05 11:39:59,357:INFO:Total runtime is 0.22009169260660807 minutes
2023-11-05 11:39:59,360:INFO:SubProcess create_model() called ==================================
2023-11-05 11:39:59,361:INFO:Initializing create_model()
2023-11-05 11:39:59,361:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CAB877F5B0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:39:59,361:INFO:Checking exceptions
2023-11-05 11:39:59,361:INFO:Importing libraries
2023-11-05 11:39:59,361:INFO:Copying training dataset
2023-11-05 11:39:59,367:INFO:Defining folds
2023-11-05 11:39:59,367:INFO:Declaring metric variables
2023-11-05 11:39:59,371:INFO:Importing untrained model
2023-11-05 11:39:59,374:INFO:Extra Trees Classifier Imported successfully
2023-11-05 11:39:59,382:INFO:Starting cross validation
2023-11-05 11:39:59,383:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:40:00,193:INFO:Calculating mean and std
2023-11-05 11:40:00,194:INFO:Creating metrics dataframe
2023-11-05 11:40:00,197:INFO:Uploading results into container
2023-11-05 11:40:00,198:INFO:Uploading model into container now
2023-11-05 11:40:00,198:INFO:_master_model_container: 12
2023-11-05 11:40:00,198:INFO:_display_container: 2
2023-11-05 11:40:00,199:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-11-05 11:40:00,199:INFO:create_model() successfully completed......................................
2023-11-05 11:40:00,266:INFO:SubProcess create_model() end ==================================
2023-11-05 11:40:00,266:INFO:Creating metrics dataframe
2023-11-05 11:40:00,278:INFO:Initializing Extreme Gradient Boosting
2023-11-05 11:40:00,278:INFO:Total runtime is 0.23544169664382936 minutes
2023-11-05 11:40:00,282:INFO:SubProcess create_model() called ==================================
2023-11-05 11:40:00,282:INFO:Initializing create_model()
2023-11-05 11:40:00,282:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CAB877F5B0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:40:00,282:INFO:Checking exceptions
2023-11-05 11:40:00,282:INFO:Importing libraries
2023-11-05 11:40:00,282:INFO:Copying training dataset
2023-11-05 11:40:00,287:INFO:Defining folds
2023-11-05 11:40:00,287:INFO:Declaring metric variables
2023-11-05 11:40:00,290:INFO:Importing untrained model
2023-11-05 11:40:00,293:INFO:Extreme Gradient Boosting Imported successfully
2023-11-05 11:40:00,301:INFO:Starting cross validation
2023-11-05 11:40:00,302:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:40:00,877:INFO:Calculating mean and std
2023-11-05 11:40:00,878:INFO:Creating metrics dataframe
2023-11-05 11:40:00,884:INFO:Uploading results into container
2023-11-05 11:40:00,885:INFO:Uploading model into container now
2023-11-05 11:40:00,885:INFO:_master_model_container: 13
2023-11-05 11:40:00,886:INFO:_display_container: 2
2023-11-05 11:40:00,887:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2023-11-05 11:40:00,887:INFO:create_model() successfully completed......................................
2023-11-05 11:40:00,965:INFO:SubProcess create_model() end ==================================
2023-11-05 11:40:00,966:INFO:Creating metrics dataframe
2023-11-05 11:40:00,978:INFO:Initializing Light Gradient Boosting Machine
2023-11-05 11:40:00,978:INFO:Total runtime is 0.24710837602615357 minutes
2023-11-05 11:40:00,982:INFO:SubProcess create_model() called ==================================
2023-11-05 11:40:00,982:INFO:Initializing create_model()
2023-11-05 11:40:00,983:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CAB877F5B0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:40:00,983:INFO:Checking exceptions
2023-11-05 11:40:00,983:INFO:Importing libraries
2023-11-05 11:40:00,983:INFO:Copying training dataset
2023-11-05 11:40:00,988:INFO:Defining folds
2023-11-05 11:40:00,988:INFO:Declaring metric variables
2023-11-05 11:40:00,991:INFO:Importing untrained model
2023-11-05 11:40:00,994:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-05 11:40:01,002:INFO:Starting cross validation
2023-11-05 11:40:01,003:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:40:02,179:INFO:Calculating mean and std
2023-11-05 11:40:02,180:INFO:Creating metrics dataframe
2023-11-05 11:40:02,184:INFO:Uploading results into container
2023-11-05 11:40:02,185:INFO:Uploading model into container now
2023-11-05 11:40:02,185:INFO:_master_model_container: 14
2023-11-05 11:40:02,185:INFO:_display_container: 2
2023-11-05 11:40:02,186:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 11:40:02,186:INFO:create_model() successfully completed......................................
2023-11-05 11:40:02,268:INFO:SubProcess create_model() end ==================================
2023-11-05 11:40:02,268:INFO:Creating metrics dataframe
2023-11-05 11:40:02,282:INFO:Initializing Dummy Classifier
2023-11-05 11:40:02,283:INFO:Total runtime is 0.2688583572705587 minutes
2023-11-05 11:40:02,286:INFO:SubProcess create_model() called ==================================
2023-11-05 11:40:02,287:INFO:Initializing create_model()
2023-11-05 11:40:02,287:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CAB877F5B0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:40:02,287:INFO:Checking exceptions
2023-11-05 11:40:02,287:INFO:Importing libraries
2023-11-05 11:40:02,287:INFO:Copying training dataset
2023-11-05 11:40:02,292:INFO:Defining folds
2023-11-05 11:40:02,292:INFO:Declaring metric variables
2023-11-05 11:40:02,295:INFO:Importing untrained model
2023-11-05 11:40:02,299:INFO:Dummy Classifier Imported successfully
2023-11-05 11:40:02,307:INFO:Starting cross validation
2023-11-05 11:40:02,308:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:40:02,349:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:40:02,351:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:40:02,354:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:40:02,356:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:40:02,356:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:40:02,358:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:40:02,359:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:40:02,359:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:40:02,359:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:40:02,365:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:40:02,386:INFO:Calculating mean and std
2023-11-05 11:40:02,386:INFO:Creating metrics dataframe
2023-11-05 11:40:02,390:INFO:Uploading results into container
2023-11-05 11:40:02,390:INFO:Uploading model into container now
2023-11-05 11:40:02,391:INFO:_master_model_container: 15
2023-11-05 11:40:02,391:INFO:_display_container: 2
2023-11-05 11:40:02,391:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-11-05 11:40:02,391:INFO:create_model() successfully completed......................................
2023-11-05 11:40:02,475:INFO:SubProcess create_model() end ==================================
2023-11-05 11:40:02,475:INFO:Creating metrics dataframe
2023-11-05 11:40:02,498:INFO:Initializing create_model()
2023-11-05 11:40:02,499:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:40:02,499:INFO:Checking exceptions
2023-11-05 11:40:02,500:INFO:Importing libraries
2023-11-05 11:40:02,501:INFO:Copying training dataset
2023-11-05 11:40:02,505:INFO:Defining folds
2023-11-05 11:40:02,505:INFO:Declaring metric variables
2023-11-05 11:40:02,505:INFO:Importing untrained model
2023-11-05 11:40:02,505:INFO:Declaring custom model
2023-11-05 11:40:02,506:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-05 11:40:02,507:INFO:Cross validation set to False
2023-11-05 11:40:02,507:INFO:Fitting Model
2023-11-05 11:40:02,522:INFO:[LightGBM] [Info] Number of positive: 1650, number of negative: 5350
2023-11-05 11:40:02,524:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001492 seconds.
2023-11-05 11:40:02,524:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-05 11:40:02,525:INFO:[LightGBM] [Info] Total Bins 2459
2023-11-05 11:40:02,525:INFO:[LightGBM] [Info] Number of data points in the train set: 7000, number of used features: 19
2023-11-05 11:40:02,525:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.235714 -> initscore=-1.176321
2023-11-05 11:40:02,525:INFO:[LightGBM] [Info] Start training from score -1.176321
2023-11-05 11:40:02,666:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 11:40:02,666:INFO:create_model() successfully completed......................................
2023-11-05 11:40:02,782:INFO:_master_model_container: 15
2023-11-05 11:40:02,782:INFO:_display_container: 2
2023-11-05 11:40:02,783:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 11:40:02,783:INFO:compare_models() successfully completed......................................
2023-11-05 11:40:20,116:INFO:Initializing create_model()
2023-11-05 11:40:20,116:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:40:20,116:INFO:Checking exceptions
2023-11-05 11:40:20,129:INFO:Importing libraries
2023-11-05 11:40:20,129:INFO:Copying training dataset
2023-11-05 11:40:20,135:INFO:Defining folds
2023-11-05 11:40:20,135:INFO:Declaring metric variables
2023-11-05 11:40:20,138:INFO:Importing untrained model
2023-11-05 11:40:20,143:INFO:Extreme Gradient Boosting Imported successfully
2023-11-05 11:40:20,151:INFO:Starting cross validation
2023-11-05 11:40:20,152:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:40:20,967:INFO:Calculating mean and std
2023-11-05 11:40:20,968:INFO:Creating metrics dataframe
2023-11-05 11:40:20,974:INFO:Finalizing model
2023-11-05 11:40:21,185:INFO:Uploading results into container
2023-11-05 11:40:21,186:INFO:Uploading model into container now
2023-11-05 11:40:21,201:INFO:_master_model_container: 16
2023-11-05 11:40:21,201:INFO:_display_container: 3
2023-11-05 11:40:21,202:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2023-11-05 11:40:21,203:INFO:create_model() successfully completed......................................
2023-11-05 11:40:58,332:INFO:Initializing create_model()
2023-11-05 11:40:58,332:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:40:58,332:INFO:Checking exceptions
2023-11-05 11:40:58,350:INFO:Importing libraries
2023-11-05 11:40:58,350:INFO:Copying training dataset
2023-11-05 11:40:58,358:INFO:Defining folds
2023-11-05 11:40:58,358:INFO:Declaring metric variables
2023-11-05 11:40:58,361:INFO:Importing untrained model
2023-11-05 11:40:58,365:INFO:Extreme Gradient Boosting Imported successfully
2023-11-05 11:40:58,371:INFO:Starting cross validation
2023-11-05 11:40:58,372:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:40:59,029:INFO:Calculating mean and std
2023-11-05 11:40:59,030:INFO:Creating metrics dataframe
2023-11-05 11:40:59,036:INFO:Finalizing model
2023-11-05 11:40:59,211:INFO:Uploading results into container
2023-11-05 11:40:59,212:INFO:Uploading model into container now
2023-11-05 11:40:59,226:INFO:_master_model_container: 17
2023-11-05 11:40:59,226:INFO:_display_container: 4
2023-11-05 11:40:59,227:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2023-11-05 11:40:59,227:INFO:create_model() successfully completed......................................
2023-11-05 11:41:17,181:INFO:Initializing predict_model()
2023-11-05 11:41:17,182:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001CAC507FDC0>)
2023-11-05 11:41:17,182:INFO:Checking exceptions
2023-11-05 11:41:17,182:INFO:Preloading libraries
2023-11-05 11:41:56,547:INFO:Initializing plot_model()
2023-11-05 11:41:56,548:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, system=True)
2023-11-05 11:41:56,548:INFO:Checking exceptions
2023-11-05 11:41:56,553:INFO:Preloading libraries
2023-11-05 11:41:56,561:INFO:Copying training dataset
2023-11-05 11:41:56,561:INFO:Plot type: feature
2023-11-05 11:41:56,562:WARNING:No coef_ found. Trying feature_importances_
2023-11-05 11:41:56,779:INFO:Visual Rendered Successfully
2023-11-05 11:41:56,847:INFO:plot_model() successfully completed......................................
2023-11-05 11:42:40,700:INFO:Initializing evaluate_model()
2023-11-05 11:42:40,700:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-11-05 11:42:40,711:INFO:Initializing plot_model()
2023-11-05 11:42:40,711:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, system=True)
2023-11-05 11:42:40,711:INFO:Checking exceptions
2023-11-05 11:42:40,714:INFO:Preloading libraries
2023-11-05 11:42:40,720:INFO:Copying training dataset
2023-11-05 11:42:40,720:INFO:Plot type: pipeline
2023-11-05 11:42:40,855:INFO:Visual Rendered Successfully
2023-11-05 11:42:40,923:INFO:plot_model() successfully completed......................................
2023-11-05 11:42:52,176:INFO:Initializing plot_model()
2023-11-05 11:42:52,176:INFO:plot_model(plot=manifold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, system=True)
2023-11-05 11:42:52,176:INFO:Checking exceptions
2023-11-05 11:42:52,180:INFO:Preloading libraries
2023-11-05 11:42:52,191:INFO:Copying training dataset
2023-11-05 11:42:52,191:INFO:Plot type: manifold
2023-11-05 11:42:52,327:INFO:Fitting & Transforming Model
2023-11-05 11:43:14,403:INFO:Visual Rendered Successfully
2023-11-05 11:43:14,473:INFO:plot_model() successfully completed......................................
2023-11-05 11:43:14,558:INFO:Initializing plot_model()
2023-11-05 11:43:14,558:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, system=True)
2023-11-05 11:43:14,558:INFO:Checking exceptions
2023-11-05 11:43:14,561:INFO:Preloading libraries
2023-11-05 11:43:14,568:INFO:Copying training dataset
2023-11-05 11:43:14,568:INFO:Plot type: parameter
2023-11-05 11:43:14,574:INFO:Visual Rendered Successfully
2023-11-05 11:43:14,654:INFO:plot_model() successfully completed......................................
2023-11-05 11:43:26,338:INFO:Initializing plot_model()
2023-11-05 11:43:26,338:INFO:plot_model(plot=manifold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, system=True)
2023-11-05 11:43:26,338:INFO:Checking exceptions
2023-11-05 11:43:26,341:INFO:Preloading libraries
2023-11-05 11:43:26,348:INFO:Copying training dataset
2023-11-05 11:43:26,348:INFO:Plot type: manifold
2023-11-05 11:43:26,439:INFO:Fitting & Transforming Model
2023-11-05 11:43:44,252:INFO:Visual Rendered Successfully
2023-11-05 11:43:44,330:INFO:plot_model() successfully completed......................................
2023-11-05 11:44:41,289:INFO:Initializing plot_model()
2023-11-05 11:44:41,289:INFO:plot_model(plot=calibration, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, system=True)
2023-11-05 11:44:41,289:INFO:Checking exceptions
2023-11-05 11:44:41,292:INFO:Preloading libraries
2023-11-05 11:44:41,299:INFO:Copying training dataset
2023-11-05 11:44:41,299:INFO:Plot type: calibration
2023-11-05 11:44:41,311:INFO:Scoring test/hold-out set
2023-11-05 11:44:41,526:INFO:Visual Rendered Successfully
2023-11-05 11:44:41,602:INFO:plot_model() successfully completed......................................
2023-11-05 11:44:45,503:INFO:Initializing plot_model()
2023-11-05 11:44:45,504:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, system=True)
2023-11-05 11:44:45,504:INFO:Checking exceptions
2023-11-05 11:44:45,507:INFO:Preloading libraries
2023-11-05 11:44:45,514:INFO:Copying training dataset
2023-11-05 11:44:45,514:INFO:Plot type: auc
2023-11-05 11:44:45,594:INFO:Fitting Model
2023-11-05 11:44:45,595:INFO:Scoring test/hold-out set
2023-11-05 11:44:45,801:INFO:Visual Rendered Successfully
2023-11-05 11:44:45,874:INFO:plot_model() successfully completed......................................
2023-11-05 11:44:58,367:INFO:Initializing plot_model()
2023-11-05 11:44:58,367:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, system=True)
2023-11-05 11:44:58,367:INFO:Checking exceptions
2023-11-05 11:44:58,370:INFO:Preloading libraries
2023-11-05 11:44:58,376:INFO:Copying training dataset
2023-11-05 11:44:58,376:INFO:Plot type: confusion_matrix
2023-11-05 11:44:58,455:INFO:Fitting Model
2023-11-05 11:44:58,456:INFO:Scoring test/hold-out set
2023-11-05 11:44:58,580:INFO:Visual Rendered Successfully
2023-11-05 11:44:58,656:INFO:plot_model() successfully completed......................................
2023-11-05 11:45:05,748:INFO:Initializing plot_model()
2023-11-05 11:45:05,748:INFO:plot_model(plot=pr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, system=True)
2023-11-05 11:45:05,748:INFO:Checking exceptions
2023-11-05 11:45:05,751:INFO:Preloading libraries
2023-11-05 11:45:05,757:INFO:Copying training dataset
2023-11-05 11:45:05,757:INFO:Plot type: pr
2023-11-05 11:45:05,838:INFO:Fitting Model
2023-11-05 11:45:05,839:INFO:Scoring test/hold-out set
2023-11-05 11:45:06,017:INFO:Visual Rendered Successfully
2023-11-05 11:45:06,091:INFO:plot_model() successfully completed......................................
2023-11-05 11:45:15,791:INFO:Initializing plot_model()
2023-11-05 11:45:15,791:INFO:plot_model(plot=tree, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, system=True)
2023-11-05 11:45:15,792:INFO:Checking exceptions
2023-11-05 11:45:25,425:INFO:Initializing plot_model()
2023-11-05 11:45:25,425:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>, system=True)
2023-11-05 11:45:25,425:INFO:Checking exceptions
2023-11-05 11:45:25,428:INFO:Preloading libraries
2023-11-05 11:45:25,434:INFO:Copying training dataset
2023-11-05 11:45:25,434:INFO:Plot type: feature
2023-11-05 11:45:25,435:WARNING:No coef_ found. Trying feature_importances_
2023-11-05 11:45:25,612:INFO:Visual Rendered Successfully
2023-11-05 11:45:25,696:INFO:plot_model() successfully completed......................................
2023-11-05 11:46:55,330:INFO:Initializing interpret_model()
2023-11-05 11:46:55,330:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=feature_importance, kwargs={'n_select': 30}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>)
2023-11-05 11:46:55,331:INFO:Checking exceptions
2023-11-05 11:46:55,331:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2023-11-05 11:47:22,083:INFO:Initializing interpret_model()
2023-11-05 11:47:22,084:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=feature_importance, kwargs={'n_select': 30}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001CAB8797E50>)
2023-11-05 11:47:22,084:INFO:Checking exceptions
2023-11-05 11:47:22,084:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2023-11-05 11:48:03,174:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-05 11:48:03,174:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-05 11:48:03,174:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-05 11:48:03,174:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-05 11:48:03,453:INFO:PyCaret ClassificationExperiment
2023-11-05 11:48:03,454:INFO:Logging name: clf-default-name
2023-11-05 11:48:03,454:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-05 11:48:03,454:INFO:version 3.1.0
2023-11-05 11:48:03,454:INFO:Initializing setup()
2023-11-05 11:48:03,454:INFO:self.USI: 2efb
2023-11-05 11:48:03,454:INFO:self._variable_keys: {'logging_param', 'y_test', 'gpu_param', 'y', 'n_jobs_param', 'memory', 'gpu_n_jobs_param', 'html_param', 'seed', 'data', 'X', 'fix_imbalance', 'USI', 'log_plots_param', 'fold_groups_param', 'fold_generator', '_ml_usecase', 'exp_id', 'is_multiclass', '_available_plots', 'X_train', 'exp_name_log', 'fold_shuffle_param', 'X_test', 'pipeline', 'target_param', 'idx', 'y_train'}
2023-11-05 11:48:03,454:INFO:Checking environment
2023-11-05 11:48:03,454:INFO:python_version: 3.9.18
2023-11-05 11:48:03,454:INFO:python_build: ('main', 'Sep 11 2023 14:09:26')
2023-11-05 11:48:03,454:INFO:machine: AMD64
2023-11-05 11:48:03,454:INFO:platform: Windows-10-10.0.19041-SP0
2023-11-05 11:48:03,454:INFO:Memory: svmem(total=25692647424, available=15929700352, percent=38.0, used=9762947072, free=15929700352)
2023-11-05 11:48:03,454:INFO:Physical Core: 8
2023-11-05 11:48:03,454:INFO:Logical Core: 16
2023-11-05 11:48:03,454:INFO:Checking libraries
2023-11-05 11:48:03,454:INFO:System:
2023-11-05 11:48:03,454:INFO:    python: 3.9.18 (main, Sep 11 2023, 14:09:26) [MSC v.1916 64 bit (AMD64)]
2023-11-05 11:48:03,454:INFO:executable: d:\programas\Anaconda3\envs\meli_test2\python.exe
2023-11-05 11:48:03,454:INFO:   machine: Windows-10-10.0.19041-SP0
2023-11-05 11:48:03,454:INFO:PyCaret required dependencies:
2023-11-05 11:48:03,475:INFO:                 pip: 23.3
2023-11-05 11:48:03,475:INFO:          setuptools: 68.0.0
2023-11-05 11:48:03,475:INFO:             pycaret: 3.1.0
2023-11-05 11:48:03,475:INFO:             IPython: 8.17.2
2023-11-05 11:48:03,475:INFO:          ipywidgets: 8.1.1
2023-11-05 11:48:03,475:INFO:                tqdm: 4.66.1
2023-11-05 11:48:03,475:INFO:               numpy: 1.23.5
2023-11-05 11:48:03,475:INFO:              pandas: 1.5.3
2023-11-05 11:48:03,475:INFO:              jinja2: 3.1.2
2023-11-05 11:48:03,475:INFO:               scipy: 1.10.1
2023-11-05 11:48:03,475:INFO:              joblib: 1.3.2
2023-11-05 11:48:03,475:INFO:             sklearn: 1.2.2
2023-11-05 11:48:03,475:INFO:                pyod: 1.1.1
2023-11-05 11:48:03,475:INFO:            imblearn: 0.11.0
2023-11-05 11:48:03,475:INFO:   category_encoders: 2.6.3
2023-11-05 11:48:03,475:INFO:            lightgbm: 4.1.0
2023-11-05 11:48:03,475:INFO:               numba: 0.58.1
2023-11-05 11:48:03,475:INFO:            requests: 2.31.0
2023-11-05 11:48:03,475:INFO:          matplotlib: 3.8.1
2023-11-05 11:48:03,475:INFO:          scikitplot: 0.3.7
2023-11-05 11:48:03,475:INFO:         yellowbrick: 1.5
2023-11-05 11:48:03,475:INFO:              plotly: 5.18.0
2023-11-05 11:48:03,475:INFO:    plotly-resampler: Not installed
2023-11-05 11:48:03,476:INFO:             kaleido: 0.2.1
2023-11-05 11:48:03,476:INFO:           schemdraw: 0.15
2023-11-05 11:48:03,476:INFO:         statsmodels: 0.14.0
2023-11-05 11:48:03,476:INFO:              sktime: 0.21.1
2023-11-05 11:48:03,476:INFO:               tbats: 1.1.3
2023-11-05 11:48:03,476:INFO:            pmdarima: 2.0.4
2023-11-05 11:48:03,476:INFO:              psutil: 5.9.6
2023-11-05 11:48:03,476:INFO:          markupsafe: 2.1.3
2023-11-05 11:48:03,476:INFO:             pickle5: Not installed
2023-11-05 11:48:03,476:INFO:         cloudpickle: 3.0.0
2023-11-05 11:48:03,476:INFO:         deprecation: 2.1.0
2023-11-05 11:48:03,476:INFO:              xxhash: 3.4.1
2023-11-05 11:48:03,476:INFO:           wurlitzer: Not installed
2023-11-05 11:48:03,476:INFO:PyCaret optional dependencies:
2023-11-05 11:48:03,523:INFO:                shap: 0.43.0
2023-11-05 11:48:03,523:INFO:           interpret: Not installed
2023-11-05 11:48:03,523:INFO:                umap: Not installed
2023-11-05 11:48:03,523:INFO:     ydata_profiling: Not installed
2023-11-05 11:48:03,524:INFO:  explainerdashboard: Not installed
2023-11-05 11:48:03,524:INFO:             autoviz: Not installed
2023-11-05 11:48:03,524:INFO:           fairlearn: Not installed
2023-11-05 11:48:03,524:INFO:          deepchecks: Not installed
2023-11-05 11:48:03,524:INFO:             xgboost: 2.0.1
2023-11-05 11:48:03,524:INFO:            catboost: Not installed
2023-11-05 11:48:03,524:INFO:              kmodes: Not installed
2023-11-05 11:48:03,524:INFO:             mlxtend: Not installed
2023-11-05 11:48:03,524:INFO:       statsforecast: Not installed
2023-11-05 11:48:03,524:INFO:        tune_sklearn: Not installed
2023-11-05 11:48:03,524:INFO:                 ray: Not installed
2023-11-05 11:48:03,524:INFO:            hyperopt: Not installed
2023-11-05 11:48:03,524:INFO:              optuna: Not installed
2023-11-05 11:48:03,524:INFO:               skopt: Not installed
2023-11-05 11:48:03,524:INFO:              mlflow: Not installed
2023-11-05 11:48:03,524:INFO:              gradio: Not installed
2023-11-05 11:48:03,524:INFO:             fastapi: Not installed
2023-11-05 11:48:03,524:INFO:             uvicorn: Not installed
2023-11-05 11:48:03,524:INFO:              m2cgen: Not installed
2023-11-05 11:48:03,524:INFO:           evidently: Not installed
2023-11-05 11:48:03,524:INFO:               fugue: Not installed
2023-11-05 11:48:03,524:INFO:           streamlit: Not installed
2023-11-05 11:48:03,524:INFO:             prophet: Not installed
2023-11-05 11:48:03,524:INFO:None
2023-11-05 11:48:03,525:INFO:Set up data.
2023-11-05 11:48:03,535:INFO:Set up folding strategy.
2023-11-05 11:48:03,535:INFO:Set up train/test split.
2023-11-05 11:48:03,541:INFO:Set up index.
2023-11-05 11:48:03,542:INFO:Assigning column types.
2023-11-05 11:48:03,545:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-05 11:48:03,597:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-05 11:48:03,599:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 11:48:03,636:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:48:03,639:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:48:03,692:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-05 11:48:03,693:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 11:48:03,725:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:48:03,728:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:48:03,729:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-05 11:48:03,781:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 11:48:03,814:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:48:03,817:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:48:03,871:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 11:48:03,904:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:48:03,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:48:03,907:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-05 11:48:03,991:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:48:03,994:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:48:04,079:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:48:04,082:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:48:04,084:INFO:Preparing preprocessing pipeline...
2023-11-05 11:48:04,085:INFO:Set up simple imputation.
2023-11-05 11:48:04,104:INFO:Finished creating preprocessing pipeline.
2023-11-05 11:48:04,109:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['a', 'b', 'c', 'd', 'e', 'f', 'h',
                                             'k', 'l', 'm', 'n', 'p', 'monto',
                                             'score', 'Country_AR',
                                             'Country_BR', 'Country_US',
                                             'Country_UY', 'Country_otros'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-05 11:48:04,109:INFO:Creating final display dataframe.
2023-11-05 11:48:04,174:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            fraude
2                   Target type            Binary
3           Original data shape       (10000, 20)
4        Transformed data shape       (10000, 20)
5   Transformed train set shape        (7000, 20)
6    Transformed test set shape        (3000, 20)
7              Numeric features                19
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              2efb
2023-11-05 11:48:04,274:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:48:04,277:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:48:04,362:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:48:04,365:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:48:04,365:INFO:setup() successfully completed in 0.91s...............
2023-11-05 11:48:04,390:INFO:Initializing compare_models()
2023-11-05 11:48:04,390:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-11-05 11:48:04,390:INFO:Checking exceptions
2023-11-05 11:48:04,395:INFO:Preparing display monitor
2023-11-05 11:48:04,422:INFO:Initializing Logistic Regression
2023-11-05 11:48:04,423:INFO:Total runtime is 1.6705195109049478e-05 minutes
2023-11-05 11:48:04,426:INFO:SubProcess create_model() called ==================================
2023-11-05 11:48:04,427:INFO:Initializing create_model()
2023-11-05 11:48:04,427:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BA0894DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:48:04,427:INFO:Checking exceptions
2023-11-05 11:48:04,427:INFO:Importing libraries
2023-11-05 11:48:04,427:INFO:Copying training dataset
2023-11-05 11:48:04,432:INFO:Defining folds
2023-11-05 11:48:04,432:INFO:Declaring metric variables
2023-11-05 11:48:04,436:INFO:Importing untrained model
2023-11-05 11:48:04,439:INFO:Logistic Regression Imported successfully
2023-11-05 11:48:04,446:INFO:Starting cross validation
2023-11-05 11:48:04,447:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:48:08,113:INFO:Calculating mean and std
2023-11-05 11:48:08,115:INFO:Creating metrics dataframe
2023-11-05 11:48:08,121:INFO:Uploading results into container
2023-11-05 11:48:08,122:INFO:Uploading model into container now
2023-11-05 11:48:08,123:INFO:_master_model_container: 1
2023-11-05 11:48:08,123:INFO:_display_container: 2
2023-11-05 11:48:08,124:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-05 11:48:08,124:INFO:create_model() successfully completed......................................
2023-11-05 11:48:08,211:INFO:SubProcess create_model() end ==================================
2023-11-05 11:48:08,211:INFO:Creating metrics dataframe
2023-11-05 11:48:08,220:INFO:Initializing K Neighbors Classifier
2023-11-05 11:48:08,220:INFO:Total runtime is 0.06330001354217529 minutes
2023-11-05 11:48:08,223:INFO:SubProcess create_model() called ==================================
2023-11-05 11:48:08,224:INFO:Initializing create_model()
2023-11-05 11:48:08,224:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BA0894DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:48:08,224:INFO:Checking exceptions
2023-11-05 11:48:08,224:INFO:Importing libraries
2023-11-05 11:48:08,224:INFO:Copying training dataset
2023-11-05 11:48:08,229:INFO:Defining folds
2023-11-05 11:48:08,229:INFO:Declaring metric variables
2023-11-05 11:48:08,233:INFO:Importing untrained model
2023-11-05 11:48:08,237:INFO:K Neighbors Classifier Imported successfully
2023-11-05 11:48:08,242:INFO:Starting cross validation
2023-11-05 11:48:08,243:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:48:10,643:INFO:Calculating mean and std
2023-11-05 11:48:10,644:INFO:Creating metrics dataframe
2023-11-05 11:48:10,649:INFO:Uploading results into container
2023-11-05 11:48:10,649:INFO:Uploading model into container now
2023-11-05 11:48:10,650:INFO:_master_model_container: 2
2023-11-05 11:48:10,650:INFO:_display_container: 2
2023-11-05 11:48:10,650:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-05 11:48:10,650:INFO:create_model() successfully completed......................................
2023-11-05 11:48:10,726:INFO:SubProcess create_model() end ==================================
2023-11-05 11:48:10,726:INFO:Creating metrics dataframe
2023-11-05 11:48:10,738:INFO:Initializing Naive Bayes
2023-11-05 11:48:10,738:INFO:Total runtime is 0.10526667435963949 minutes
2023-11-05 11:48:10,743:INFO:SubProcess create_model() called ==================================
2023-11-05 11:48:10,743:INFO:Initializing create_model()
2023-11-05 11:48:10,743:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BA0894DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:48:10,743:INFO:Checking exceptions
2023-11-05 11:48:10,744:INFO:Importing libraries
2023-11-05 11:48:10,744:INFO:Copying training dataset
2023-11-05 11:48:10,751:INFO:Defining folds
2023-11-05 11:48:10,751:INFO:Declaring metric variables
2023-11-05 11:48:10,754:INFO:Importing untrained model
2023-11-05 11:48:10,757:INFO:Naive Bayes Imported successfully
2023-11-05 11:48:10,763:INFO:Starting cross validation
2023-11-05 11:48:10,764:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:48:10,834:INFO:Calculating mean and std
2023-11-05 11:48:10,834:INFO:Creating metrics dataframe
2023-11-05 11:48:10,837:INFO:Uploading results into container
2023-11-05 11:48:10,838:INFO:Uploading model into container now
2023-11-05 11:48:10,838:INFO:_master_model_container: 3
2023-11-05 11:48:10,838:INFO:_display_container: 2
2023-11-05 11:48:10,838:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-05 11:48:10,838:INFO:create_model() successfully completed......................................
2023-11-05 11:48:10,903:INFO:SubProcess create_model() end ==================================
2023-11-05 11:48:10,903:INFO:Creating metrics dataframe
2023-11-05 11:48:10,912:INFO:Initializing Decision Tree Classifier
2023-11-05 11:48:10,912:INFO:Total runtime is 0.10816665887832642 minutes
2023-11-05 11:48:10,916:INFO:SubProcess create_model() called ==================================
2023-11-05 11:48:10,917:INFO:Initializing create_model()
2023-11-05 11:48:10,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BA0894DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:48:10,917:INFO:Checking exceptions
2023-11-05 11:48:10,917:INFO:Importing libraries
2023-11-05 11:48:10,917:INFO:Copying training dataset
2023-11-05 11:48:10,922:INFO:Defining folds
2023-11-05 11:48:10,922:INFO:Declaring metric variables
2023-11-05 11:48:10,925:INFO:Importing untrained model
2023-11-05 11:48:10,929:INFO:Decision Tree Classifier Imported successfully
2023-11-05 11:48:10,935:INFO:Starting cross validation
2023-11-05 11:48:10,936:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:48:11,074:INFO:Calculating mean and std
2023-11-05 11:48:11,075:INFO:Creating metrics dataframe
2023-11-05 11:48:11,079:INFO:Uploading results into container
2023-11-05 11:48:11,079:INFO:Uploading model into container now
2023-11-05 11:48:11,080:INFO:_master_model_container: 4
2023-11-05 11:48:11,080:INFO:_display_container: 2
2023-11-05 11:48:11,080:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-11-05 11:48:11,080:INFO:create_model() successfully completed......................................
2023-11-05 11:48:11,147:INFO:SubProcess create_model() end ==================================
2023-11-05 11:48:11,147:INFO:Creating metrics dataframe
2023-11-05 11:48:11,156:INFO:Initializing SVM - Linear Kernel
2023-11-05 11:48:11,156:INFO:Total runtime is 0.1122333288192749 minutes
2023-11-05 11:48:11,161:INFO:SubProcess create_model() called ==================================
2023-11-05 11:48:11,161:INFO:Initializing create_model()
2023-11-05 11:48:11,161:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BA0894DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:48:11,161:INFO:Checking exceptions
2023-11-05 11:48:11,161:INFO:Importing libraries
2023-11-05 11:48:11,161:INFO:Copying training dataset
2023-11-05 11:48:11,167:INFO:Defining folds
2023-11-05 11:48:11,168:INFO:Declaring metric variables
2023-11-05 11:48:11,171:INFO:Importing untrained model
2023-11-05 11:48:11,174:INFO:SVM - Linear Kernel Imported successfully
2023-11-05 11:48:11,182:INFO:Starting cross validation
2023-11-05 11:48:11,183:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:48:11,235:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:48:11,235:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:48:11,241:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:48:11,242:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:48:11,243:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:48:11,244:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:48:11,246:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:48:11,248:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:48:11,254:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:48:11,258:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:48:11,259:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:48:11,275:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:48:11,281:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:48:11,295:INFO:Calculating mean and std
2023-11-05 11:48:11,296:INFO:Creating metrics dataframe
2023-11-05 11:48:11,300:INFO:Uploading results into container
2023-11-05 11:48:11,301:INFO:Uploading model into container now
2023-11-05 11:48:11,302:INFO:_master_model_container: 5
2023-11-05 11:48:11,302:INFO:_display_container: 2
2023-11-05 11:48:11,303:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-05 11:48:11,303:INFO:create_model() successfully completed......................................
2023-11-05 11:48:11,369:INFO:SubProcess create_model() end ==================================
2023-11-05 11:48:11,369:INFO:Creating metrics dataframe
2023-11-05 11:48:11,378:INFO:Initializing Ridge Classifier
2023-11-05 11:48:11,378:INFO:Total runtime is 0.11593335072199504 minutes
2023-11-05 11:48:11,381:INFO:SubProcess create_model() called ==================================
2023-11-05 11:48:11,382:INFO:Initializing create_model()
2023-11-05 11:48:11,382:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BA0894DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:48:11,382:INFO:Checking exceptions
2023-11-05 11:48:11,382:INFO:Importing libraries
2023-11-05 11:48:11,382:INFO:Copying training dataset
2023-11-05 11:48:11,386:INFO:Defining folds
2023-11-05 11:48:11,387:INFO:Declaring metric variables
2023-11-05 11:48:11,389:INFO:Importing untrained model
2023-11-05 11:48:11,393:INFO:Ridge Classifier Imported successfully
2023-11-05 11:48:11,399:INFO:Starting cross validation
2023-11-05 11:48:11,399:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:48:11,429:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.77216e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:48:11,430:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.65142e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:48:11,432:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.50996e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:48:11,432:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.68392e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:48:11,437:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.86427e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:48:11,439:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:48:11,439:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.97939e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:48:11,440:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:48:11,440:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.96089e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:48:11,440:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:48:11,441:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:48:11,444:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:48:11,445:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:48:11,447:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.89142e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:48:11,448:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:48:11,449:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.7932e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:48:11,451:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.67359e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:48:11,454:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:48:11,456:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:48:11,457:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:48:11,469:INFO:Calculating mean and std
2023-11-05 11:48:11,470:INFO:Creating metrics dataframe
2023-11-05 11:48:11,473:INFO:Uploading results into container
2023-11-05 11:48:11,474:INFO:Uploading model into container now
2023-11-05 11:48:11,474:INFO:_master_model_container: 6
2023-11-05 11:48:11,474:INFO:_display_container: 2
2023-11-05 11:48:11,475:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-11-05 11:48:11,475:INFO:create_model() successfully completed......................................
2023-11-05 11:48:11,540:INFO:SubProcess create_model() end ==================================
2023-11-05 11:48:11,540:INFO:Creating metrics dataframe
2023-11-05 11:48:11,552:INFO:Initializing Random Forest Classifier
2023-11-05 11:48:11,552:INFO:Total runtime is 0.11883333524068197 minutes
2023-11-05 11:48:11,555:INFO:SubProcess create_model() called ==================================
2023-11-05 11:48:11,555:INFO:Initializing create_model()
2023-11-05 11:48:11,555:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BA0894DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:48:11,556:INFO:Checking exceptions
2023-11-05 11:48:11,556:INFO:Importing libraries
2023-11-05 11:48:11,556:INFO:Copying training dataset
2023-11-05 11:48:11,560:INFO:Defining folds
2023-11-05 11:48:11,560:INFO:Declaring metric variables
2023-11-05 11:48:11,563:INFO:Importing untrained model
2023-11-05 11:48:11,567:INFO:Random Forest Classifier Imported successfully
2023-11-05 11:48:11,573:INFO:Starting cross validation
2023-11-05 11:48:11,574:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:48:13,031:INFO:Calculating mean and std
2023-11-05 11:48:13,032:INFO:Creating metrics dataframe
2023-11-05 11:48:13,036:INFO:Uploading results into container
2023-11-05 11:48:13,037:INFO:Uploading model into container now
2023-11-05 11:48:13,037:INFO:_master_model_container: 7
2023-11-05 11:48:13,037:INFO:_display_container: 2
2023-11-05 11:48:13,038:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-11-05 11:48:13,038:INFO:create_model() successfully completed......................................
2023-11-05 11:48:13,103:INFO:SubProcess create_model() end ==================================
2023-11-05 11:48:13,104:INFO:Creating metrics dataframe
2023-11-05 11:48:13,114:INFO:Initializing Quadratic Discriminant Analysis
2023-11-05 11:48:13,114:INFO:Total runtime is 0.14486668904622396 minutes
2023-11-05 11:48:13,117:INFO:SubProcess create_model() called ==================================
2023-11-05 11:48:13,117:INFO:Initializing create_model()
2023-11-05 11:48:13,117:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BA0894DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:48:13,117:INFO:Checking exceptions
2023-11-05 11:48:13,118:INFO:Importing libraries
2023-11-05 11:48:13,118:INFO:Copying training dataset
2023-11-05 11:48:13,122:INFO:Defining folds
2023-11-05 11:48:13,122:INFO:Declaring metric variables
2023-11-05 11:48:13,125:INFO:Importing untrained model
2023-11-05 11:48:13,128:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-05 11:48:13,134:INFO:Starting cross validation
2023-11-05 11:48:13,135:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:48:13,165:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:48:13,166:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:48:13,169:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:48:13,172:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:48:13,173:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,173:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,173:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-11-05 11:48:13,175:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,176:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,176:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,176:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,176:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-11-05 11:48:13,176:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-11-05 11:48:13,176:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:48:13,177:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,178:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,178:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-11-05 11:48:13,179:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,179:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,179:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-11-05 11:48:13,179:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-11-05 11:48:13,180:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,180:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,181:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-11-05 11:48:13,182:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,182:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,182:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:48:13,182:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-11-05 11:48:13,184:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-11-05 11:48:13,184:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,184:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-11-05 11:48:13,184:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,184:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,185:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-11-05 11:48:13,185:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:48:13,185:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:48:13,186:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,186:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,186:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-11-05 11:48:13,186:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-11-05 11:48:13,186:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,186:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,187:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-11-05 11:48:13,188:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-11-05 11:48:13,189:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,189:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,189:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-11-05 11:48:13,189:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-11-05 11:48:13,191:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:48:13,192:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,192:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,192:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,192:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-11-05 11:48:13,192:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,193:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-11-05 11:48:13,194:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,194:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,195:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-11-05 11:48:13,195:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-11-05 11:48:13,196:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,196:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,196:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-11-05 11:48:13,196:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,196:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,196:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-11-05 11:48:13,197:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,197:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,197:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-11-05 11:48:13,200:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-11-05 11:48:13,200:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-11-05 11:48:13,200:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-11-05 11:48:13,200:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,200:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,201:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-11-05 11:48:13,204:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,204:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-11-05 11:48:13,204:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-11-05 11:48:13,206:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 87, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-11-05 11:48:13,222:INFO:Calculating mean and std
2023-11-05 11:48:13,223:INFO:Creating metrics dataframe
2023-11-05 11:48:13,226:INFO:Uploading results into container
2023-11-05 11:48:13,227:INFO:Uploading model into container now
2023-11-05 11:48:13,227:INFO:_master_model_container: 8
2023-11-05 11:48:13,227:INFO:_display_container: 2
2023-11-05 11:48:13,227:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-05 11:48:13,228:INFO:create_model() successfully completed......................................
2023-11-05 11:48:13,293:INFO:SubProcess create_model() end ==================================
2023-11-05 11:48:13,293:INFO:Creating metrics dataframe
2023-11-05 11:48:13,304:INFO:Initializing Ada Boost Classifier
2023-11-05 11:48:13,304:INFO:Total runtime is 0.1480333129564921 minutes
2023-11-05 11:48:13,307:INFO:SubProcess create_model() called ==================================
2023-11-05 11:48:13,307:INFO:Initializing create_model()
2023-11-05 11:48:13,307:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BA0894DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:48:13,307:INFO:Checking exceptions
2023-11-05 11:48:13,307:INFO:Importing libraries
2023-11-05 11:48:13,307:INFO:Copying training dataset
2023-11-05 11:48:13,312:INFO:Defining folds
2023-11-05 11:48:13,312:INFO:Declaring metric variables
2023-11-05 11:48:13,315:INFO:Importing untrained model
2023-11-05 11:48:13,318:INFO:Ada Boost Classifier Imported successfully
2023-11-05 11:48:13,323:INFO:Starting cross validation
2023-11-05 11:48:13,324:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:48:14,002:INFO:Calculating mean and std
2023-11-05 11:48:14,003:INFO:Creating metrics dataframe
2023-11-05 11:48:14,007:INFO:Uploading results into container
2023-11-05 11:48:14,008:INFO:Uploading model into container now
2023-11-05 11:48:14,008:INFO:_master_model_container: 9
2023-11-05 11:48:14,008:INFO:_display_container: 2
2023-11-05 11:48:14,008:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-11-05 11:48:14,009:INFO:create_model() successfully completed......................................
2023-11-05 11:48:14,075:INFO:SubProcess create_model() end ==================================
2023-11-05 11:48:14,075:INFO:Creating metrics dataframe
2023-11-05 11:48:14,086:INFO:Initializing Gradient Boosting Classifier
2023-11-05 11:48:14,086:INFO:Total runtime is 0.16106665929158528 minutes
2023-11-05 11:48:14,089:INFO:SubProcess create_model() called ==================================
2023-11-05 11:48:14,089:INFO:Initializing create_model()
2023-11-05 11:48:14,089:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BA0894DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:48:14,090:INFO:Checking exceptions
2023-11-05 11:48:14,090:INFO:Importing libraries
2023-11-05 11:48:14,090:INFO:Copying training dataset
2023-11-05 11:48:14,094:INFO:Defining folds
2023-11-05 11:48:14,094:INFO:Declaring metric variables
2023-11-05 11:48:14,097:INFO:Importing untrained model
2023-11-05 11:48:14,100:INFO:Gradient Boosting Classifier Imported successfully
2023-11-05 11:48:14,105:INFO:Starting cross validation
2023-11-05 11:48:14,106:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:48:16,658:INFO:Calculating mean and std
2023-11-05 11:48:16,659:INFO:Creating metrics dataframe
2023-11-05 11:48:16,663:INFO:Uploading results into container
2023-11-05 11:48:16,663:INFO:Uploading model into container now
2023-11-05 11:48:16,664:INFO:_master_model_container: 10
2023-11-05 11:48:16,664:INFO:_display_container: 2
2023-11-05 11:48:16,665:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-11-05 11:48:16,665:INFO:create_model() successfully completed......................................
2023-11-05 11:48:16,744:INFO:SubProcess create_model() end ==================================
2023-11-05 11:48:16,744:INFO:Creating metrics dataframe
2023-11-05 11:48:16,757:INFO:Initializing Linear Discriminant Analysis
2023-11-05 11:48:16,757:INFO:Total runtime is 0.20558332999547324 minutes
2023-11-05 11:48:16,760:INFO:SubProcess create_model() called ==================================
2023-11-05 11:48:16,761:INFO:Initializing create_model()
2023-11-05 11:48:16,761:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BA0894DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:48:16,761:INFO:Checking exceptions
2023-11-05 11:48:16,761:INFO:Importing libraries
2023-11-05 11:48:16,761:INFO:Copying training dataset
2023-11-05 11:48:16,767:INFO:Defining folds
2023-11-05 11:48:16,767:INFO:Declaring metric variables
2023-11-05 11:48:16,771:INFO:Importing untrained model
2023-11-05 11:48:16,776:INFO:Linear Discriminant Analysis Imported successfully
2023-11-05 11:48:16,786:INFO:Starting cross validation
2023-11-05 11:48:16,787:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:48:16,881:INFO:Calculating mean and std
2023-11-05 11:48:16,882:INFO:Creating metrics dataframe
2023-11-05 11:48:16,886:INFO:Uploading results into container
2023-11-05 11:48:16,886:INFO:Uploading model into container now
2023-11-05 11:48:16,886:INFO:_master_model_container: 11
2023-11-05 11:48:16,886:INFO:_display_container: 2
2023-11-05 11:48:16,887:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-05 11:48:16,887:INFO:create_model() successfully completed......................................
2023-11-05 11:48:16,956:INFO:SubProcess create_model() end ==================================
2023-11-05 11:48:16,957:INFO:Creating metrics dataframe
2023-11-05 11:48:16,970:INFO:Initializing Extra Trees Classifier
2023-11-05 11:48:16,970:INFO:Total runtime is 0.20913334687550864 minutes
2023-11-05 11:48:16,973:INFO:SubProcess create_model() called ==================================
2023-11-05 11:48:16,974:INFO:Initializing create_model()
2023-11-05 11:48:16,974:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BA0894DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:48:16,974:INFO:Checking exceptions
2023-11-05 11:48:16,974:INFO:Importing libraries
2023-11-05 11:48:16,974:INFO:Copying training dataset
2023-11-05 11:48:16,979:INFO:Defining folds
2023-11-05 11:48:16,979:INFO:Declaring metric variables
2023-11-05 11:48:16,982:INFO:Importing untrained model
2023-11-05 11:48:16,986:INFO:Extra Trees Classifier Imported successfully
2023-11-05 11:48:16,993:INFO:Starting cross validation
2023-11-05 11:48:16,994:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:48:17,813:INFO:Calculating mean and std
2023-11-05 11:48:17,813:INFO:Creating metrics dataframe
2023-11-05 11:48:17,817:INFO:Uploading results into container
2023-11-05 11:48:17,818:INFO:Uploading model into container now
2023-11-05 11:48:17,818:INFO:_master_model_container: 12
2023-11-05 11:48:17,818:INFO:_display_container: 2
2023-11-05 11:48:17,819:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-11-05 11:48:17,819:INFO:create_model() successfully completed......................................
2023-11-05 11:48:17,886:INFO:SubProcess create_model() end ==================================
2023-11-05 11:48:17,886:INFO:Creating metrics dataframe
2023-11-05 11:48:17,898:INFO:Initializing Extreme Gradient Boosting
2023-11-05 11:48:17,898:INFO:Total runtime is 0.2246000091234843 minutes
2023-11-05 11:48:17,901:INFO:SubProcess create_model() called ==================================
2023-11-05 11:48:17,902:INFO:Initializing create_model()
2023-11-05 11:48:17,902:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BA0894DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:48:17,902:INFO:Checking exceptions
2023-11-05 11:48:17,902:INFO:Importing libraries
2023-11-05 11:48:17,902:INFO:Copying training dataset
2023-11-05 11:48:17,906:INFO:Defining folds
2023-11-05 11:48:17,907:INFO:Declaring metric variables
2023-11-05 11:48:17,909:INFO:Importing untrained model
2023-11-05 11:48:17,913:INFO:Extreme Gradient Boosting Imported successfully
2023-11-05 11:48:17,920:INFO:Starting cross validation
2023-11-05 11:48:17,921:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:48:18,492:INFO:Calculating mean and std
2023-11-05 11:48:18,493:INFO:Creating metrics dataframe
2023-11-05 11:48:18,497:INFO:Uploading results into container
2023-11-05 11:48:18,498:INFO:Uploading model into container now
2023-11-05 11:48:18,498:INFO:_master_model_container: 13
2023-11-05 11:48:18,498:INFO:_display_container: 2
2023-11-05 11:48:18,499:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2023-11-05 11:48:18,499:INFO:create_model() successfully completed......................................
2023-11-05 11:48:18,564:INFO:SubProcess create_model() end ==================================
2023-11-05 11:48:18,564:INFO:Creating metrics dataframe
2023-11-05 11:48:18,577:INFO:Initializing Light Gradient Boosting Machine
2023-11-05 11:48:18,577:INFO:Total runtime is 0.2359167218208313 minutes
2023-11-05 11:48:18,580:INFO:SubProcess create_model() called ==================================
2023-11-05 11:48:18,581:INFO:Initializing create_model()
2023-11-05 11:48:18,581:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BA0894DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:48:18,581:INFO:Checking exceptions
2023-11-05 11:48:18,581:INFO:Importing libraries
2023-11-05 11:48:18,581:INFO:Copying training dataset
2023-11-05 11:48:18,586:INFO:Defining folds
2023-11-05 11:48:18,586:INFO:Declaring metric variables
2023-11-05 11:48:18,589:INFO:Importing untrained model
2023-11-05 11:48:18,592:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-05 11:48:18,599:INFO:Starting cross validation
2023-11-05 11:48:18,599:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:48:19,638:INFO:Calculating mean and std
2023-11-05 11:48:19,639:INFO:Creating metrics dataframe
2023-11-05 11:48:19,644:INFO:Uploading results into container
2023-11-05 11:48:19,644:INFO:Uploading model into container now
2023-11-05 11:48:19,645:INFO:_master_model_container: 14
2023-11-05 11:48:19,645:INFO:_display_container: 2
2023-11-05 11:48:19,645:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 11:48:19,646:INFO:create_model() successfully completed......................................
2023-11-05 11:48:19,724:INFO:SubProcess create_model() end ==================================
2023-11-05 11:48:19,724:INFO:Creating metrics dataframe
2023-11-05 11:48:19,738:INFO:Initializing Dummy Classifier
2023-11-05 11:48:19,738:INFO:Total runtime is 0.2552666783332825 minutes
2023-11-05 11:48:19,741:INFO:SubProcess create_model() called ==================================
2023-11-05 11:48:19,742:INFO:Initializing create_model()
2023-11-05 11:48:19,742:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BA0894DC0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:48:19,742:INFO:Checking exceptions
2023-11-05 11:48:19,742:INFO:Importing libraries
2023-11-05 11:48:19,742:INFO:Copying training dataset
2023-11-05 11:48:19,750:INFO:Defining folds
2023-11-05 11:48:19,750:INFO:Declaring metric variables
2023-11-05 11:48:19,754:INFO:Importing untrained model
2023-11-05 11:48:19,759:INFO:Dummy Classifier Imported successfully
2023-11-05 11:48:19,765:INFO:Starting cross validation
2023-11-05 11:48:19,766:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:48:19,802:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:48:19,803:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:48:19,804:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:48:19,805:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:48:19,806:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:48:19,807:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:48:19,809:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:48:19,811:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:48:19,817:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:48:19,820:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:48:19,830:INFO:Calculating mean and std
2023-11-05 11:48:19,830:INFO:Creating metrics dataframe
2023-11-05 11:48:19,833:INFO:Uploading results into container
2023-11-05 11:48:19,834:INFO:Uploading model into container now
2023-11-05 11:48:19,834:INFO:_master_model_container: 15
2023-11-05 11:48:19,834:INFO:_display_container: 2
2023-11-05 11:48:19,834:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-11-05 11:48:19,834:INFO:create_model() successfully completed......................................
2023-11-05 11:48:19,898:INFO:SubProcess create_model() end ==================================
2023-11-05 11:48:19,898:INFO:Creating metrics dataframe
2023-11-05 11:48:19,921:INFO:Initializing create_model()
2023-11-05 11:48:19,921:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:48:19,921:INFO:Checking exceptions
2023-11-05 11:48:19,922:INFO:Importing libraries
2023-11-05 11:48:19,923:INFO:Copying training dataset
2023-11-05 11:48:19,926:INFO:Defining folds
2023-11-05 11:48:19,927:INFO:Declaring metric variables
2023-11-05 11:48:19,927:INFO:Importing untrained model
2023-11-05 11:48:19,927:INFO:Declaring custom model
2023-11-05 11:48:19,927:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-05 11:48:19,928:INFO:Cross validation set to False
2023-11-05 11:48:19,928:INFO:Fitting Model
2023-11-05 11:48:19,942:INFO:[LightGBM] [Info] Number of positive: 1603, number of negative: 5397
2023-11-05 11:48:19,944:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001417 seconds.
2023-11-05 11:48:19,945:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-05 11:48:19,945:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-05 11:48:19,945:INFO:[LightGBM] [Info] Number of data points in the train set: 7000, number of used features: 19
2023-11-05 11:48:19,945:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.229000 -> initscore=-1.213966
2023-11-05 11:48:19,945:INFO:[LightGBM] [Info] Start training from score -1.213966
2023-11-05 11:48:20,063:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 11:48:20,063:INFO:create_model() successfully completed......................................
2023-11-05 11:48:20,173:INFO:_master_model_container: 15
2023-11-05 11:48:20,173:INFO:_display_container: 2
2023-11-05 11:48:20,173:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 11:48:20,174:INFO:compare_models() successfully completed......................................
2023-11-05 11:48:20,205:INFO:Initializing create_model()
2023-11-05 11:48:20,205:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>, estimator=xgboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:48:20,205:INFO:Checking exceptions
2023-11-05 11:48:20,220:INFO:Importing libraries
2023-11-05 11:48:20,220:INFO:Copying training dataset
2023-11-05 11:48:20,226:INFO:Defining folds
2023-11-05 11:48:20,226:INFO:Declaring metric variables
2023-11-05 11:48:20,229:INFO:Importing untrained model
2023-11-05 11:48:20,233:INFO:Extreme Gradient Boosting Imported successfully
2023-11-05 11:48:20,239:INFO:Starting cross validation
2023-11-05 11:48:20,240:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:48:20,993:INFO:Calculating mean and std
2023-11-05 11:48:20,994:INFO:Creating metrics dataframe
2023-11-05 11:48:21,000:INFO:Finalizing model
2023-11-05 11:48:21,175:INFO:Uploading results into container
2023-11-05 11:48:21,176:INFO:Uploading model into container now
2023-11-05 11:48:21,188:INFO:_master_model_container: 16
2023-11-05 11:48:21,188:INFO:_display_container: 3
2023-11-05 11:48:21,189:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2023-11-05 11:48:21,189:INFO:create_model() successfully completed......................................
2023-11-05 11:48:21,298:INFO:Initializing predict_model()
2023-11-05 11:48:21,298:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022B945619D0>)
2023-11-05 11:48:21,298:INFO:Checking exceptions
2023-11-05 11:48:21,298:INFO:Preloading libraries
2023-11-05 11:48:21,473:INFO:Initializing evaluate_model()
2023-11-05 11:48:21,473:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-11-05 11:48:21,485:INFO:Initializing plot_model()
2023-11-05 11:48:21,485:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>, system=True)
2023-11-05 11:48:21,485:INFO:Checking exceptions
2023-11-05 11:48:21,488:INFO:Preloading libraries
2023-11-05 11:48:21,495:INFO:Copying training dataset
2023-11-05 11:48:21,495:INFO:Plot type: pipeline
2023-11-05 11:48:21,634:INFO:Visual Rendered Successfully
2023-11-05 11:48:21,702:INFO:plot_model() successfully completed......................................
2023-11-05 11:48:21,745:INFO:Initializing interpret_model()
2023-11-05 11:48:21,746:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=feature_importance, kwargs={'n_select': 30}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>)
2023-11-05 11:48:21,746:INFO:Checking exceptions
2023-11-05 11:48:21,746:INFO:Soft dependency imported: shap: 0.43.0
2023-11-05 11:48:22,117:INFO:plot type: summary
2023-11-05 11:48:22,117:INFO:Creating TreeExplainer
2023-11-05 11:48:22,239:INFO:Compiling shap values
2023-11-05 11:48:43,056:INFO:Initializing interpret_model()
2023-11-05 11:48:43,056:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=feature_importance, kwargs={'n_select': 30}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>)
2023-11-05 11:48:43,056:INFO:Checking exceptions
2023-11-05 11:48:43,056:INFO:Soft dependency imported: shap: 0.43.0
2023-11-05 11:48:43,075:INFO:plot type: summary
2023-11-05 11:48:43,075:INFO:Creating TreeExplainer
2023-11-05 11:48:43,206:INFO:Compiling shap values
2023-11-05 11:48:52,256:INFO:Initializing interpret_model()
2023-11-05 11:48:52,256:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=feature_importance, kwargs={'n_select': 10}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>)
2023-11-05 11:48:52,256:INFO:Checking exceptions
2023-11-05 11:48:52,257:INFO:Soft dependency imported: shap: 0.43.0
2023-11-05 11:48:52,276:INFO:plot type: summary
2023-11-05 11:48:52,276:INFO:Creating TreeExplainer
2023-11-05 11:48:52,410:INFO:Compiling shap values
2023-11-05 11:48:59,633:INFO:Initializing interpret_model()
2023-11-05 11:48:59,633:INFO:interpret_model(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=feature_importance, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>)
2023-11-05 11:48:59,633:INFO:Checking exceptions
2023-11-05 11:48:59,633:INFO:Soft dependency imported: shap: 0.43.0
2023-11-05 11:48:59,651:INFO:plot type: summary
2023-11-05 11:48:59,652:INFO:Creating TreeExplainer
2023-11-05 11:48:59,778:INFO:Compiling shap values
2023-11-05 11:49:00,830:INFO:Visual Rendered Successfully
2023-11-05 11:49:00,830:INFO:interpret_model() successfully completed......................................
2023-11-05 11:49:07,612:INFO:Initializing plot_model()
2023-11-05 11:49:07,612:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>, system=True)
2023-11-05 11:49:07,612:INFO:Checking exceptions
2023-11-05 11:49:07,616:INFO:Preloading libraries
2023-11-05 11:49:07,624:INFO:Copying training dataset
2023-11-05 11:49:07,624:INFO:Plot type: feature
2023-11-05 11:49:07,625:WARNING:No coef_ found. Trying feature_importances_
2023-11-05 11:49:07,820:INFO:Visual Rendered Successfully
2023-11-05 11:49:07,919:INFO:plot_model() successfully completed......................................
2023-11-05 11:50:12,648:INFO:Initializing plot_model()
2023-11-05 11:50:12,648:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B9457F1C0>, system=True)
2023-11-05 11:50:12,648:INFO:Checking exceptions
2023-11-05 11:50:12,653:INFO:Preloading libraries
2023-11-05 11:50:12,659:INFO:Copying training dataset
2023-11-05 11:50:12,659:INFO:Plot type: feature
2023-11-05 11:50:12,659:WARNING:No coef_ found. Trying feature_importances_
2023-11-05 11:50:12,858:INFO:Visual Rendered Successfully
2023-11-05 11:50:12,954:INFO:plot_model() successfully completed......................................
2023-11-05 11:51:00,470:INFO:PyCaret ClassificationExperiment
2023-11-05 11:51:00,470:INFO:Logging name: clf-default-name
2023-11-05 11:51:00,470:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-05 11:51:00,470:INFO:version 3.1.0
2023-11-05 11:51:00,470:INFO:Initializing setup()
2023-11-05 11:51:00,470:INFO:self.USI: bf84
2023-11-05 11:51:00,470:INFO:self._variable_keys: {'logging_param', 'y_test', 'gpu_param', 'y', 'n_jobs_param', 'memory', 'gpu_n_jobs_param', 'html_param', 'seed', 'data', 'X', 'fix_imbalance', 'USI', 'log_plots_param', 'fold_groups_param', 'fold_generator', '_ml_usecase', 'exp_id', 'is_multiclass', '_available_plots', 'X_train', 'exp_name_log', 'fold_shuffle_param', 'X_test', 'pipeline', 'target_param', 'idx', 'y_train'}
2023-11-05 11:51:00,470:INFO:Checking environment
2023-11-05 11:51:00,470:INFO:python_version: 3.9.18
2023-11-05 11:51:00,470:INFO:python_build: ('main', 'Sep 11 2023 14:09:26')
2023-11-05 11:51:00,470:INFO:machine: AMD64
2023-11-05 11:51:00,470:INFO:platform: Windows-10-10.0.19041-SP0
2023-11-05 11:51:00,470:INFO:Memory: svmem(total=25692647424, available=13596672000, percent=47.1, used=12095975424, free=13596672000)
2023-11-05 11:51:00,470:INFO:Physical Core: 8
2023-11-05 11:51:00,470:INFO:Logical Core: 16
2023-11-05 11:51:00,470:INFO:Checking libraries
2023-11-05 11:51:00,471:INFO:System:
2023-11-05 11:51:00,471:INFO:    python: 3.9.18 (main, Sep 11 2023, 14:09:26) [MSC v.1916 64 bit (AMD64)]
2023-11-05 11:51:00,471:INFO:executable: d:\programas\Anaconda3\envs\meli_test2\python.exe
2023-11-05 11:51:00,471:INFO:   machine: Windows-10-10.0.19041-SP0
2023-11-05 11:51:00,471:INFO:PyCaret required dependencies:
2023-11-05 11:51:00,471:INFO:                 pip: 23.3
2023-11-05 11:51:00,471:INFO:          setuptools: 68.0.0
2023-11-05 11:51:00,471:INFO:             pycaret: 3.1.0
2023-11-05 11:51:00,471:INFO:             IPython: 8.17.2
2023-11-05 11:51:00,471:INFO:          ipywidgets: 8.1.1
2023-11-05 11:51:00,471:INFO:                tqdm: 4.66.1
2023-11-05 11:51:00,471:INFO:               numpy: 1.23.5
2023-11-05 11:51:00,471:INFO:              pandas: 1.5.3
2023-11-05 11:51:00,471:INFO:              jinja2: 3.1.2
2023-11-05 11:51:00,471:INFO:               scipy: 1.10.1
2023-11-05 11:51:00,471:INFO:              joblib: 1.3.2
2023-11-05 11:51:00,471:INFO:             sklearn: 1.2.2
2023-11-05 11:51:00,471:INFO:                pyod: 1.1.1
2023-11-05 11:51:00,471:INFO:            imblearn: 0.11.0
2023-11-05 11:51:00,471:INFO:   category_encoders: 2.6.3
2023-11-05 11:51:00,471:INFO:            lightgbm: 4.1.0
2023-11-05 11:51:00,471:INFO:               numba: 0.58.1
2023-11-05 11:51:00,472:INFO:            requests: 2.31.0
2023-11-05 11:51:00,472:INFO:          matplotlib: 3.8.1
2023-11-05 11:51:00,472:INFO:          scikitplot: 0.3.7
2023-11-05 11:51:00,472:INFO:         yellowbrick: 1.5
2023-11-05 11:51:00,472:INFO:              plotly: 5.18.0
2023-11-05 11:51:00,472:INFO:    plotly-resampler: Not installed
2023-11-05 11:51:00,472:INFO:             kaleido: 0.2.1
2023-11-05 11:51:00,472:INFO:           schemdraw: 0.15
2023-11-05 11:51:00,472:INFO:         statsmodels: 0.14.0
2023-11-05 11:51:00,472:INFO:              sktime: 0.21.1
2023-11-05 11:51:00,472:INFO:               tbats: 1.1.3
2023-11-05 11:51:00,472:INFO:            pmdarima: 2.0.4
2023-11-05 11:51:00,472:INFO:              psutil: 5.9.6
2023-11-05 11:51:00,472:INFO:          markupsafe: 2.1.3
2023-11-05 11:51:00,472:INFO:             pickle5: Not installed
2023-11-05 11:51:00,472:INFO:         cloudpickle: 3.0.0
2023-11-05 11:51:00,472:INFO:         deprecation: 2.1.0
2023-11-05 11:51:00,473:INFO:              xxhash: 3.4.1
2023-11-05 11:51:00,473:INFO:           wurlitzer: Not installed
2023-11-05 11:51:00,473:INFO:PyCaret optional dependencies:
2023-11-05 11:51:00,473:INFO:                shap: 0.43.0
2023-11-05 11:51:00,473:INFO:           interpret: Not installed
2023-11-05 11:51:00,473:INFO:                umap: Not installed
2023-11-05 11:51:00,473:INFO:     ydata_profiling: Not installed
2023-11-05 11:51:00,473:INFO:  explainerdashboard: Not installed
2023-11-05 11:51:00,473:INFO:             autoviz: Not installed
2023-11-05 11:51:00,473:INFO:           fairlearn: Not installed
2023-11-05 11:51:00,473:INFO:          deepchecks: Not installed
2023-11-05 11:51:00,473:INFO:             xgboost: 2.0.1
2023-11-05 11:51:00,473:INFO:            catboost: Not installed
2023-11-05 11:51:00,473:INFO:              kmodes: Not installed
2023-11-05 11:51:00,473:INFO:             mlxtend: Not installed
2023-11-05 11:51:00,473:INFO:       statsforecast: Not installed
2023-11-05 11:51:00,473:INFO:        tune_sklearn: Not installed
2023-11-05 11:51:00,473:INFO:                 ray: Not installed
2023-11-05 11:51:00,473:INFO:            hyperopt: Not installed
2023-11-05 11:51:00,473:INFO:              optuna: Not installed
2023-11-05 11:51:00,473:INFO:               skopt: Not installed
2023-11-05 11:51:00,473:INFO:              mlflow: Not installed
2023-11-05 11:51:00,473:INFO:              gradio: Not installed
2023-11-05 11:51:00,474:INFO:             fastapi: Not installed
2023-11-05 11:51:00,474:INFO:             uvicorn: Not installed
2023-11-05 11:51:00,474:INFO:              m2cgen: Not installed
2023-11-05 11:51:00,474:INFO:           evidently: Not installed
2023-11-05 11:51:00,474:INFO:               fugue: Not installed
2023-11-05 11:51:00,474:INFO:           streamlit: Not installed
2023-11-05 11:51:00,474:INFO:             prophet: Not installed
2023-11-05 11:51:00,474:INFO:None
2023-11-05 11:51:00,474:INFO:Set up data.
2023-11-05 11:51:00,557:INFO:Set up folding strategy.
2023-11-05 11:51:00,557:INFO:Set up train/test split.
2023-11-05 11:51:00,644:INFO:Set up index.
2023-11-05 11:51:00,648:INFO:Assigning column types.
2023-11-05 11:51:00,680:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-05 11:51:00,734:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-05 11:51:00,735:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 11:51:00,769:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:51:00,772:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:51:00,825:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-05 11:51:00,826:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 11:51:00,861:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:51:00,864:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:51:00,865:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-05 11:51:00,919:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 11:51:00,953:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:51:00,957:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:51:01,012:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 11:51:01,047:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:51:01,050:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:51:01,050:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-05 11:51:01,139:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:51:01,142:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:51:01,230:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:51:01,234:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:51:01,235:INFO:Preparing preprocessing pipeline...
2023-11-05 11:51:01,240:INFO:Set up simple imputation.
2023-11-05 11:51:01,331:INFO:Finished creating preprocessing pipeline.
2023-11-05 11:51:01,334:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['a', 'b', 'c', 'd', 'e', 'f', 'h',
                                             'k', 'l', 'm', 'n', 'p', 'monto',
                                             'score', 'Country_AR',
                                             'Country_BR', 'Country_US',
                                             'Country_UY', 'Country_otros'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-05 11:51:01,334:INFO:Creating final display dataframe.
2023-11-05 11:51:01,576:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            fraude
2                   Target type            Binary
3           Original data shape      (181519, 20)
4        Transformed data shape      (181519, 20)
5   Transformed train set shape      (127063, 20)
6    Transformed test set shape       (54456, 20)
7              Numeric features                19
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              bf84
2023-11-05 11:51:01,684:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:51:01,687:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:51:01,785:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:51:01,789:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:51:01,789:INFO:setup() successfully completed in 1.32s...............
2023-11-05 11:51:06,719:INFO:PyCaret ClassificationExperiment
2023-11-05 11:51:06,719:INFO:Logging name: clf-default-name
2023-11-05 11:51:06,719:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-05 11:51:06,719:INFO:version 3.1.0
2023-11-05 11:51:06,719:INFO:Initializing setup()
2023-11-05 11:51:06,720:INFO:self.USI: e54c
2023-11-05 11:51:06,720:INFO:self._variable_keys: {'logging_param', 'y_test', 'gpu_param', 'y', 'n_jobs_param', 'memory', 'gpu_n_jobs_param', 'html_param', 'seed', 'data', 'X', 'fix_imbalance', 'USI', 'log_plots_param', 'fold_groups_param', 'fold_generator', '_ml_usecase', 'exp_id', 'is_multiclass', '_available_plots', 'X_train', 'exp_name_log', 'fold_shuffle_param', 'X_test', 'pipeline', 'target_param', 'idx', 'y_train'}
2023-11-05 11:51:06,720:INFO:Checking environment
2023-11-05 11:51:06,720:INFO:python_version: 3.9.18
2023-11-05 11:51:06,720:INFO:python_build: ('main', 'Sep 11 2023 14:09:26')
2023-11-05 11:51:06,720:INFO:machine: AMD64
2023-11-05 11:51:06,720:INFO:platform: Windows-10-10.0.19041-SP0
2023-11-05 11:51:06,720:INFO:Memory: svmem(total=25692647424, available=13522358272, percent=47.4, used=12170289152, free=13522358272)
2023-11-05 11:51:06,720:INFO:Physical Core: 8
2023-11-05 11:51:06,720:INFO:Logical Core: 16
2023-11-05 11:51:06,720:INFO:Checking libraries
2023-11-05 11:51:06,720:INFO:System:
2023-11-05 11:51:06,720:INFO:    python: 3.9.18 (main, Sep 11 2023, 14:09:26) [MSC v.1916 64 bit (AMD64)]
2023-11-05 11:51:06,720:INFO:executable: d:\programas\Anaconda3\envs\meli_test2\python.exe
2023-11-05 11:51:06,720:INFO:   machine: Windows-10-10.0.19041-SP0
2023-11-05 11:51:06,720:INFO:PyCaret required dependencies:
2023-11-05 11:51:06,720:INFO:                 pip: 23.3
2023-11-05 11:51:06,720:INFO:          setuptools: 68.0.0
2023-11-05 11:51:06,720:INFO:             pycaret: 3.1.0
2023-11-05 11:51:06,720:INFO:             IPython: 8.17.2
2023-11-05 11:51:06,720:INFO:          ipywidgets: 8.1.1
2023-11-05 11:51:06,721:INFO:                tqdm: 4.66.1
2023-11-05 11:51:06,721:INFO:               numpy: 1.23.5
2023-11-05 11:51:06,721:INFO:              pandas: 1.5.3
2023-11-05 11:51:06,721:INFO:              jinja2: 3.1.2
2023-11-05 11:51:06,721:INFO:               scipy: 1.10.1
2023-11-05 11:51:06,721:INFO:              joblib: 1.3.2
2023-11-05 11:51:06,721:INFO:             sklearn: 1.2.2
2023-11-05 11:51:06,721:INFO:                pyod: 1.1.1
2023-11-05 11:51:06,721:INFO:            imblearn: 0.11.0
2023-11-05 11:51:06,721:INFO:   category_encoders: 2.6.3
2023-11-05 11:51:06,721:INFO:            lightgbm: 4.1.0
2023-11-05 11:51:06,721:INFO:               numba: 0.58.1
2023-11-05 11:51:06,721:INFO:            requests: 2.31.0
2023-11-05 11:51:06,721:INFO:          matplotlib: 3.8.1
2023-11-05 11:51:06,721:INFO:          scikitplot: 0.3.7
2023-11-05 11:51:06,721:INFO:         yellowbrick: 1.5
2023-11-05 11:51:06,721:INFO:              plotly: 5.18.0
2023-11-05 11:51:06,721:INFO:    plotly-resampler: Not installed
2023-11-05 11:51:06,721:INFO:             kaleido: 0.2.1
2023-11-05 11:51:06,721:INFO:           schemdraw: 0.15
2023-11-05 11:51:06,721:INFO:         statsmodels: 0.14.0
2023-11-05 11:51:06,721:INFO:              sktime: 0.21.1
2023-11-05 11:51:06,721:INFO:               tbats: 1.1.3
2023-11-05 11:51:06,721:INFO:            pmdarima: 2.0.4
2023-11-05 11:51:06,721:INFO:              psutil: 5.9.6
2023-11-05 11:51:06,722:INFO:          markupsafe: 2.1.3
2023-11-05 11:51:06,722:INFO:             pickle5: Not installed
2023-11-05 11:51:06,722:INFO:         cloudpickle: 3.0.0
2023-11-05 11:51:06,722:INFO:         deprecation: 2.1.0
2023-11-05 11:51:06,722:INFO:              xxhash: 3.4.1
2023-11-05 11:51:06,722:INFO:           wurlitzer: Not installed
2023-11-05 11:51:06,722:INFO:PyCaret optional dependencies:
2023-11-05 11:51:06,722:INFO:                shap: 0.43.0
2023-11-05 11:51:06,722:INFO:           interpret: Not installed
2023-11-05 11:51:06,722:INFO:                umap: Not installed
2023-11-05 11:51:06,722:INFO:     ydata_profiling: Not installed
2023-11-05 11:51:06,722:INFO:  explainerdashboard: Not installed
2023-11-05 11:51:06,722:INFO:             autoviz: Not installed
2023-11-05 11:51:06,722:INFO:           fairlearn: Not installed
2023-11-05 11:51:06,722:INFO:          deepchecks: Not installed
2023-11-05 11:51:06,722:INFO:             xgboost: 2.0.1
2023-11-05 11:51:06,722:INFO:            catboost: Not installed
2023-11-05 11:51:06,722:INFO:              kmodes: Not installed
2023-11-05 11:51:06,722:INFO:             mlxtend: Not installed
2023-11-05 11:51:06,722:INFO:       statsforecast: Not installed
2023-11-05 11:51:06,722:INFO:        tune_sklearn: Not installed
2023-11-05 11:51:06,722:INFO:                 ray: Not installed
2023-11-05 11:51:06,722:INFO:            hyperopt: Not installed
2023-11-05 11:51:06,722:INFO:              optuna: Not installed
2023-11-05 11:51:06,723:INFO:               skopt: Not installed
2023-11-05 11:51:06,723:INFO:              mlflow: Not installed
2023-11-05 11:51:06,723:INFO:              gradio: Not installed
2023-11-05 11:51:06,723:INFO:             fastapi: Not installed
2023-11-05 11:51:06,723:INFO:             uvicorn: Not installed
2023-11-05 11:51:06,723:INFO:              m2cgen: Not installed
2023-11-05 11:51:06,723:INFO:           evidently: Not installed
2023-11-05 11:51:06,723:INFO:               fugue: Not installed
2023-11-05 11:51:06,723:INFO:           streamlit: Not installed
2023-11-05 11:51:06,723:INFO:             prophet: Not installed
2023-11-05 11:51:06,723:INFO:None
2023-11-05 11:51:06,723:INFO:Set up data.
2023-11-05 11:51:06,782:INFO:Set up folding strategy.
2023-11-05 11:51:06,782:INFO:Set up train/test split.
2023-11-05 11:51:06,859:INFO:Set up index.
2023-11-05 11:51:06,862:INFO:Assigning column types.
2023-11-05 11:51:06,891:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-05 11:51:06,945:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-05 11:51:06,946:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 11:51:06,980:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:51:06,983:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:51:07,037:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-05 11:51:07,038:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 11:51:07,071:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:51:07,075:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:51:07,075:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-05 11:51:07,129:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 11:51:07,163:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:51:07,166:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:51:07,221:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 11:51:07,253:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:51:07,256:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:51:07,256:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-05 11:51:07,340:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:51:07,343:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:51:07,428:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:51:07,434:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:51:07,435:INFO:Preparing preprocessing pipeline...
2023-11-05 11:51:07,440:INFO:Set up simple imputation.
2023-11-05 11:51:07,527:INFO:Finished creating preprocessing pipeline.
2023-11-05 11:51:07,531:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['a', 'b', 'c', 'd', 'e', 'f', 'h',
                                             'k', 'l', 'm', 'n', 'p', 'monto',
                                             'score', 'Country_AR',
                                             'Country_BR', 'Country_US',
                                             'Country_UY', 'Country_otros'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-05 11:51:07,531:INFO:Creating final display dataframe.
2023-11-05 11:51:07,769:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            fraude
2                   Target type            Binary
3           Original data shape      (181519, 20)
4        Transformed data shape      (181519, 20)
5   Transformed train set shape      (127063, 20)
6    Transformed test set shape       (54456, 20)
7              Numeric features                19
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              e54c
2023-11-05 11:51:07,885:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:51:07,889:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:51:07,987:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 11:51:07,990:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 11:51:07,991:INFO:setup() successfully completed in 1.27s...............
2023-11-05 11:51:30,162:INFO:Initializing compare_models()
2023-11-05 11:51:30,162:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BA2B2DDC0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022BA2B2DDC0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-11-05 11:51:30,162:INFO:Checking exceptions
2023-11-05 11:51:30,189:INFO:Preparing display monitor
2023-11-05 11:51:30,211:INFO:Initializing Logistic Regression
2023-11-05 11:51:30,211:INFO:Total runtime is 1.6689300537109375e-05 minutes
2023-11-05 11:51:30,214:INFO:SubProcess create_model() called ==================================
2023-11-05 11:51:30,215:INFO:Initializing create_model()
2023-11-05 11:51:30,215:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BA2B2DDC0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BCB17CEB0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:51:30,215:INFO:Checking exceptions
2023-11-05 11:51:30,215:INFO:Importing libraries
2023-11-05 11:51:30,215:INFO:Copying training dataset
2023-11-05 11:51:30,267:INFO:Defining folds
2023-11-05 11:51:30,268:INFO:Declaring metric variables
2023-11-05 11:51:30,271:INFO:Importing untrained model
2023-11-05 11:51:30,274:INFO:Logistic Regression Imported successfully
2023-11-05 11:51:30,280:INFO:Starting cross validation
2023-11-05 11:51:30,281:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:51:34,710:INFO:Calculating mean and std
2023-11-05 11:51:34,712:INFO:Creating metrics dataframe
2023-11-05 11:51:34,716:INFO:Uploading results into container
2023-11-05 11:51:34,717:INFO:Uploading model into container now
2023-11-05 11:51:34,718:INFO:_master_model_container: 1
2023-11-05 11:51:34,718:INFO:_display_container: 2
2023-11-05 11:51:34,719:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-05 11:51:34,719:INFO:create_model() successfully completed......................................
2023-11-05 11:51:34,818:INFO:SubProcess create_model() end ==================================
2023-11-05 11:51:34,818:INFO:Creating metrics dataframe
2023-11-05 11:51:34,826:INFO:Initializing K Neighbors Classifier
2023-11-05 11:51:34,826:INFO:Total runtime is 0.0769333799680074 minutes
2023-11-05 11:51:34,829:INFO:SubProcess create_model() called ==================================
2023-11-05 11:51:34,830:INFO:Initializing create_model()
2023-11-05 11:51:34,830:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BA2B2DDC0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BCB17CEB0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:51:34,830:INFO:Checking exceptions
2023-11-05 11:51:34,830:INFO:Importing libraries
2023-11-05 11:51:34,830:INFO:Copying training dataset
2023-11-05 11:51:34,871:INFO:Defining folds
2023-11-05 11:51:34,872:INFO:Declaring metric variables
2023-11-05 11:51:34,875:INFO:Importing untrained model
2023-11-05 11:51:34,878:INFO:K Neighbors Classifier Imported successfully
2023-11-05 11:51:34,884:INFO:Starting cross validation
2023-11-05 11:51:34,885:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:52:03,697:INFO:Calculating mean and std
2023-11-05 11:52:03,698:INFO:Creating metrics dataframe
2023-11-05 11:52:03,702:INFO:Uploading results into container
2023-11-05 11:52:03,702:INFO:Uploading model into container now
2023-11-05 11:52:03,703:INFO:_master_model_container: 2
2023-11-05 11:52:03,703:INFO:_display_container: 2
2023-11-05 11:52:03,703:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-05 11:52:03,703:INFO:create_model() successfully completed......................................
2023-11-05 11:52:03,803:INFO:SubProcess create_model() end ==================================
2023-11-05 11:52:03,804:INFO:Creating metrics dataframe
2023-11-05 11:52:03,812:INFO:Initializing Naive Bayes
2023-11-05 11:52:03,813:INFO:Total runtime is 0.5600499908129374 minutes
2023-11-05 11:52:03,816:INFO:SubProcess create_model() called ==================================
2023-11-05 11:52:03,816:INFO:Initializing create_model()
2023-11-05 11:52:03,816:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BA2B2DDC0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BCB17CEB0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:52:03,816:INFO:Checking exceptions
2023-11-05 11:52:03,816:INFO:Importing libraries
2023-11-05 11:52:03,817:INFO:Copying training dataset
2023-11-05 11:52:03,863:INFO:Defining folds
2023-11-05 11:52:03,863:INFO:Declaring metric variables
2023-11-05 11:52:03,869:INFO:Importing untrained model
2023-11-05 11:52:03,875:INFO:Naive Bayes Imported successfully
2023-11-05 11:52:03,883:INFO:Starting cross validation
2023-11-05 11:52:03,885:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:52:04,520:INFO:Calculating mean and std
2023-11-05 11:52:04,521:INFO:Creating metrics dataframe
2023-11-05 11:52:04,524:INFO:Uploading results into container
2023-11-05 11:52:04,525:INFO:Uploading model into container now
2023-11-05 11:52:04,525:INFO:_master_model_container: 3
2023-11-05 11:52:04,525:INFO:_display_container: 2
2023-11-05 11:52:04,526:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-05 11:52:04,526:INFO:create_model() successfully completed......................................
2023-11-05 11:52:04,617:INFO:SubProcess create_model() end ==================================
2023-11-05 11:52:04,617:INFO:Creating metrics dataframe
2023-11-05 11:52:04,627:INFO:Initializing Decision Tree Classifier
2023-11-05 11:52:04,627:INFO:Total runtime is 0.5736169775327047 minutes
2023-11-05 11:52:04,630:INFO:SubProcess create_model() called ==================================
2023-11-05 11:52:04,630:INFO:Initializing create_model()
2023-11-05 11:52:04,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BA2B2DDC0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BCB17CEB0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:52:04,630:INFO:Checking exceptions
2023-11-05 11:52:04,630:INFO:Importing libraries
2023-11-05 11:52:04,631:INFO:Copying training dataset
2023-11-05 11:52:04,672:INFO:Defining folds
2023-11-05 11:52:04,672:INFO:Declaring metric variables
2023-11-05 11:52:04,676:INFO:Importing untrained model
2023-11-05 11:52:04,679:INFO:Decision Tree Classifier Imported successfully
2023-11-05 11:52:04,686:INFO:Starting cross validation
2023-11-05 11:52:04,687:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:52:07,298:INFO:Calculating mean and std
2023-11-05 11:52:07,300:INFO:Creating metrics dataframe
2023-11-05 11:52:07,303:INFO:Uploading results into container
2023-11-05 11:52:07,304:INFO:Uploading model into container now
2023-11-05 11:52:07,304:INFO:_master_model_container: 4
2023-11-05 11:52:07,304:INFO:_display_container: 2
2023-11-05 11:52:07,305:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-11-05 11:52:07,305:INFO:create_model() successfully completed......................................
2023-11-05 11:52:07,397:INFO:SubProcess create_model() end ==================================
2023-11-05 11:52:07,397:INFO:Creating metrics dataframe
2023-11-05 11:52:07,406:INFO:Initializing SVM - Linear Kernel
2023-11-05 11:52:07,406:INFO:Total runtime is 0.6199334303538004 minutes
2023-11-05 11:52:07,409:INFO:SubProcess create_model() called ==================================
2023-11-05 11:52:07,410:INFO:Initializing create_model()
2023-11-05 11:52:07,410:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BA2B2DDC0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BCB17CEB0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:52:07,410:INFO:Checking exceptions
2023-11-05 11:52:07,410:INFO:Importing libraries
2023-11-05 11:52:07,410:INFO:Copying training dataset
2023-11-05 11:52:07,454:INFO:Defining folds
2023-11-05 11:52:07,454:INFO:Declaring metric variables
2023-11-05 11:52:07,457:INFO:Importing untrained model
2023-11-05 11:52:07,462:INFO:SVM - Linear Kernel Imported successfully
2023-11-05 11:52:07,467:INFO:Starting cross validation
2023-11-05 11:52:07,468:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:52:11,257:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:52:11,424:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:52:11,574:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:52:11,620:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:52:11,645:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:52:11,793:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:52:11,991:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:52:12,260:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:52:12,647:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:52:13,769:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 11:52:13,908:INFO:Calculating mean and std
2023-11-05 11:52:13,909:INFO:Creating metrics dataframe
2023-11-05 11:52:13,912:INFO:Uploading results into container
2023-11-05 11:52:13,913:INFO:Uploading model into container now
2023-11-05 11:52:13,913:INFO:_master_model_container: 5
2023-11-05 11:52:13,914:INFO:_display_container: 2
2023-11-05 11:52:13,914:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-05 11:52:13,915:INFO:create_model() successfully completed......................................
2023-11-05 11:52:14,008:INFO:SubProcess create_model() end ==================================
2023-11-05 11:52:14,008:INFO:Creating metrics dataframe
2023-11-05 11:52:14,018:INFO:Initializing Ridge Classifier
2023-11-05 11:52:14,018:INFO:Total runtime is 0.7301333785057068 minutes
2023-11-05 11:52:14,021:INFO:SubProcess create_model() called ==================================
2023-11-05 11:52:14,022:INFO:Initializing create_model()
2023-11-05 11:52:14,022:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BA2B2DDC0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BCB17CEB0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:52:14,022:INFO:Checking exceptions
2023-11-05 11:52:14,022:INFO:Importing libraries
2023-11-05 11:52:14,022:INFO:Copying training dataset
2023-11-05 11:52:14,062:INFO:Defining folds
2023-11-05 11:52:14,062:INFO:Declaring metric variables
2023-11-05 11:52:14,066:INFO:Importing untrained model
2023-11-05 11:52:14,069:INFO:Ridge Classifier Imported successfully
2023-11-05 11:52:14,075:INFO:Starting cross validation
2023-11-05 11:52:14,076:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:52:14,401:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.13719e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:52:14,428:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.02642e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:52:14,428:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.19282e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:52:14,440:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.11761e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:52:14,443:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:52:14,451:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:52:14,454:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:52:14,461:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.21583e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:52:14,467:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.16596e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:52:14,475:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:52:14,482:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.04676e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:52:14,483:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:52:14,488:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:52:14,498:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:52:14,502:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.20541e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:52:14,517:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.20378e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:52:14,518:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:52:14,531:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.11314e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 11:52:14,531:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:52:14,543:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 11:52:14,689:INFO:Calculating mean and std
2023-11-05 11:52:14,690:INFO:Creating metrics dataframe
2023-11-05 11:52:14,696:INFO:Uploading results into container
2023-11-05 11:52:14,697:INFO:Uploading model into container now
2023-11-05 11:52:14,697:INFO:_master_model_container: 6
2023-11-05 11:52:14,697:INFO:_display_container: 2
2023-11-05 11:52:14,697:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-11-05 11:52:14,697:INFO:create_model() successfully completed......................................
2023-11-05 11:52:14,789:INFO:SubProcess create_model() end ==================================
2023-11-05 11:52:14,789:INFO:Creating metrics dataframe
2023-11-05 11:52:14,799:INFO:Initializing Random Forest Classifier
2023-11-05 11:52:14,799:INFO:Total runtime is 0.743146018187205 minutes
2023-11-05 11:52:14,802:INFO:SubProcess create_model() called ==================================
2023-11-05 11:52:14,802:INFO:Initializing create_model()
2023-11-05 11:52:14,803:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BA2B2DDC0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BCB17CEB0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:52:14,803:INFO:Checking exceptions
2023-11-05 11:52:14,803:INFO:Importing libraries
2023-11-05 11:52:14,803:INFO:Copying training dataset
2023-11-05 11:52:14,847:INFO:Defining folds
2023-11-05 11:52:14,847:INFO:Declaring metric variables
2023-11-05 11:52:14,850:INFO:Importing untrained model
2023-11-05 11:52:14,855:INFO:Random Forest Classifier Imported successfully
2023-11-05 11:52:14,860:INFO:Starting cross validation
2023-11-05 11:52:14,861:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:52:52,596:INFO:Calculating mean and std
2023-11-05 11:52:52,598:INFO:Creating metrics dataframe
2023-11-05 11:52:52,603:INFO:Uploading results into container
2023-11-05 11:52:52,603:INFO:Uploading model into container now
2023-11-05 11:52:52,604:INFO:_master_model_container: 7
2023-11-05 11:52:52,604:INFO:_display_container: 2
2023-11-05 11:52:52,604:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-11-05 11:52:52,604:INFO:create_model() successfully completed......................................
2023-11-05 11:52:52,700:INFO:SubProcess create_model() end ==================================
2023-11-05 11:52:52,701:INFO:Creating metrics dataframe
2023-11-05 11:52:52,711:INFO:Initializing Quadratic Discriminant Analysis
2023-11-05 11:52:52,711:INFO:Total runtime is 1.3750126798947653 minutes
2023-11-05 11:52:52,714:INFO:SubProcess create_model() called ==================================
2023-11-05 11:52:52,715:INFO:Initializing create_model()
2023-11-05 11:52:52,715:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BA2B2DDC0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BCB17CEB0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:52:52,715:INFO:Checking exceptions
2023-11-05 11:52:52,715:INFO:Importing libraries
2023-11-05 11:52:52,715:INFO:Copying training dataset
2023-11-05 11:52:52,759:INFO:Defining folds
2023-11-05 11:52:52,759:INFO:Declaring metric variables
2023-11-05 11:52:52,762:INFO:Importing untrained model
2023-11-05 11:52:52,766:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-05 11:52:52,771:INFO:Starting cross validation
2023-11-05 11:52:52,772:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:52:53,557:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:52:53,620:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:52:53,641:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:52:53,659:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:52:53,698:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:52:53,744:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:52:53,800:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:52:53,823:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:52:53,827:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:52:53,870:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 11:52:54,114:INFO:Calculating mean and std
2023-11-05 11:52:54,115:INFO:Creating metrics dataframe
2023-11-05 11:52:54,118:INFO:Uploading results into container
2023-11-05 11:52:54,119:INFO:Uploading model into container now
2023-11-05 11:52:54,119:INFO:_master_model_container: 8
2023-11-05 11:52:54,119:INFO:_display_container: 2
2023-11-05 11:52:54,119:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-05 11:52:54,120:INFO:create_model() successfully completed......................................
2023-11-05 11:52:54,216:INFO:SubProcess create_model() end ==================================
2023-11-05 11:52:54,216:INFO:Creating metrics dataframe
2023-11-05 11:52:54,226:INFO:Initializing Ada Boost Classifier
2023-11-05 11:52:54,226:INFO:Total runtime is 1.4002626895904542 minutes
2023-11-05 11:52:54,230:INFO:SubProcess create_model() called ==================================
2023-11-05 11:52:54,230:INFO:Initializing create_model()
2023-11-05 11:52:54,230:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BA2B2DDC0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BCB17CEB0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:52:54,230:INFO:Checking exceptions
2023-11-05 11:52:54,230:INFO:Importing libraries
2023-11-05 11:52:54,231:INFO:Copying training dataset
2023-11-05 11:52:54,272:INFO:Defining folds
2023-11-05 11:52:54,272:INFO:Declaring metric variables
2023-11-05 11:52:54,276:INFO:Importing untrained model
2023-11-05 11:52:54,279:INFO:Ada Boost Classifier Imported successfully
2023-11-05 11:52:54,285:INFO:Starting cross validation
2023-11-05 11:52:54,286:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:53:06,281:INFO:Calculating mean and std
2023-11-05 11:53:06,282:INFO:Creating metrics dataframe
2023-11-05 11:53:06,285:INFO:Uploading results into container
2023-11-05 11:53:06,286:INFO:Uploading model into container now
2023-11-05 11:53:06,286:INFO:_master_model_container: 9
2023-11-05 11:53:06,287:INFO:_display_container: 2
2023-11-05 11:53:06,287:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-11-05 11:53:06,287:INFO:create_model() successfully completed......................................
2023-11-05 11:53:06,379:INFO:SubProcess create_model() end ==================================
2023-11-05 11:53:06,380:INFO:Creating metrics dataframe
2023-11-05 11:53:06,390:INFO:Initializing Gradient Boosting Classifier
2023-11-05 11:53:06,390:INFO:Total runtime is 1.6029946406682334 minutes
2023-11-05 11:53:06,393:INFO:SubProcess create_model() called ==================================
2023-11-05 11:53:06,394:INFO:Initializing create_model()
2023-11-05 11:53:06,394:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BA2B2DDC0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BCB17CEB0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:53:06,394:INFO:Checking exceptions
2023-11-05 11:53:06,394:INFO:Importing libraries
2023-11-05 11:53:06,394:INFO:Copying training dataset
2023-11-05 11:53:06,437:INFO:Defining folds
2023-11-05 11:53:06,437:INFO:Declaring metric variables
2023-11-05 11:53:06,441:INFO:Importing untrained model
2023-11-05 11:53:06,444:INFO:Gradient Boosting Classifier Imported successfully
2023-11-05 11:53:06,450:INFO:Starting cross validation
2023-11-05 11:53:06,451:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:53:58,982:INFO:Calculating mean and std
2023-11-05 11:53:58,984:INFO:Creating metrics dataframe
2023-11-05 11:53:58,987:INFO:Uploading results into container
2023-11-05 11:53:58,987:INFO:Uploading model into container now
2023-11-05 11:53:58,988:INFO:_master_model_container: 10
2023-11-05 11:53:58,988:INFO:_display_container: 2
2023-11-05 11:53:58,988:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-11-05 11:53:58,988:INFO:create_model() successfully completed......................................
2023-11-05 11:53:59,079:INFO:SubProcess create_model() end ==================================
2023-11-05 11:53:59,080:INFO:Creating metrics dataframe
2023-11-05 11:53:59,091:INFO:Initializing Linear Discriminant Analysis
2023-11-05 11:53:59,091:INFO:Total runtime is 2.481352484226227 minutes
2023-11-05 11:53:59,095:INFO:SubProcess create_model() called ==================================
2023-11-05 11:53:59,095:INFO:Initializing create_model()
2023-11-05 11:53:59,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BA2B2DDC0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BCB17CEB0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:53:59,095:INFO:Checking exceptions
2023-11-05 11:53:59,095:INFO:Importing libraries
2023-11-05 11:53:59,095:INFO:Copying training dataset
2023-11-05 11:53:59,136:INFO:Defining folds
2023-11-05 11:53:59,136:INFO:Declaring metric variables
2023-11-05 11:53:59,140:INFO:Importing untrained model
2023-11-05 11:53:59,143:INFO:Linear Discriminant Analysis Imported successfully
2023-11-05 11:53:59,149:INFO:Starting cross validation
2023-11-05 11:53:59,150:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:54:00,703:INFO:Calculating mean and std
2023-11-05 11:54:00,704:INFO:Creating metrics dataframe
2023-11-05 11:54:00,708:INFO:Uploading results into container
2023-11-05 11:54:00,708:INFO:Uploading model into container now
2023-11-05 11:54:00,709:INFO:_master_model_container: 11
2023-11-05 11:54:00,709:INFO:_display_container: 2
2023-11-05 11:54:00,709:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-05 11:54:00,709:INFO:create_model() successfully completed......................................
2023-11-05 11:54:00,800:INFO:SubProcess create_model() end ==================================
2023-11-05 11:54:00,800:INFO:Creating metrics dataframe
2023-11-05 11:54:00,811:INFO:Initializing Extra Trees Classifier
2023-11-05 11:54:00,811:INFO:Total runtime is 2.510020184516907 minutes
2023-11-05 11:54:00,814:INFO:SubProcess create_model() called ==================================
2023-11-05 11:54:00,815:INFO:Initializing create_model()
2023-11-05 11:54:00,815:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BA2B2DDC0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BCB17CEB0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:54:00,815:INFO:Checking exceptions
2023-11-05 11:54:00,815:INFO:Importing libraries
2023-11-05 11:54:00,815:INFO:Copying training dataset
2023-11-05 11:54:00,857:INFO:Defining folds
2023-11-05 11:54:00,857:INFO:Declaring metric variables
2023-11-05 11:54:00,860:INFO:Importing untrained model
2023-11-05 11:54:00,863:INFO:Extra Trees Classifier Imported successfully
2023-11-05 11:54:00,869:INFO:Starting cross validation
2023-11-05 11:54:00,870:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:54:24,601:INFO:Calculating mean and std
2023-11-05 11:54:24,603:INFO:Creating metrics dataframe
2023-11-05 11:54:24,606:INFO:Uploading results into container
2023-11-05 11:54:24,607:INFO:Uploading model into container now
2023-11-05 11:54:24,607:INFO:_master_model_container: 12
2023-11-05 11:54:24,607:INFO:_display_container: 2
2023-11-05 11:54:24,608:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-11-05 11:54:24,608:INFO:create_model() successfully completed......................................
2023-11-05 11:54:24,727:INFO:SubProcess create_model() end ==================================
2023-11-05 11:54:24,727:INFO:Creating metrics dataframe
2023-11-05 11:54:24,739:INFO:Initializing Extreme Gradient Boosting
2023-11-05 11:54:24,740:INFO:Total runtime is 2.90883686542511 minutes
2023-11-05 11:54:24,743:INFO:SubProcess create_model() called ==================================
2023-11-05 11:54:24,744:INFO:Initializing create_model()
2023-11-05 11:54:24,744:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BA2B2DDC0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BCB17CEB0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:54:24,744:INFO:Checking exceptions
2023-11-05 11:54:24,744:INFO:Importing libraries
2023-11-05 11:54:24,744:INFO:Copying training dataset
2023-11-05 11:54:24,796:INFO:Defining folds
2023-11-05 11:54:24,796:INFO:Declaring metric variables
2023-11-05 11:54:24,800:INFO:Importing untrained model
2023-11-05 11:54:24,805:INFO:Extreme Gradient Boosting Imported successfully
2023-11-05 11:54:24,812:INFO:Starting cross validation
2023-11-05 11:54:24,813:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:54:28,593:INFO:Calculating mean and std
2023-11-05 11:54:28,595:INFO:Creating metrics dataframe
2023-11-05 11:54:28,599:INFO:Uploading results into container
2023-11-05 11:54:28,600:INFO:Uploading model into container now
2023-11-05 11:54:28,600:INFO:_master_model_container: 13
2023-11-05 11:54:28,600:INFO:_display_container: 2
2023-11-05 11:54:28,601:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2023-11-05 11:54:28,601:INFO:create_model() successfully completed......................................
2023-11-05 11:54:28,699:INFO:SubProcess create_model() end ==================================
2023-11-05 11:54:28,699:INFO:Creating metrics dataframe
2023-11-05 11:54:28,711:INFO:Initializing Light Gradient Boosting Machine
2023-11-05 11:54:28,711:INFO:Total runtime is 2.9750201980272934 minutes
2023-11-05 11:54:28,714:INFO:SubProcess create_model() called ==================================
2023-11-05 11:54:28,715:INFO:Initializing create_model()
2023-11-05 11:54:28,715:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BA2B2DDC0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BCB17CEB0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:54:28,715:INFO:Checking exceptions
2023-11-05 11:54:28,715:INFO:Importing libraries
2023-11-05 11:54:28,715:INFO:Copying training dataset
2023-11-05 11:54:28,763:INFO:Defining folds
2023-11-05 11:54:28,763:INFO:Declaring metric variables
2023-11-05 11:54:28,767:INFO:Importing untrained model
2023-11-05 11:54:28,771:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-05 11:54:28,777:INFO:Starting cross validation
2023-11-05 11:54:28,778:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:54:33,859:INFO:Calculating mean and std
2023-11-05 11:54:33,861:INFO:Creating metrics dataframe
2023-11-05 11:54:33,864:INFO:Uploading results into container
2023-11-05 11:54:33,865:INFO:Uploading model into container now
2023-11-05 11:54:33,865:INFO:_master_model_container: 14
2023-11-05 11:54:33,865:INFO:_display_container: 2
2023-11-05 11:54:33,866:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 11:54:33,866:INFO:create_model() successfully completed......................................
2023-11-05 11:54:33,978:INFO:SubProcess create_model() end ==================================
2023-11-05 11:54:33,978:INFO:Creating metrics dataframe
2023-11-05 11:54:33,992:INFO:Initializing Dummy Classifier
2023-11-05 11:54:33,992:INFO:Total runtime is 3.0630368709564215 minutes
2023-11-05 11:54:33,997:INFO:SubProcess create_model() called ==================================
2023-11-05 11:54:33,997:INFO:Initializing create_model()
2023-11-05 11:54:33,997:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BA2B2DDC0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022BCB17CEB0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:54:33,997:INFO:Checking exceptions
2023-11-05 11:54:33,998:INFO:Importing libraries
2023-11-05 11:54:33,998:INFO:Copying training dataset
2023-11-05 11:54:34,051:INFO:Defining folds
2023-11-05 11:54:34,051:INFO:Declaring metric variables
2023-11-05 11:54:34,054:INFO:Importing untrained model
2023-11-05 11:54:34,057:INFO:Dummy Classifier Imported successfully
2023-11-05 11:54:34,064:INFO:Starting cross validation
2023-11-05 11:54:34,065:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 11:54:34,310:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:54:34,341:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:54:34,345:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:54:34,347:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:54:34,348:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:54:34,351:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:54:34,395:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:54:34,397:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:54:34,406:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:54:34,409:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 11:54:34,541:INFO:Calculating mean and std
2023-11-05 11:54:34,542:INFO:Creating metrics dataframe
2023-11-05 11:54:34,548:INFO:Uploading results into container
2023-11-05 11:54:34,549:INFO:Uploading model into container now
2023-11-05 11:54:34,550:INFO:_master_model_container: 15
2023-11-05 11:54:34,550:INFO:_display_container: 2
2023-11-05 11:54:34,550:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-11-05 11:54:34,550:INFO:create_model() successfully completed......................................
2023-11-05 11:54:34,648:INFO:SubProcess create_model() end ==================================
2023-11-05 11:54:34,649:INFO:Creating metrics dataframe
2023-11-05 11:54:34,670:INFO:Initializing create_model()
2023-11-05 11:54:34,671:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BA2B2DDC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-05 11:54:34,671:INFO:Checking exceptions
2023-11-05 11:54:34,673:INFO:Importing libraries
2023-11-05 11:54:34,673:INFO:Copying training dataset
2023-11-05 11:54:34,716:INFO:Defining folds
2023-11-05 11:54:34,716:INFO:Declaring metric variables
2023-11-05 11:54:34,716:INFO:Importing untrained model
2023-11-05 11:54:34,716:INFO:Declaring custom model
2023-11-05 11:54:34,717:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-05 11:54:34,718:INFO:Cross validation set to False
2023-11-05 11:54:34,718:INFO:Fitting Model
2023-11-05 11:54:34,861:INFO:[LightGBM] [Info] Number of positive: 29322, number of negative: 97741
2023-11-05 11:54:34,880:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014475 seconds.
2023-11-05 11:54:34,880:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-05 11:54:34,880:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-05 11:54:34,880:INFO:[LightGBM] [Info] Number of data points in the train set: 127063, number of used features: 19
2023-11-05 11:54:34,881:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230767 -> initscore=-1.203983
2023-11-05 11:54:34,881:INFO:[LightGBM] [Info] Start training from score -1.203983
2023-11-05 11:54:35,320:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 11:54:35,320:INFO:create_model() successfully completed......................................
2023-11-05 11:54:35,463:INFO:_master_model_container: 15
2023-11-05 11:54:35,463:INFO:_display_container: 2
2023-11-05 11:54:35,464:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 11:54:35,464:INFO:compare_models() successfully completed......................................
2023-11-05 12:04:50,250:INFO:Initializing create_model()
2023-11-05 12:04:50,250:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BA2B2DDC0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:04:50,250:INFO:Checking exceptions
2023-11-05 12:04:50,265:INFO:Importing libraries
2023-11-05 12:04:50,265:INFO:Copying training dataset
2023-11-05 12:04:50,326:INFO:Defining folds
2023-11-05 12:04:50,326:INFO:Declaring metric variables
2023-11-05 12:04:50,329:INFO:Importing untrained model
2023-11-05 12:04:50,333:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-05 12:04:50,339:INFO:Starting cross validation
2023-11-05 12:04:50,340:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:04:58,631:INFO:Calculating mean and std
2023-11-05 12:04:58,632:INFO:Creating metrics dataframe
2023-11-05 12:04:58,638:INFO:Finalizing model
2023-11-05 12:04:58,807:INFO:[LightGBM] [Info] Number of positive: 29322, number of negative: 97741
2023-11-05 12:04:58,823:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004279 seconds.
2023-11-05 12:04:58,823:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-05 12:04:58,823:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-05 12:04:58,823:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-05 12:04:58,824:INFO:[LightGBM] [Info] Number of data points in the train set: 127063, number of used features: 19
2023-11-05 12:04:58,824:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230767 -> initscore=-1.203983
2023-11-05 12:04:58,824:INFO:[LightGBM] [Info] Start training from score -1.203983
2023-11-05 12:04:59,325:INFO:Uploading results into container
2023-11-05 12:04:59,326:INFO:Uploading model into container now
2023-11-05 12:04:59,338:INFO:_master_model_container: 16
2023-11-05 12:04:59,338:INFO:_display_container: 3
2023-11-05 12:04:59,339:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 12:04:59,339:INFO:create_model() successfully completed......................................
2023-11-05 12:05:08,734:INFO:Initializing predict_model()
2023-11-05 12:05:08,735:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BA2B2DDC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022C06B5CEE0>)
2023-11-05 12:05:08,735:INFO:Checking exceptions
2023-11-05 12:05:08,735:INFO:Preloading libraries
2023-11-05 12:05:11,660:INFO:Initializing evaluate_model()
2023-11-05 12:05:11,660:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BA2B2DDC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-11-05 12:05:11,683:INFO:Initializing plot_model()
2023-11-05 12:05:11,683:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BA2B2DDC0>, system=True)
2023-11-05 12:05:11,683:INFO:Checking exceptions
2023-11-05 12:05:11,700:INFO:Preloading libraries
2023-11-05 12:05:11,706:INFO:Copying training dataset
2023-11-05 12:05:11,706:INFO:Plot type: pipeline
2023-11-05 12:05:11,796:INFO:Visual Rendered Successfully
2023-11-05 12:05:11,903:INFO:plot_model() successfully completed......................................
2023-11-05 12:05:17,836:INFO:Initializing interpret_model()
2023-11-05 12:05:17,836:INFO:interpret_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=feature_importance, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BA2B2DDC0>)
2023-11-05 12:05:17,836:INFO:Checking exceptions
2023-11-05 12:05:17,836:INFO:Soft dependency imported: shap: 0.43.0
2023-11-05 12:05:17,890:INFO:plot type: summary
2023-11-05 12:05:17,890:INFO:Creating TreeExplainer
2023-11-05 12:05:18,019:INFO:Compiling shap values
2023-11-05 12:05:29,287:INFO:Visual Rendered Successfully
2023-11-05 12:05:29,287:INFO:interpret_model() successfully completed......................................
2023-11-05 12:07:45,313:INFO:Initializing create_model()
2023-11-05 12:07:45,313:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022BA2B2DDC0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:07:45,313:INFO:Checking exceptions
2023-11-05 12:07:45,328:INFO:Importing libraries
2023-11-05 12:07:45,328:INFO:Copying training dataset
2023-11-05 12:07:45,397:INFO:Defining folds
2023-11-05 12:07:45,397:INFO:Declaring metric variables
2023-11-05 12:07:45,401:INFO:Importing untrained model
2023-11-05 12:07:45,405:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-05 12:07:45,416:INFO:Starting cross validation
2023-11-05 12:07:45,417:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:07:52,321:INFO:Calculating mean and std
2023-11-05 12:07:52,323:INFO:Creating metrics dataframe
2023-11-05 12:07:52,327:INFO:Finalizing model
2023-11-05 12:07:52,459:INFO:[LightGBM] [Info] Number of positive: 29322, number of negative: 97741
2023-11-05 12:07:52,476:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003829 seconds.
2023-11-05 12:07:52,476:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-05 12:07:52,476:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-05 12:07:52,477:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-05 12:07:52,477:INFO:[LightGBM] [Info] Number of data points in the train set: 127063, number of used features: 19
2023-11-05 12:07:52,478:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230767 -> initscore=-1.203983
2023-11-05 12:07:52,478:INFO:[LightGBM] [Info] Start training from score -1.203983
2023-11-05 12:07:52,939:INFO:Uploading results into container
2023-11-05 12:07:52,940:INFO:Uploading model into container now
2023-11-05 12:07:52,951:INFO:_master_model_container: 17
2023-11-05 12:07:52,952:INFO:_display_container: 5
2023-11-05 12:07:52,952:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 12:07:52,952:INFO:create_model() successfully completed......................................
2023-11-05 12:25:01,142:INFO:PyCaret ClassificationExperiment
2023-11-05 12:25:01,142:INFO:Logging name: clf-default-name
2023-11-05 12:25:01,142:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-05 12:25:01,142:INFO:version 3.1.0
2023-11-05 12:25:01,142:INFO:Initializing setup()
2023-11-05 12:25:01,142:INFO:self.USI: 03d8
2023-11-05 12:25:01,143:INFO:self._variable_keys: {'logging_param', 'y_test', 'gpu_param', 'y', 'n_jobs_param', 'memory', 'gpu_n_jobs_param', 'html_param', 'seed', 'data', 'X', 'fix_imbalance', 'USI', 'log_plots_param', 'fold_groups_param', 'fold_generator', '_ml_usecase', 'exp_id', 'is_multiclass', '_available_plots', 'X_train', 'exp_name_log', 'fold_shuffle_param', 'X_test', 'pipeline', 'target_param', 'idx', 'y_train'}
2023-11-05 12:25:01,143:INFO:Checking environment
2023-11-05 12:25:01,143:INFO:python_version: 3.9.18
2023-11-05 12:25:01,143:INFO:python_build: ('main', 'Sep 11 2023 14:09:26')
2023-11-05 12:25:01,143:INFO:machine: AMD64
2023-11-05 12:25:01,143:INFO:platform: Windows-10-10.0.19041-SP0
2023-11-05 12:25:01,143:INFO:Memory: svmem(total=25692647424, available=15491739648, percent=39.7, used=10200907776, free=15491739648)
2023-11-05 12:25:01,143:INFO:Physical Core: 8
2023-11-05 12:25:01,143:INFO:Logical Core: 16
2023-11-05 12:25:01,143:INFO:Checking libraries
2023-11-05 12:25:01,143:INFO:System:
2023-11-05 12:25:01,143:INFO:    python: 3.9.18 (main, Sep 11 2023, 14:09:26) [MSC v.1916 64 bit (AMD64)]
2023-11-05 12:25:01,144:INFO:executable: d:\programas\Anaconda3\envs\meli_test2\python.exe
2023-11-05 12:25:01,144:INFO:   machine: Windows-10-10.0.19041-SP0
2023-11-05 12:25:01,144:INFO:PyCaret required dependencies:
2023-11-05 12:25:01,144:INFO:                 pip: 23.3
2023-11-05 12:25:01,144:INFO:          setuptools: 68.0.0
2023-11-05 12:25:01,144:INFO:             pycaret: 3.1.0
2023-11-05 12:25:01,144:INFO:             IPython: 8.17.2
2023-11-05 12:25:01,144:INFO:          ipywidgets: 8.1.1
2023-11-05 12:25:01,144:INFO:                tqdm: 4.66.1
2023-11-05 12:25:01,144:INFO:               numpy: 1.23.5
2023-11-05 12:25:01,144:INFO:              pandas: 1.5.3
2023-11-05 12:25:01,144:INFO:              jinja2: 3.1.2
2023-11-05 12:25:01,144:INFO:               scipy: 1.10.1
2023-11-05 12:25:01,144:INFO:              joblib: 1.3.2
2023-11-05 12:25:01,144:INFO:             sklearn: 1.2.2
2023-11-05 12:25:01,144:INFO:                pyod: 1.1.1
2023-11-05 12:25:01,144:INFO:            imblearn: 0.11.0
2023-11-05 12:25:01,144:INFO:   category_encoders: 2.6.3
2023-11-05 12:25:01,144:INFO:            lightgbm: 4.1.0
2023-11-05 12:25:01,144:INFO:               numba: 0.58.1
2023-11-05 12:25:01,144:INFO:            requests: 2.31.0
2023-11-05 12:25:01,144:INFO:          matplotlib: 3.8.1
2023-11-05 12:25:01,144:INFO:          scikitplot: 0.3.7
2023-11-05 12:25:01,145:INFO:         yellowbrick: 1.5
2023-11-05 12:25:01,145:INFO:              plotly: 5.18.0
2023-11-05 12:25:01,145:INFO:    plotly-resampler: Not installed
2023-11-05 12:25:01,145:INFO:             kaleido: 0.2.1
2023-11-05 12:25:01,145:INFO:           schemdraw: 0.15
2023-11-05 12:25:01,145:INFO:         statsmodels: 0.14.0
2023-11-05 12:25:01,145:INFO:              sktime: 0.21.1
2023-11-05 12:25:01,145:INFO:               tbats: 1.1.3
2023-11-05 12:25:01,145:INFO:            pmdarima: 2.0.4
2023-11-05 12:25:01,145:INFO:              psutil: 5.9.6
2023-11-05 12:25:01,145:INFO:          markupsafe: 2.1.3
2023-11-05 12:25:01,145:INFO:             pickle5: Not installed
2023-11-05 12:25:01,145:INFO:         cloudpickle: 3.0.0
2023-11-05 12:25:01,145:INFO:         deprecation: 2.1.0
2023-11-05 12:25:01,145:INFO:              xxhash: 3.4.1
2023-11-05 12:25:01,145:INFO:           wurlitzer: Not installed
2023-11-05 12:25:01,145:INFO:PyCaret optional dependencies:
2023-11-05 12:25:01,145:INFO:                shap: 0.43.0
2023-11-05 12:25:01,145:INFO:           interpret: Not installed
2023-11-05 12:25:01,145:INFO:                umap: Not installed
2023-11-05 12:25:01,145:INFO:     ydata_profiling: Not installed
2023-11-05 12:25:01,145:INFO:  explainerdashboard: Not installed
2023-11-05 12:25:01,145:INFO:             autoviz: Not installed
2023-11-05 12:25:01,145:INFO:           fairlearn: Not installed
2023-11-05 12:25:01,146:INFO:          deepchecks: Not installed
2023-11-05 12:25:01,146:INFO:             xgboost: 2.0.1
2023-11-05 12:25:01,146:INFO:            catboost: Not installed
2023-11-05 12:25:01,146:INFO:              kmodes: Not installed
2023-11-05 12:25:01,146:INFO:             mlxtend: Not installed
2023-11-05 12:25:01,146:INFO:       statsforecast: Not installed
2023-11-05 12:25:01,146:INFO:        tune_sklearn: Not installed
2023-11-05 12:25:01,146:INFO:                 ray: Not installed
2023-11-05 12:25:01,146:INFO:            hyperopt: Not installed
2023-11-05 12:25:01,146:INFO:              optuna: Not installed
2023-11-05 12:25:01,146:INFO:               skopt: Not installed
2023-11-05 12:25:01,146:INFO:              mlflow: Not installed
2023-11-05 12:25:01,146:INFO:              gradio: Not installed
2023-11-05 12:25:01,146:INFO:             fastapi: Not installed
2023-11-05 12:25:01,146:INFO:             uvicorn: Not installed
2023-11-05 12:25:01,146:INFO:              m2cgen: Not installed
2023-11-05 12:25:01,146:INFO:           evidently: Not installed
2023-11-05 12:25:01,146:INFO:               fugue: Not installed
2023-11-05 12:25:01,146:INFO:           streamlit: Not installed
2023-11-05 12:25:01,146:INFO:             prophet: Not installed
2023-11-05 12:25:01,146:INFO:None
2023-11-05 12:25:01,146:INFO:Set up data.
2023-11-05 12:25:01,207:INFO:Set up folding strategy.
2023-11-05 12:25:01,207:INFO:Set up train/test split.
2023-11-05 12:25:01,283:INFO:Set up index.
2023-11-05 12:25:01,287:INFO:Assigning column types.
2023-11-05 12:25:01,316:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-05 12:25:01,367:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-05 12:25:01,368:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 12:25:01,400:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 12:25:01,403:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 12:25:01,454:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-05 12:25:01,455:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 12:25:01,487:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 12:25:01,489:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 12:25:01,490:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-05 12:25:01,541:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 12:25:01,573:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 12:25:01,576:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 12:25:01,629:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 12:25:01,661:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 12:25:01,665:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 12:25:01,665:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-05 12:25:01,751:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 12:25:01,754:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 12:25:01,840:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 12:25:01,843:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 12:25:01,844:INFO:Preparing preprocessing pipeline...
2023-11-05 12:25:01,849:INFO:Set up simple imputation.
2023-11-05 12:25:01,932:INFO:Finished creating preprocessing pipeline.
2023-11-05 12:25:01,936:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['a', 'b', 'c', 'd', 'e', 'f', 'h',
                                             'k', 'l', 'm', 'n', 'p', 'monto',
                                             'score', 'Country_AR',
                                             'Country_BR', 'Country_US',
                                             'Country_UY', 'Country_otros'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-05 12:25:01,936:INFO:Creating final display dataframe.
2023-11-05 12:25:02,172:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            fraude
2                   Target type            Binary
3           Original data shape      (181519, 20)
4        Transformed data shape      (181519, 20)
5   Transformed train set shape      (127063, 20)
6    Transformed test set shape       (54456, 20)
7              Numeric features                19
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              03d8
2023-11-05 12:25:02,269:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 12:25:02,272:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 12:25:02,361:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 12:25:02,364:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 12:25:02,364:INFO:setup() successfully completed in 1.22s...............
2023-11-05 12:25:02,395:INFO:Initializing compare_models()
2023-11-05 12:25:02,396:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B93F9F220>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022B93F9F220>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-11-05 12:25:02,396:INFO:Checking exceptions
2023-11-05 12:25:02,422:INFO:Preparing display monitor
2023-11-05 12:25:02,444:INFO:Initializing Logistic Regression
2023-11-05 12:25:02,444:INFO:Total runtime is 0.0 minutes
2023-11-05 12:25:02,448:INFO:SubProcess create_model() called ==================================
2023-11-05 12:25:02,448:INFO:Initializing create_model()
2023-11-05 12:25:02,448:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B93F9F220>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C0366DF40>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:25:02,448:INFO:Checking exceptions
2023-11-05 12:25:02,448:INFO:Importing libraries
2023-11-05 12:25:02,449:INFO:Copying training dataset
2023-11-05 12:25:02,498:INFO:Defining folds
2023-11-05 12:25:02,499:INFO:Declaring metric variables
2023-11-05 12:25:02,502:INFO:Importing untrained model
2023-11-05 12:25:02,506:INFO:Logistic Regression Imported successfully
2023-11-05 12:25:02,513:INFO:Starting cross validation
2023-11-05 12:25:02,514:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:25:10,341:INFO:Calculating mean and std
2023-11-05 12:25:10,343:INFO:Creating metrics dataframe
2023-11-05 12:25:10,347:INFO:Uploading results into container
2023-11-05 12:25:10,347:INFO:Uploading model into container now
2023-11-05 12:25:10,348:INFO:_master_model_container: 1
2023-11-05 12:25:10,348:INFO:_display_container: 2
2023-11-05 12:25:10,348:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-05 12:25:10,348:INFO:create_model() successfully completed......................................
2023-11-05 12:25:10,464:INFO:SubProcess create_model() end ==================================
2023-11-05 12:25:10,464:INFO:Creating metrics dataframe
2023-11-05 12:25:10,472:INFO:Initializing K Neighbors Classifier
2023-11-05 12:25:10,473:INFO:Total runtime is 0.1338177720705668 minutes
2023-11-05 12:25:10,476:INFO:SubProcess create_model() called ==================================
2023-11-05 12:25:10,476:INFO:Initializing create_model()
2023-11-05 12:25:10,476:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B93F9F220>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C0366DF40>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:25:10,476:INFO:Checking exceptions
2023-11-05 12:25:10,476:INFO:Importing libraries
2023-11-05 12:25:10,476:INFO:Copying training dataset
2023-11-05 12:25:10,520:INFO:Defining folds
2023-11-05 12:25:10,520:INFO:Declaring metric variables
2023-11-05 12:25:10,524:INFO:Importing untrained model
2023-11-05 12:25:10,527:INFO:K Neighbors Classifier Imported successfully
2023-11-05 12:25:10,533:INFO:Starting cross validation
2023-11-05 12:25:10,534:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:25:37,892:INFO:Calculating mean and std
2023-11-05 12:25:37,893:INFO:Creating metrics dataframe
2023-11-05 12:25:37,896:INFO:Uploading results into container
2023-11-05 12:25:37,897:INFO:Uploading model into container now
2023-11-05 12:25:37,897:INFO:_master_model_container: 2
2023-11-05 12:25:37,897:INFO:_display_container: 2
2023-11-05 12:25:37,898:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-05 12:25:37,898:INFO:create_model() successfully completed......................................
2023-11-05 12:25:37,999:INFO:SubProcess create_model() end ==================================
2023-11-05 12:25:37,999:INFO:Creating metrics dataframe
2023-11-05 12:25:38,008:INFO:Initializing Naive Bayes
2023-11-05 12:25:38,008:INFO:Total runtime is 0.5927281657854716 minutes
2023-11-05 12:25:38,011:INFO:SubProcess create_model() called ==================================
2023-11-05 12:25:38,011:INFO:Initializing create_model()
2023-11-05 12:25:38,011:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B93F9F220>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C0366DF40>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:25:38,011:INFO:Checking exceptions
2023-11-05 12:25:38,012:INFO:Importing libraries
2023-11-05 12:25:38,012:INFO:Copying training dataset
2023-11-05 12:25:38,051:INFO:Defining folds
2023-11-05 12:25:38,052:INFO:Declaring metric variables
2023-11-05 12:25:38,056:INFO:Importing untrained model
2023-11-05 12:25:38,061:INFO:Naive Bayes Imported successfully
2023-11-05 12:25:38,068:INFO:Starting cross validation
2023-11-05 12:25:38,069:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:25:38,682:INFO:Calculating mean and std
2023-11-05 12:25:38,684:INFO:Creating metrics dataframe
2023-11-05 12:25:38,688:INFO:Uploading results into container
2023-11-05 12:25:38,689:INFO:Uploading model into container now
2023-11-05 12:25:38,689:INFO:_master_model_container: 3
2023-11-05 12:25:38,689:INFO:_display_container: 2
2023-11-05 12:25:38,690:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-05 12:25:38,690:INFO:create_model() successfully completed......................................
2023-11-05 12:25:38,791:INFO:SubProcess create_model() end ==================================
2023-11-05 12:25:38,791:INFO:Creating metrics dataframe
2023-11-05 12:25:38,800:INFO:Initializing Decision Tree Classifier
2023-11-05 12:25:38,800:INFO:Total runtime is 0.6059345563252767 minutes
2023-11-05 12:25:38,803:INFO:SubProcess create_model() called ==================================
2023-11-05 12:25:38,803:INFO:Initializing create_model()
2023-11-05 12:25:38,804:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B93F9F220>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C0366DF40>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:25:38,804:INFO:Checking exceptions
2023-11-05 12:25:38,804:INFO:Importing libraries
2023-11-05 12:25:38,804:INFO:Copying training dataset
2023-11-05 12:25:38,843:INFO:Defining folds
2023-11-05 12:25:38,844:INFO:Declaring metric variables
2023-11-05 12:25:38,847:INFO:Importing untrained model
2023-11-05 12:25:38,850:INFO:Decision Tree Classifier Imported successfully
2023-11-05 12:25:38,856:INFO:Starting cross validation
2023-11-05 12:25:38,857:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:25:41,510:INFO:Calculating mean and std
2023-11-05 12:25:41,512:INFO:Creating metrics dataframe
2023-11-05 12:25:41,516:INFO:Uploading results into container
2023-11-05 12:25:41,517:INFO:Uploading model into container now
2023-11-05 12:25:41,517:INFO:_master_model_container: 4
2023-11-05 12:25:41,517:INFO:_display_container: 2
2023-11-05 12:25:41,518:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-11-05 12:25:41,518:INFO:create_model() successfully completed......................................
2023-11-05 12:25:41,619:INFO:SubProcess create_model() end ==================================
2023-11-05 12:25:41,620:INFO:Creating metrics dataframe
2023-11-05 12:25:41,629:INFO:Initializing SVM - Linear Kernel
2023-11-05 12:25:41,629:INFO:Total runtime is 0.6530840277671814 minutes
2023-11-05 12:25:41,632:INFO:SubProcess create_model() called ==================================
2023-11-05 12:25:41,633:INFO:Initializing create_model()
2023-11-05 12:25:41,633:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B93F9F220>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C0366DF40>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:25:41,633:INFO:Checking exceptions
2023-11-05 12:25:41,633:INFO:Importing libraries
2023-11-05 12:25:41,633:INFO:Copying training dataset
2023-11-05 12:25:41,673:INFO:Defining folds
2023-11-05 12:25:41,674:INFO:Declaring metric variables
2023-11-05 12:25:41,677:INFO:Importing untrained model
2023-11-05 12:25:41,680:INFO:SVM - Linear Kernel Imported successfully
2023-11-05 12:25:41,686:INFO:Starting cross validation
2023-11-05 12:25:41,687:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:25:45,518:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:25:45,531:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:25:45,712:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:25:45,806:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:25:45,892:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:25:46,012:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:25:46,230:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:25:46,348:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:25:46,804:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:25:47,759:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:25:47,899:INFO:Calculating mean and std
2023-11-05 12:25:47,900:INFO:Creating metrics dataframe
2023-11-05 12:25:47,904:INFO:Uploading results into container
2023-11-05 12:25:47,904:INFO:Uploading model into container now
2023-11-05 12:25:47,905:INFO:_master_model_container: 5
2023-11-05 12:25:47,905:INFO:_display_container: 2
2023-11-05 12:25:47,905:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-05 12:25:47,905:INFO:create_model() successfully completed......................................
2023-11-05 12:25:48,006:INFO:SubProcess create_model() end ==================================
2023-11-05 12:25:48,006:INFO:Creating metrics dataframe
2023-11-05 12:25:48,016:INFO:Initializing Ridge Classifier
2023-11-05 12:25:48,016:INFO:Total runtime is 0.7595361471176147 minutes
2023-11-05 12:25:48,019:INFO:SubProcess create_model() called ==================================
2023-11-05 12:25:48,019:INFO:Initializing create_model()
2023-11-05 12:25:48,019:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B93F9F220>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C0366DF40>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:25:48,019:INFO:Checking exceptions
2023-11-05 12:25:48,019:INFO:Importing libraries
2023-11-05 12:25:48,020:INFO:Copying training dataset
2023-11-05 12:25:48,060:INFO:Defining folds
2023-11-05 12:25:48,061:INFO:Declaring metric variables
2023-11-05 12:25:48,064:INFO:Importing untrained model
2023-11-05 12:25:48,068:INFO:Ridge Classifier Imported successfully
2023-11-05 12:25:48,074:INFO:Starting cross validation
2023-11-05 12:25:48,075:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:25:48,345:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.13719e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:25:48,389:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:25:48,400:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.02642e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:25:48,421:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.19282e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:25:48,430:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.11761e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:25:48,431:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:25:48,445:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:25:48,455:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.04676e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:25:48,456:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.21583e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:25:48,460:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:25:48,474:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:25:48,481:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.20541e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:25:48,481:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:25:48,500:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:25:48,503:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.16596e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:25:48,507:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.20378e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:25:48,516:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:25:48,522:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:25:48,527:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.11314e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:25:48,537:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:25:48,677:INFO:Calculating mean and std
2023-11-05 12:25:48,678:INFO:Creating metrics dataframe
2023-11-05 12:25:48,684:INFO:Uploading results into container
2023-11-05 12:25:48,685:INFO:Uploading model into container now
2023-11-05 12:25:48,685:INFO:_master_model_container: 6
2023-11-05 12:25:48,686:INFO:_display_container: 2
2023-11-05 12:25:48,686:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-11-05 12:25:48,686:INFO:create_model() successfully completed......................................
2023-11-05 12:25:48,787:INFO:SubProcess create_model() end ==================================
2023-11-05 12:25:48,787:INFO:Creating metrics dataframe
2023-11-05 12:25:48,797:INFO:Initializing Random Forest Classifier
2023-11-05 12:25:48,797:INFO:Total runtime is 0.7725505749384562 minutes
2023-11-05 12:25:48,801:INFO:SubProcess create_model() called ==================================
2023-11-05 12:25:48,801:INFO:Initializing create_model()
2023-11-05 12:25:48,801:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B93F9F220>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C0366DF40>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:25:48,801:INFO:Checking exceptions
2023-11-05 12:25:48,801:INFO:Importing libraries
2023-11-05 12:25:48,802:INFO:Copying training dataset
2023-11-05 12:25:48,842:INFO:Defining folds
2023-11-05 12:25:48,842:INFO:Declaring metric variables
2023-11-05 12:25:48,846:INFO:Importing untrained model
2023-11-05 12:25:48,849:INFO:Random Forest Classifier Imported successfully
2023-11-05 12:25:48,856:INFO:Starting cross validation
2023-11-05 12:25:48,857:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:26:26,480:INFO:Calculating mean and std
2023-11-05 12:26:26,482:INFO:Creating metrics dataframe
2023-11-05 12:26:26,485:INFO:Uploading results into container
2023-11-05 12:26:26,486:INFO:Uploading model into container now
2023-11-05 12:26:26,486:INFO:_master_model_container: 7
2023-11-05 12:26:26,486:INFO:_display_container: 2
2023-11-05 12:26:26,486:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-11-05 12:26:26,487:INFO:create_model() successfully completed......................................
2023-11-05 12:26:26,609:INFO:SubProcess create_model() end ==================================
2023-11-05 12:26:26,609:INFO:Creating metrics dataframe
2023-11-05 12:26:26,619:INFO:Initializing Quadratic Discriminant Analysis
2023-11-05 12:26:26,619:INFO:Total runtime is 1.4029172579447429 minutes
2023-11-05 12:26:26,623:INFO:SubProcess create_model() called ==================================
2023-11-05 12:26:26,623:INFO:Initializing create_model()
2023-11-05 12:26:26,623:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B93F9F220>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C0366DF40>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:26:26,623:INFO:Checking exceptions
2023-11-05 12:26:26,623:INFO:Importing libraries
2023-11-05 12:26:26,624:INFO:Copying training dataset
2023-11-05 12:26:26,672:INFO:Defining folds
2023-11-05 12:26:26,672:INFO:Declaring metric variables
2023-11-05 12:26:26,676:INFO:Importing untrained model
2023-11-05 12:26:26,680:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-05 12:26:26,687:INFO:Starting cross validation
2023-11-05 12:26:26,688:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:26:27,370:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:26:27,500:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:26:27,503:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:26:27,676:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:26:27,693:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:26:27,706:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:26:27,712:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:26:27,763:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:26:27,781:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:26:27,794:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:26:28,077:INFO:Calculating mean and std
2023-11-05 12:26:28,078:INFO:Creating metrics dataframe
2023-11-05 12:26:28,081:INFO:Uploading results into container
2023-11-05 12:26:28,082:INFO:Uploading model into container now
2023-11-05 12:26:28,082:INFO:_master_model_container: 8
2023-11-05 12:26:28,082:INFO:_display_container: 2
2023-11-05 12:26:28,082:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-05 12:26:28,083:INFO:create_model() successfully completed......................................
2023-11-05 12:26:28,184:INFO:SubProcess create_model() end ==================================
2023-11-05 12:26:28,185:INFO:Creating metrics dataframe
2023-11-05 12:26:28,195:INFO:Initializing Ada Boost Classifier
2023-11-05 12:26:28,196:INFO:Total runtime is 1.4292009830474854 minutes
2023-11-05 12:26:28,199:INFO:SubProcess create_model() called ==================================
2023-11-05 12:26:28,200:INFO:Initializing create_model()
2023-11-05 12:26:28,200:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B93F9F220>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C0366DF40>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:26:28,200:INFO:Checking exceptions
2023-11-05 12:26:28,200:INFO:Importing libraries
2023-11-05 12:26:28,200:INFO:Copying training dataset
2023-11-05 12:26:28,242:INFO:Defining folds
2023-11-05 12:26:28,243:INFO:Declaring metric variables
2023-11-05 12:26:28,246:INFO:Importing untrained model
2023-11-05 12:26:28,250:INFO:Ada Boost Classifier Imported successfully
2023-11-05 12:26:28,255:INFO:Starting cross validation
2023-11-05 12:26:28,256:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:26:40,394:INFO:Calculating mean and std
2023-11-05 12:26:40,395:INFO:Creating metrics dataframe
2023-11-05 12:26:40,399:INFO:Uploading results into container
2023-11-05 12:26:40,399:INFO:Uploading model into container now
2023-11-05 12:26:40,399:INFO:_master_model_container: 9
2023-11-05 12:26:40,400:INFO:_display_container: 2
2023-11-05 12:26:40,400:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-11-05 12:26:40,400:INFO:create_model() successfully completed......................................
2023-11-05 12:26:40,501:INFO:SubProcess create_model() end ==================================
2023-11-05 12:26:40,501:INFO:Creating metrics dataframe
2023-11-05 12:26:40,512:INFO:Initializing Gradient Boosting Classifier
2023-11-05 12:26:40,513:INFO:Total runtime is 1.634466866652171 minutes
2023-11-05 12:26:40,516:INFO:SubProcess create_model() called ==================================
2023-11-05 12:26:40,516:INFO:Initializing create_model()
2023-11-05 12:26:40,516:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B93F9F220>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C0366DF40>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:26:40,516:INFO:Checking exceptions
2023-11-05 12:26:40,516:INFO:Importing libraries
2023-11-05 12:26:40,517:INFO:Copying training dataset
2023-11-05 12:26:40,556:INFO:Defining folds
2023-11-05 12:26:40,556:INFO:Declaring metric variables
2023-11-05 12:26:40,559:INFO:Importing untrained model
2023-11-05 12:26:40,563:INFO:Gradient Boosting Classifier Imported successfully
2023-11-05 12:26:40,572:INFO:Starting cross validation
2023-11-05 12:26:40,573:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:27:33,717:INFO:Calculating mean and std
2023-11-05 12:27:33,718:INFO:Creating metrics dataframe
2023-11-05 12:27:33,721:INFO:Uploading results into container
2023-11-05 12:27:33,722:INFO:Uploading model into container now
2023-11-05 12:27:33,722:INFO:_master_model_container: 10
2023-11-05 12:27:33,723:INFO:_display_container: 2
2023-11-05 12:27:33,723:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-11-05 12:27:33,723:INFO:create_model() successfully completed......................................
2023-11-05 12:27:33,826:INFO:SubProcess create_model() end ==================================
2023-11-05 12:27:33,826:INFO:Creating metrics dataframe
2023-11-05 12:27:33,837:INFO:Initializing Linear Discriminant Analysis
2023-11-05 12:27:33,837:INFO:Total runtime is 2.5232078154881794 minutes
2023-11-05 12:27:33,840:INFO:SubProcess create_model() called ==================================
2023-11-05 12:27:33,841:INFO:Initializing create_model()
2023-11-05 12:27:33,841:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B93F9F220>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C0366DF40>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:27:33,841:INFO:Checking exceptions
2023-11-05 12:27:33,841:INFO:Importing libraries
2023-11-05 12:27:33,841:INFO:Copying training dataset
2023-11-05 12:27:33,883:INFO:Defining folds
2023-11-05 12:27:33,883:INFO:Declaring metric variables
2023-11-05 12:27:33,887:INFO:Importing untrained model
2023-11-05 12:27:33,890:INFO:Linear Discriminant Analysis Imported successfully
2023-11-05 12:27:33,895:INFO:Starting cross validation
2023-11-05 12:27:33,896:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:27:35,499:INFO:Calculating mean and std
2023-11-05 12:27:35,500:INFO:Creating metrics dataframe
2023-11-05 12:27:35,504:INFO:Uploading results into container
2023-11-05 12:27:35,504:INFO:Uploading model into container now
2023-11-05 12:27:35,504:INFO:_master_model_container: 11
2023-11-05 12:27:35,505:INFO:_display_container: 2
2023-11-05 12:27:35,505:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-05 12:27:35,505:INFO:create_model() successfully completed......................................
2023-11-05 12:27:35,607:INFO:SubProcess create_model() end ==================================
2023-11-05 12:27:35,607:INFO:Creating metrics dataframe
2023-11-05 12:27:35,619:INFO:Initializing Extra Trees Classifier
2023-11-05 12:27:35,619:INFO:Total runtime is 2.5529146671295164 minutes
2023-11-05 12:27:35,623:INFO:SubProcess create_model() called ==================================
2023-11-05 12:27:35,623:INFO:Initializing create_model()
2023-11-05 12:27:35,623:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B93F9F220>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C0366DF40>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:27:35,623:INFO:Checking exceptions
2023-11-05 12:27:35,623:INFO:Importing libraries
2023-11-05 12:27:35,623:INFO:Copying training dataset
2023-11-05 12:27:35,666:INFO:Defining folds
2023-11-05 12:27:35,667:INFO:Declaring metric variables
2023-11-05 12:27:35,670:INFO:Importing untrained model
2023-11-05 12:27:35,675:INFO:Extra Trees Classifier Imported successfully
2023-11-05 12:27:35,681:INFO:Starting cross validation
2023-11-05 12:27:35,682:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:28:01,047:INFO:Calculating mean and std
2023-11-05 12:28:01,049:INFO:Creating metrics dataframe
2023-11-05 12:28:01,052:INFO:Uploading results into container
2023-11-05 12:28:01,053:INFO:Uploading model into container now
2023-11-05 12:28:01,053:INFO:_master_model_container: 12
2023-11-05 12:28:01,053:INFO:_display_container: 2
2023-11-05 12:28:01,054:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-11-05 12:28:01,054:INFO:create_model() successfully completed......................................
2023-11-05 12:28:01,179:INFO:SubProcess create_model() end ==================================
2023-11-05 12:28:01,179:INFO:Creating metrics dataframe
2023-11-05 12:28:01,191:INFO:Initializing Extreme Gradient Boosting
2023-11-05 12:28:01,191:INFO:Total runtime is 2.9791145801544188 minutes
2023-11-05 12:28:01,195:INFO:SubProcess create_model() called ==================================
2023-11-05 12:28:01,195:INFO:Initializing create_model()
2023-11-05 12:28:01,195:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B93F9F220>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C0366DF40>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:28:01,195:INFO:Checking exceptions
2023-11-05 12:28:01,195:INFO:Importing libraries
2023-11-05 12:28:01,195:INFO:Copying training dataset
2023-11-05 12:28:01,242:INFO:Defining folds
2023-11-05 12:28:01,242:INFO:Declaring metric variables
2023-11-05 12:28:01,245:INFO:Importing untrained model
2023-11-05 12:28:01,249:INFO:Extreme Gradient Boosting Imported successfully
2023-11-05 12:28:01,256:INFO:Starting cross validation
2023-11-05 12:28:01,257:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:28:04,993:INFO:Calculating mean and std
2023-11-05 12:28:04,995:INFO:Creating metrics dataframe
2023-11-05 12:28:04,999:INFO:Uploading results into container
2023-11-05 12:28:05,000:INFO:Uploading model into container now
2023-11-05 12:28:05,000:INFO:_master_model_container: 13
2023-11-05 12:28:05,000:INFO:_display_container: 2
2023-11-05 12:28:05,002:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2023-11-05 12:28:05,002:INFO:create_model() successfully completed......................................
2023-11-05 12:28:05,104:INFO:SubProcess create_model() end ==================================
2023-11-05 12:28:05,105:INFO:Creating metrics dataframe
2023-11-05 12:28:05,117:INFO:Initializing Light Gradient Boosting Machine
2023-11-05 12:28:05,117:INFO:Total runtime is 3.0445479075113933 minutes
2023-11-05 12:28:05,120:INFO:SubProcess create_model() called ==================================
2023-11-05 12:28:05,120:INFO:Initializing create_model()
2023-11-05 12:28:05,121:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B93F9F220>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C0366DF40>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:28:05,121:INFO:Checking exceptions
2023-11-05 12:28:05,121:INFO:Importing libraries
2023-11-05 12:28:05,121:INFO:Copying training dataset
2023-11-05 12:28:05,162:INFO:Defining folds
2023-11-05 12:28:05,162:INFO:Declaring metric variables
2023-11-05 12:28:05,166:INFO:Importing untrained model
2023-11-05 12:28:05,169:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-05 12:28:05,175:INFO:Starting cross validation
2023-11-05 12:28:05,176:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:28:09,517:INFO:Calculating mean and std
2023-11-05 12:28:09,519:INFO:Creating metrics dataframe
2023-11-05 12:28:09,523:INFO:Uploading results into container
2023-11-05 12:28:09,523:INFO:Uploading model into container now
2023-11-05 12:28:09,524:INFO:_master_model_container: 14
2023-11-05 12:28:09,524:INFO:_display_container: 2
2023-11-05 12:28:09,524:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 12:28:09,524:INFO:create_model() successfully completed......................................
2023-11-05 12:28:09,644:INFO:SubProcess create_model() end ==================================
2023-11-05 12:28:09,644:INFO:Creating metrics dataframe
2023-11-05 12:28:09,658:INFO:Initializing Dummy Classifier
2023-11-05 12:28:09,658:INFO:Total runtime is 3.1202312191327413 minutes
2023-11-05 12:28:09,661:INFO:SubProcess create_model() called ==================================
2023-11-05 12:28:09,661:INFO:Initializing create_model()
2023-11-05 12:28:09,661:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B93F9F220>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022C0366DF40>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:28:09,662:INFO:Checking exceptions
2023-11-05 12:28:09,662:INFO:Importing libraries
2023-11-05 12:28:09,662:INFO:Copying training dataset
2023-11-05 12:28:09,704:INFO:Defining folds
2023-11-05 12:28:09,704:INFO:Declaring metric variables
2023-11-05 12:28:09,708:INFO:Importing untrained model
2023-11-05 12:28:09,711:INFO:Dummy Classifier Imported successfully
2023-11-05 12:28:09,717:INFO:Starting cross validation
2023-11-05 12:28:09,718:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:28:09,956:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:28:09,964:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:28:09,980:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:28:10,010:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:28:10,025:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:28:10,034:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:28:10,045:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:28:10,058:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:28:10,075:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:28:10,097:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:28:10,226:INFO:Calculating mean and std
2023-11-05 12:28:10,227:INFO:Creating metrics dataframe
2023-11-05 12:28:10,231:INFO:Uploading results into container
2023-11-05 12:28:10,232:INFO:Uploading model into container now
2023-11-05 12:28:10,232:INFO:_master_model_container: 15
2023-11-05 12:28:10,232:INFO:_display_container: 2
2023-11-05 12:28:10,232:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-11-05 12:28:10,232:INFO:create_model() successfully completed......................................
2023-11-05 12:28:10,342:INFO:SubProcess create_model() end ==================================
2023-11-05 12:28:10,342:INFO:Creating metrics dataframe
2023-11-05 12:28:10,364:INFO:Initializing create_model()
2023-11-05 12:28:10,364:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B93F9F220>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:28:10,364:INFO:Checking exceptions
2023-11-05 12:28:10,366:INFO:Importing libraries
2023-11-05 12:28:10,366:INFO:Copying training dataset
2023-11-05 12:28:10,408:INFO:Defining folds
2023-11-05 12:28:10,409:INFO:Declaring metric variables
2023-11-05 12:28:10,409:INFO:Importing untrained model
2023-11-05 12:28:10,409:INFO:Declaring custom model
2023-11-05 12:28:10,410:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-05 12:28:10,410:INFO:Cross validation set to False
2023-11-05 12:28:10,411:INFO:Fitting Model
2023-11-05 12:28:10,551:INFO:[LightGBM] [Info] Number of positive: 29322, number of negative: 97741
2023-11-05 12:28:10,569:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004323 seconds.
2023-11-05 12:28:10,569:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-05 12:28:10,569:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-05 12:28:10,569:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-05 12:28:10,570:INFO:[LightGBM] [Info] Number of data points in the train set: 127063, number of used features: 19
2023-11-05 12:28:10,571:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230767 -> initscore=-1.203983
2023-11-05 12:28:10,571:INFO:[LightGBM] [Info] Start training from score -1.203983
2023-11-05 12:28:11,040:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 12:28:11,040:INFO:create_model() successfully completed......................................
2023-11-05 12:28:11,196:INFO:_master_model_container: 15
2023-11-05 12:28:11,196:INFO:_display_container: 2
2023-11-05 12:28:11,197:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 12:28:11,197:INFO:compare_models() successfully completed......................................
2023-11-05 12:28:11,243:INFO:Initializing create_model()
2023-11-05 12:28:11,243:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B93F9F220>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:28:11,243:INFO:Checking exceptions
2023-11-05 12:28:11,258:INFO:Importing libraries
2023-11-05 12:28:11,258:INFO:Copying training dataset
2023-11-05 12:28:11,306:INFO:Defining folds
2023-11-05 12:28:11,306:INFO:Declaring metric variables
2023-11-05 12:28:11,310:INFO:Importing untrained model
2023-11-05 12:28:11,313:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-05 12:28:11,319:INFO:Starting cross validation
2023-11-05 12:28:11,320:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:28:15,923:INFO:Calculating mean and std
2023-11-05 12:28:15,925:INFO:Creating metrics dataframe
2023-11-05 12:28:15,930:INFO:Finalizing model
2023-11-05 12:28:16,069:INFO:[LightGBM] [Info] Number of positive: 29322, number of negative: 97741
2023-11-05 12:28:16,087:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003871 seconds.
2023-11-05 12:28:16,087:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-05 12:28:16,087:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-05 12:28:16,087:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-05 12:28:16,087:INFO:[LightGBM] [Info] Number of data points in the train set: 127063, number of used features: 19
2023-11-05 12:28:16,088:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230767 -> initscore=-1.203983
2023-11-05 12:28:16,088:INFO:[LightGBM] [Info] Start training from score -1.203983
2023-11-05 12:28:16,487:INFO:Uploading results into container
2023-11-05 12:28:16,488:INFO:Uploading model into container now
2023-11-05 12:28:16,500:INFO:_master_model_container: 16
2023-11-05 12:28:16,500:INFO:_display_container: 3
2023-11-05 12:28:16,500:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 12:28:16,501:INFO:create_model() successfully completed......................................
2023-11-05 12:28:16,654:INFO:Initializing predict_model()
2023-11-05 12:28:16,654:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B93F9F220>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022B965F6670>)
2023-11-05 12:28:16,654:INFO:Checking exceptions
2023-11-05 12:28:16,654:INFO:Preloading libraries
2023-11-05 12:28:17,122:INFO:Initializing evaluate_model()
2023-11-05 12:28:17,122:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B93F9F220>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-11-05 12:28:17,146:INFO:Initializing plot_model()
2023-11-05 12:28:17,146:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B93F9F220>, system=True)
2023-11-05 12:28:17,146:INFO:Checking exceptions
2023-11-05 12:28:17,162:INFO:Preloading libraries
2023-11-05 12:28:17,169:INFO:Copying training dataset
2023-11-05 12:28:17,169:INFO:Plot type: pipeline
2023-11-05 12:28:17,259:INFO:Visual Rendered Successfully
2023-11-05 12:28:17,371:INFO:plot_model() successfully completed......................................
2023-11-05 12:28:17,415:INFO:Initializing interpret_model()
2023-11-05 12:28:17,415:INFO:interpret_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=feature_importance, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B93F9F220>)
2023-11-05 12:28:17,416:INFO:Checking exceptions
2023-11-05 12:28:17,416:INFO:Soft dependency imported: shap: 0.43.0
2023-11-05 12:28:17,472:INFO:plot type: summary
2023-11-05 12:28:17,473:INFO:Creating TreeExplainer
2023-11-05 12:28:17,600:INFO:Compiling shap values
2023-11-05 12:28:28,404:INFO:Visual Rendered Successfully
2023-11-05 12:28:28,404:INFO:interpret_model() successfully completed......................................
2023-11-05 12:29:47,470:INFO:Initializing plot_model()
2023-11-05 12:29:47,470:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B93F9F220>, system=True)
2023-11-05 12:29:47,470:INFO:Checking exceptions
2023-11-05 12:29:47,486:INFO:Preloading libraries
2023-11-05 12:29:47,492:INFO:Copying training dataset
2023-11-05 12:29:47,492:INFO:Plot type: confusion_matrix
2023-11-05 12:29:47,740:INFO:Fitting Model
2023-11-05 12:29:47,741:INFO:Scoring test/hold-out set
2023-11-05 12:29:47,951:INFO:Visual Rendered Successfully
2023-11-05 12:29:48,061:INFO:plot_model() successfully completed......................................
2023-11-05 12:30:39,960:INFO:Initializing plot_model()
2023-11-05 12:30:39,960:INFO:plot_model(plot=pr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022B93F9F220>, system=True)
2023-11-05 12:30:39,961:INFO:Checking exceptions
2023-11-05 12:30:39,976:INFO:Preloading libraries
2023-11-05 12:30:39,982:INFO:Copying training dataset
2023-11-05 12:30:39,982:INFO:Plot type: pr
2023-11-05 12:30:40,233:INFO:Fitting Model
2023-11-05 12:30:40,237:INFO:Scoring test/hold-out set
2023-11-05 12:30:40,539:INFO:Visual Rendered Successfully
2023-11-05 12:30:40,639:INFO:plot_model() successfully completed......................................
2023-11-05 12:43:54,603:INFO:PyCaret ClassificationExperiment
2023-11-05 12:43:54,603:INFO:Logging name: clf-default-name
2023-11-05 12:43:54,603:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-05 12:43:54,603:INFO:version 3.1.0
2023-11-05 12:43:54,603:INFO:Initializing setup()
2023-11-05 12:43:54,603:INFO:self.USI: 53d7
2023-11-05 12:43:54,603:INFO:self._variable_keys: {'logging_param', 'y_test', 'gpu_param', 'y', 'n_jobs_param', 'memory', 'gpu_n_jobs_param', 'html_param', 'seed', 'data', 'X', 'fix_imbalance', 'USI', 'log_plots_param', 'fold_groups_param', 'fold_generator', '_ml_usecase', 'exp_id', 'is_multiclass', '_available_plots', 'X_train', 'exp_name_log', 'fold_shuffle_param', 'X_test', 'pipeline', 'target_param', 'idx', 'y_train'}
2023-11-05 12:43:54,603:INFO:Checking environment
2023-11-05 12:43:54,603:INFO:python_version: 3.9.18
2023-11-05 12:43:54,603:INFO:python_build: ('main', 'Sep 11 2023 14:09:26')
2023-11-05 12:43:54,603:INFO:machine: AMD64
2023-11-05 12:43:54,603:INFO:platform: Windows-10-10.0.19041-SP0
2023-11-05 12:43:54,603:INFO:Memory: svmem(total=25692647424, available=15235653632, percent=40.7, used=10456993792, free=15235653632)
2023-11-05 12:43:54,603:INFO:Physical Core: 8
2023-11-05 12:43:54,603:INFO:Logical Core: 16
2023-11-05 12:43:54,603:INFO:Checking libraries
2023-11-05 12:43:54,603:INFO:System:
2023-11-05 12:43:54,603:INFO:    python: 3.9.18 (main, Sep 11 2023, 14:09:26) [MSC v.1916 64 bit (AMD64)]
2023-11-05 12:43:54,603:INFO:executable: d:\programas\Anaconda3\envs\meli_test2\python.exe
2023-11-05 12:43:54,604:INFO:   machine: Windows-10-10.0.19041-SP0
2023-11-05 12:43:54,604:INFO:PyCaret required dependencies:
2023-11-05 12:43:54,604:INFO:                 pip: 23.3
2023-11-05 12:43:54,604:INFO:          setuptools: 68.0.0
2023-11-05 12:43:54,604:INFO:             pycaret: 3.1.0
2023-11-05 12:43:54,604:INFO:             IPython: 8.17.2
2023-11-05 12:43:54,604:INFO:          ipywidgets: 8.1.1
2023-11-05 12:43:54,604:INFO:                tqdm: 4.66.1
2023-11-05 12:43:54,604:INFO:               numpy: 1.23.5
2023-11-05 12:43:54,604:INFO:              pandas: 1.5.3
2023-11-05 12:43:54,604:INFO:              jinja2: 3.1.2
2023-11-05 12:43:54,604:INFO:               scipy: 1.10.1
2023-11-05 12:43:54,604:INFO:              joblib: 1.3.2
2023-11-05 12:43:54,604:INFO:             sklearn: 1.2.2
2023-11-05 12:43:54,604:INFO:                pyod: 1.1.1
2023-11-05 12:43:54,604:INFO:            imblearn: 0.11.0
2023-11-05 12:43:54,604:INFO:   category_encoders: 2.6.3
2023-11-05 12:43:54,604:INFO:            lightgbm: 4.1.0
2023-11-05 12:43:54,604:INFO:               numba: 0.58.1
2023-11-05 12:43:54,604:INFO:            requests: 2.31.0
2023-11-05 12:43:54,604:INFO:          matplotlib: 3.8.1
2023-11-05 12:43:54,604:INFO:          scikitplot: 0.3.7
2023-11-05 12:43:54,605:INFO:         yellowbrick: 1.5
2023-11-05 12:43:54,605:INFO:              plotly: 5.18.0
2023-11-05 12:43:54,605:INFO:    plotly-resampler: Not installed
2023-11-05 12:43:54,605:INFO:             kaleido: 0.2.1
2023-11-05 12:43:54,605:INFO:           schemdraw: 0.15
2023-11-05 12:43:54,605:INFO:         statsmodels: 0.14.0
2023-11-05 12:43:54,605:INFO:              sktime: 0.21.1
2023-11-05 12:43:54,605:INFO:               tbats: 1.1.3
2023-11-05 12:43:54,605:INFO:            pmdarima: 2.0.4
2023-11-05 12:43:54,605:INFO:              psutil: 5.9.6
2023-11-05 12:43:54,605:INFO:          markupsafe: 2.1.3
2023-11-05 12:43:54,605:INFO:             pickle5: Not installed
2023-11-05 12:43:54,605:INFO:         cloudpickle: 3.0.0
2023-11-05 12:43:54,605:INFO:         deprecation: 2.1.0
2023-11-05 12:43:54,605:INFO:              xxhash: 3.4.1
2023-11-05 12:43:54,605:INFO:           wurlitzer: Not installed
2023-11-05 12:43:54,605:INFO:PyCaret optional dependencies:
2023-11-05 12:43:54,605:INFO:                shap: 0.43.0
2023-11-05 12:43:54,605:INFO:           interpret: Not installed
2023-11-05 12:43:54,605:INFO:                umap: Not installed
2023-11-05 12:43:54,605:INFO:     ydata_profiling: Not installed
2023-11-05 12:43:54,605:INFO:  explainerdashboard: Not installed
2023-11-05 12:43:54,605:INFO:             autoviz: Not installed
2023-11-05 12:43:54,605:INFO:           fairlearn: Not installed
2023-11-05 12:43:54,605:INFO:          deepchecks: Not installed
2023-11-05 12:43:54,606:INFO:             xgboost: 2.0.1
2023-11-05 12:43:54,606:INFO:            catboost: Not installed
2023-11-05 12:43:54,606:INFO:              kmodes: Not installed
2023-11-05 12:43:54,606:INFO:             mlxtend: Not installed
2023-11-05 12:43:54,606:INFO:       statsforecast: Not installed
2023-11-05 12:43:54,606:INFO:        tune_sklearn: Not installed
2023-11-05 12:43:54,606:INFO:                 ray: Not installed
2023-11-05 12:43:54,606:INFO:            hyperopt: Not installed
2023-11-05 12:43:54,606:INFO:              optuna: Not installed
2023-11-05 12:43:54,606:INFO:               skopt: Not installed
2023-11-05 12:43:54,606:INFO:              mlflow: Not installed
2023-11-05 12:43:54,606:INFO:              gradio: Not installed
2023-11-05 12:43:54,606:INFO:             fastapi: Not installed
2023-11-05 12:43:54,606:INFO:             uvicorn: Not installed
2023-11-05 12:43:54,606:INFO:              m2cgen: Not installed
2023-11-05 12:43:54,606:INFO:           evidently: Not installed
2023-11-05 12:43:54,606:INFO:               fugue: Not installed
2023-11-05 12:43:54,606:INFO:           streamlit: Not installed
2023-11-05 12:43:54,606:INFO:             prophet: Not installed
2023-11-05 12:43:54,606:INFO:None
2023-11-05 12:43:54,606:INFO:Set up data.
2023-11-05 12:43:54,665:INFO:Set up folding strategy.
2023-11-05 12:43:54,665:INFO:Set up train/test split.
2023-11-05 12:43:54,739:INFO:Set up index.
2023-11-05 12:43:54,742:INFO:Assigning column types.
2023-11-05 12:43:54,771:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-05 12:43:54,823:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-05 12:43:54,824:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 12:43:54,857:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 12:43:54,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 12:43:54,912:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-05 12:43:54,913:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 12:43:54,945:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 12:43:54,948:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 12:43:54,949:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-05 12:43:55,001:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 12:43:55,034:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 12:43:55,037:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 12:43:55,090:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 12:43:55,122:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 12:43:55,125:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 12:43:55,126:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-05 12:43:55,212:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 12:43:55,215:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 12:43:55,301:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 12:43:55,304:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 12:43:55,305:INFO:Preparing preprocessing pipeline...
2023-11-05 12:43:55,310:INFO:Set up simple imputation.
2023-11-05 12:43:55,390:INFO:Finished creating preprocessing pipeline.
2023-11-05 12:43:55,394:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['a', 'b', 'c', 'd', 'e', 'f', 'h',
                                             'k', 'l', 'm', 'n', 'p', 'monto',
                                             'score', 'Country_AR',
                                             'Country_BR', 'Country_US',
                                             'Country_UY', 'Country_otros'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-05 12:43:55,394:INFO:Creating final display dataframe.
2023-11-05 12:43:55,615:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            fraude
2                   Target type            Binary
3           Original data shape      (181519, 20)
4        Transformed data shape      (181519, 20)
5   Transformed train set shape      (127063, 20)
6    Transformed test set shape       (54456, 20)
7              Numeric features                19
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              53d7
2023-11-05 12:43:55,715:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 12:43:55,718:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 12:43:55,802:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 12:43:55,805:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 12:43:55,806:INFO:setup() successfully completed in 1.2s...............
2023-11-05 12:43:55,829:INFO:Initializing compare_models()
2023-11-05 12:43:55,829:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C01C98C40>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022C01C98C40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-11-05 12:43:55,829:INFO:Checking exceptions
2023-11-05 12:43:55,859:INFO:Preparing display monitor
2023-11-05 12:43:55,883:INFO:Initializing Logistic Regression
2023-11-05 12:43:55,883:INFO:Total runtime is 0.0 minutes
2023-11-05 12:43:55,886:INFO:SubProcess create_model() called ==================================
2023-11-05 12:43:55,886:INFO:Initializing create_model()
2023-11-05 12:43:55,887:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C01C98C40>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94D62460>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:43:55,887:INFO:Checking exceptions
2023-11-05 12:43:55,887:INFO:Importing libraries
2023-11-05 12:43:55,887:INFO:Copying training dataset
2023-11-05 12:43:55,930:INFO:Defining folds
2023-11-05 12:43:55,930:INFO:Declaring metric variables
2023-11-05 12:43:55,933:INFO:Importing untrained model
2023-11-05 12:43:55,936:INFO:Logistic Regression Imported successfully
2023-11-05 12:43:55,942:INFO:Starting cross validation
2023-11-05 12:43:55,943:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:44:03,499:INFO:Calculating mean and std
2023-11-05 12:44:03,501:INFO:Creating metrics dataframe
2023-11-05 12:44:03,505:INFO:Uploading results into container
2023-11-05 12:44:03,506:INFO:Uploading model into container now
2023-11-05 12:44:03,506:INFO:_master_model_container: 1
2023-11-05 12:44:03,506:INFO:_display_container: 2
2023-11-05 12:44:03,506:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-05 12:44:03,507:INFO:create_model() successfully completed......................................
2023-11-05 12:44:03,639:INFO:SubProcess create_model() end ==================================
2023-11-05 12:44:03,639:INFO:Creating metrics dataframe
2023-11-05 12:44:03,647:INFO:Initializing K Neighbors Classifier
2023-11-05 12:44:03,647:INFO:Total runtime is 0.12939995527267456 minutes
2023-11-05 12:44:03,651:INFO:SubProcess create_model() called ==================================
2023-11-05 12:44:03,651:INFO:Initializing create_model()
2023-11-05 12:44:03,651:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C01C98C40>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94D62460>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:44:03,651:INFO:Checking exceptions
2023-11-05 12:44:03,651:INFO:Importing libraries
2023-11-05 12:44:03,651:INFO:Copying training dataset
2023-11-05 12:44:03,692:INFO:Defining folds
2023-11-05 12:44:03,692:INFO:Declaring metric variables
2023-11-05 12:44:03,697:INFO:Importing untrained model
2023-11-05 12:44:03,701:INFO:K Neighbors Classifier Imported successfully
2023-11-05 12:44:03,709:INFO:Starting cross validation
2023-11-05 12:44:03,711:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:44:31,431:INFO:Calculating mean and std
2023-11-05 12:44:31,432:INFO:Creating metrics dataframe
2023-11-05 12:44:31,436:INFO:Uploading results into container
2023-11-05 12:44:31,437:INFO:Uploading model into container now
2023-11-05 12:44:31,437:INFO:_master_model_container: 2
2023-11-05 12:44:31,438:INFO:_display_container: 2
2023-11-05 12:44:31,438:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-05 12:44:31,438:INFO:create_model() successfully completed......................................
2023-11-05 12:44:31,560:INFO:SubProcess create_model() end ==================================
2023-11-05 12:44:31,560:INFO:Creating metrics dataframe
2023-11-05 12:44:31,570:INFO:Initializing Naive Bayes
2023-11-05 12:44:31,570:INFO:Total runtime is 0.5947832942008973 minutes
2023-11-05 12:44:31,573:INFO:SubProcess create_model() called ==================================
2023-11-05 12:44:31,573:INFO:Initializing create_model()
2023-11-05 12:44:31,573:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C01C98C40>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94D62460>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:44:31,574:INFO:Checking exceptions
2023-11-05 12:44:31,574:INFO:Importing libraries
2023-11-05 12:44:31,574:INFO:Copying training dataset
2023-11-05 12:44:31,614:INFO:Defining folds
2023-11-05 12:44:31,614:INFO:Declaring metric variables
2023-11-05 12:44:31,617:INFO:Importing untrained model
2023-11-05 12:44:31,622:INFO:Naive Bayes Imported successfully
2023-11-05 12:44:31,628:INFO:Starting cross validation
2023-11-05 12:44:31,629:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:44:32,275:INFO:Calculating mean and std
2023-11-05 12:44:32,277:INFO:Creating metrics dataframe
2023-11-05 12:44:32,282:INFO:Uploading results into container
2023-11-05 12:44:32,283:INFO:Uploading model into container now
2023-11-05 12:44:32,284:INFO:_master_model_container: 3
2023-11-05 12:44:32,284:INFO:_display_container: 2
2023-11-05 12:44:32,284:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-05 12:44:32,285:INFO:create_model() successfully completed......................................
2023-11-05 12:44:32,394:INFO:SubProcess create_model() end ==================================
2023-11-05 12:44:32,394:INFO:Creating metrics dataframe
2023-11-05 12:44:32,403:INFO:Initializing Decision Tree Classifier
2023-11-05 12:44:32,404:INFO:Total runtime is 0.6086834470431011 minutes
2023-11-05 12:44:32,408:INFO:SubProcess create_model() called ==================================
2023-11-05 12:44:32,408:INFO:Initializing create_model()
2023-11-05 12:44:32,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C01C98C40>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94D62460>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:44:32,409:INFO:Checking exceptions
2023-11-05 12:44:32,409:INFO:Importing libraries
2023-11-05 12:44:32,409:INFO:Copying training dataset
2023-11-05 12:44:32,448:INFO:Defining folds
2023-11-05 12:44:32,448:INFO:Declaring metric variables
2023-11-05 12:44:32,451:INFO:Importing untrained model
2023-11-05 12:44:32,455:INFO:Decision Tree Classifier Imported successfully
2023-11-05 12:44:32,460:INFO:Starting cross validation
2023-11-05 12:44:32,461:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:44:35,190:INFO:Calculating mean and std
2023-11-05 12:44:35,191:INFO:Creating metrics dataframe
2023-11-05 12:44:35,195:INFO:Uploading results into container
2023-11-05 12:44:35,195:INFO:Uploading model into container now
2023-11-05 12:44:35,196:INFO:_master_model_container: 4
2023-11-05 12:44:35,196:INFO:_display_container: 2
2023-11-05 12:44:35,196:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-11-05 12:44:35,197:INFO:create_model() successfully completed......................................
2023-11-05 12:44:35,310:INFO:SubProcess create_model() end ==================================
2023-11-05 12:44:35,310:INFO:Creating metrics dataframe
2023-11-05 12:44:35,320:INFO:Initializing SVM - Linear Kernel
2023-11-05 12:44:35,320:INFO:Total runtime is 0.6572855512301128 minutes
2023-11-05 12:44:35,323:INFO:SubProcess create_model() called ==================================
2023-11-05 12:44:35,323:INFO:Initializing create_model()
2023-11-05 12:44:35,323:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C01C98C40>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94D62460>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:44:35,323:INFO:Checking exceptions
2023-11-05 12:44:35,323:INFO:Importing libraries
2023-11-05 12:44:35,323:INFO:Copying training dataset
2023-11-05 12:44:35,369:INFO:Defining folds
2023-11-05 12:44:35,370:INFO:Declaring metric variables
2023-11-05 12:44:35,373:INFO:Importing untrained model
2023-11-05 12:44:35,376:INFO:SVM - Linear Kernel Imported successfully
2023-11-05 12:44:35,382:INFO:Starting cross validation
2023-11-05 12:44:35,384:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:44:39,478:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:44:39,576:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:44:39,741:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:44:39,772:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:44:39,809:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:44:39,935:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:44:40,175:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:44:40,376:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:44:40,756:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:44:41,782:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:44:41,926:INFO:Calculating mean and std
2023-11-05 12:44:41,927:INFO:Creating metrics dataframe
2023-11-05 12:44:41,933:INFO:Uploading results into container
2023-11-05 12:44:41,934:INFO:Uploading model into container now
2023-11-05 12:44:41,934:INFO:_master_model_container: 5
2023-11-05 12:44:41,934:INFO:_display_container: 2
2023-11-05 12:44:41,935:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-05 12:44:41,935:INFO:create_model() successfully completed......................................
2023-11-05 12:44:42,043:INFO:SubProcess create_model() end ==================================
2023-11-05 12:44:42,043:INFO:Creating metrics dataframe
2023-11-05 12:44:42,054:INFO:Initializing Ridge Classifier
2023-11-05 12:44:42,054:INFO:Total runtime is 0.7695165316263836 minutes
2023-11-05 12:44:42,057:INFO:SubProcess create_model() called ==================================
2023-11-05 12:44:42,058:INFO:Initializing create_model()
2023-11-05 12:44:42,058:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C01C98C40>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94D62460>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:44:42,058:INFO:Checking exceptions
2023-11-05 12:44:42,058:INFO:Importing libraries
2023-11-05 12:44:42,058:INFO:Copying training dataset
2023-11-05 12:44:42,097:INFO:Defining folds
2023-11-05 12:44:42,097:INFO:Declaring metric variables
2023-11-05 12:44:42,100:INFO:Importing untrained model
2023-11-05 12:44:42,104:INFO:Ridge Classifier Imported successfully
2023-11-05 12:44:42,110:INFO:Starting cross validation
2023-11-05 12:44:42,111:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:44:42,405:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.13719e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:44:42,434:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.02642e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:44:42,442:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:44:42,455:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.19282e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:44:42,473:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:44:42,482:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.04676e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:44:42,487:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:44:42,489:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.21583e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:44:42,491:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.11761e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:44:42,503:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:44:42,519:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:44:42,519:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:44:42,525:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.20541e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:44:42,533:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.16596e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:44:42,545:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.20378e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:44:42,546:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:44:42,556:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:44:42,557:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:44:42,563:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.11314e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:44:42,573:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:44:42,720:INFO:Calculating mean and std
2023-11-05 12:44:42,721:INFO:Creating metrics dataframe
2023-11-05 12:44:42,727:INFO:Uploading results into container
2023-11-05 12:44:42,728:INFO:Uploading model into container now
2023-11-05 12:44:42,729:INFO:_master_model_container: 6
2023-11-05 12:44:42,729:INFO:_display_container: 2
2023-11-05 12:44:42,729:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-11-05 12:44:42,729:INFO:create_model() successfully completed......................................
2023-11-05 12:44:42,841:INFO:SubProcess create_model() end ==================================
2023-11-05 12:44:42,841:INFO:Creating metrics dataframe
2023-11-05 12:44:42,854:INFO:Initializing Random Forest Classifier
2023-11-05 12:44:42,854:INFO:Total runtime is 0.782849411169688 minutes
2023-11-05 12:44:42,857:INFO:SubProcess create_model() called ==================================
2023-11-05 12:44:42,857:INFO:Initializing create_model()
2023-11-05 12:44:42,857:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C01C98C40>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94D62460>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:44:42,857:INFO:Checking exceptions
2023-11-05 12:44:42,858:INFO:Importing libraries
2023-11-05 12:44:42,858:INFO:Copying training dataset
2023-11-05 12:44:42,897:INFO:Defining folds
2023-11-05 12:44:42,897:INFO:Declaring metric variables
2023-11-05 12:44:42,900:INFO:Importing untrained model
2023-11-05 12:44:42,904:INFO:Random Forest Classifier Imported successfully
2023-11-05 12:44:42,909:INFO:Starting cross validation
2023-11-05 12:44:42,910:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:45:20,616:INFO:Calculating mean and std
2023-11-05 12:45:20,617:INFO:Creating metrics dataframe
2023-11-05 12:45:20,621:INFO:Uploading results into container
2023-11-05 12:45:20,621:INFO:Uploading model into container now
2023-11-05 12:45:20,622:INFO:_master_model_container: 7
2023-11-05 12:45:20,622:INFO:_display_container: 2
2023-11-05 12:45:20,622:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-11-05 12:45:20,622:INFO:create_model() successfully completed......................................
2023-11-05 12:45:20,731:INFO:SubProcess create_model() end ==================================
2023-11-05 12:45:20,733:INFO:Creating metrics dataframe
2023-11-05 12:45:20,743:INFO:Initializing Quadratic Discriminant Analysis
2023-11-05 12:45:20,743:INFO:Total runtime is 1.4143332481384276 minutes
2023-11-05 12:45:20,746:INFO:SubProcess create_model() called ==================================
2023-11-05 12:45:20,746:INFO:Initializing create_model()
2023-11-05 12:45:20,746:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C01C98C40>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94D62460>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:45:20,746:INFO:Checking exceptions
2023-11-05 12:45:20,746:INFO:Importing libraries
2023-11-05 12:45:20,747:INFO:Copying training dataset
2023-11-05 12:45:20,787:INFO:Defining folds
2023-11-05 12:45:20,787:INFO:Declaring metric variables
2023-11-05 12:45:20,791:INFO:Importing untrained model
2023-11-05 12:45:20,796:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-05 12:45:20,802:INFO:Starting cross validation
2023-11-05 12:45:20,803:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:45:21,583:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:45:21,586:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:45:21,606:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:45:21,626:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:45:21,628:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:45:21,751:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:45:21,796:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:45:21,820:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:45:21,826:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:45:21,905:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:45:22,142:INFO:Calculating mean and std
2023-11-05 12:45:22,144:INFO:Creating metrics dataframe
2023-11-05 12:45:22,148:INFO:Uploading results into container
2023-11-05 12:45:22,149:INFO:Uploading model into container now
2023-11-05 12:45:22,150:INFO:_master_model_container: 8
2023-11-05 12:45:22,150:INFO:_display_container: 2
2023-11-05 12:45:22,150:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-05 12:45:22,150:INFO:create_model() successfully completed......................................
2023-11-05 12:45:22,269:INFO:SubProcess create_model() end ==================================
2023-11-05 12:45:22,269:INFO:Creating metrics dataframe
2023-11-05 12:45:22,281:INFO:Initializing Ada Boost Classifier
2023-11-05 12:45:22,281:INFO:Total runtime is 1.4399666388829548 minutes
2023-11-05 12:45:22,284:INFO:SubProcess create_model() called ==================================
2023-11-05 12:45:22,285:INFO:Initializing create_model()
2023-11-05 12:45:22,285:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C01C98C40>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94D62460>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:45:22,285:INFO:Checking exceptions
2023-11-05 12:45:22,285:INFO:Importing libraries
2023-11-05 12:45:22,285:INFO:Copying training dataset
2023-11-05 12:45:22,328:INFO:Defining folds
2023-11-05 12:45:22,328:INFO:Declaring metric variables
2023-11-05 12:45:22,331:INFO:Importing untrained model
2023-11-05 12:45:22,335:INFO:Ada Boost Classifier Imported successfully
2023-11-05 12:45:22,341:INFO:Starting cross validation
2023-11-05 12:45:22,343:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:45:34,439:INFO:Calculating mean and std
2023-11-05 12:45:34,440:INFO:Creating metrics dataframe
2023-11-05 12:45:34,443:INFO:Uploading results into container
2023-11-05 12:45:34,444:INFO:Uploading model into container now
2023-11-05 12:45:34,445:INFO:_master_model_container: 9
2023-11-05 12:45:34,445:INFO:_display_container: 2
2023-11-05 12:45:34,445:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-11-05 12:45:34,445:INFO:create_model() successfully completed......................................
2023-11-05 12:45:34,555:INFO:SubProcess create_model() end ==================================
2023-11-05 12:45:34,555:INFO:Creating metrics dataframe
2023-11-05 12:45:34,567:INFO:Initializing Gradient Boosting Classifier
2023-11-05 12:45:34,567:INFO:Total runtime is 1.6447332143783568 minutes
2023-11-05 12:45:34,570:INFO:SubProcess create_model() called ==================================
2023-11-05 12:45:34,570:INFO:Initializing create_model()
2023-11-05 12:45:34,570:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C01C98C40>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94D62460>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:45:34,570:INFO:Checking exceptions
2023-11-05 12:45:34,570:INFO:Importing libraries
2023-11-05 12:45:34,571:INFO:Copying training dataset
2023-11-05 12:45:34,611:INFO:Defining folds
2023-11-05 12:45:34,611:INFO:Declaring metric variables
2023-11-05 12:45:34,615:INFO:Importing untrained model
2023-11-05 12:45:34,619:INFO:Gradient Boosting Classifier Imported successfully
2023-11-05 12:45:34,625:INFO:Starting cross validation
2023-11-05 12:45:34,626:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:46:27,765:INFO:Calculating mean and std
2023-11-05 12:46:27,766:INFO:Creating metrics dataframe
2023-11-05 12:46:27,770:INFO:Uploading results into container
2023-11-05 12:46:27,770:INFO:Uploading model into container now
2023-11-05 12:46:27,770:INFO:_master_model_container: 10
2023-11-05 12:46:27,771:INFO:_display_container: 2
2023-11-05 12:46:27,771:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-11-05 12:46:27,771:INFO:create_model() successfully completed......................................
2023-11-05 12:46:27,883:INFO:SubProcess create_model() end ==================================
2023-11-05 12:46:27,883:INFO:Creating metrics dataframe
2023-11-05 12:46:27,898:INFO:Initializing Linear Discriminant Analysis
2023-11-05 12:46:27,898:INFO:Total runtime is 2.5335806330045063 minutes
2023-11-05 12:46:27,901:INFO:SubProcess create_model() called ==================================
2023-11-05 12:46:27,902:INFO:Initializing create_model()
2023-11-05 12:46:27,902:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C01C98C40>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94D62460>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:46:27,902:INFO:Checking exceptions
2023-11-05 12:46:27,902:INFO:Importing libraries
2023-11-05 12:46:27,902:INFO:Copying training dataset
2023-11-05 12:46:27,943:INFO:Defining folds
2023-11-05 12:46:27,943:INFO:Declaring metric variables
2023-11-05 12:46:27,947:INFO:Importing untrained model
2023-11-05 12:46:27,950:INFO:Linear Discriminant Analysis Imported successfully
2023-11-05 12:46:27,956:INFO:Starting cross validation
2023-11-05 12:46:27,957:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:46:29,529:INFO:Calculating mean and std
2023-11-05 12:46:29,530:INFO:Creating metrics dataframe
2023-11-05 12:46:29,533:INFO:Uploading results into container
2023-11-05 12:46:29,534:INFO:Uploading model into container now
2023-11-05 12:46:29,534:INFO:_master_model_container: 11
2023-11-05 12:46:29,534:INFO:_display_container: 2
2023-11-05 12:46:29,535:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-05 12:46:29,535:INFO:create_model() successfully completed......................................
2023-11-05 12:46:29,650:INFO:SubProcess create_model() end ==================================
2023-11-05 12:46:29,650:INFO:Creating metrics dataframe
2023-11-05 12:46:29,662:INFO:Initializing Extra Trees Classifier
2023-11-05 12:46:29,662:INFO:Total runtime is 2.5629820307095845 minutes
2023-11-05 12:46:29,665:INFO:SubProcess create_model() called ==================================
2023-11-05 12:46:29,665:INFO:Initializing create_model()
2023-11-05 12:46:29,665:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C01C98C40>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94D62460>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:46:29,665:INFO:Checking exceptions
2023-11-05 12:46:29,665:INFO:Importing libraries
2023-11-05 12:46:29,665:INFO:Copying training dataset
2023-11-05 12:46:29,706:INFO:Defining folds
2023-11-05 12:46:29,706:INFO:Declaring metric variables
2023-11-05 12:46:29,709:INFO:Importing untrained model
2023-11-05 12:46:29,713:INFO:Extra Trees Classifier Imported successfully
2023-11-05 12:46:29,718:INFO:Starting cross validation
2023-11-05 12:46:29,719:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:46:54,283:INFO:Calculating mean and std
2023-11-05 12:46:54,284:INFO:Creating metrics dataframe
2023-11-05 12:46:54,288:INFO:Uploading results into container
2023-11-05 12:46:54,289:INFO:Uploading model into container now
2023-11-05 12:46:54,289:INFO:_master_model_container: 12
2023-11-05 12:46:54,289:INFO:_display_container: 2
2023-11-05 12:46:54,290:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-11-05 12:46:54,290:INFO:create_model() successfully completed......................................
2023-11-05 12:46:54,420:INFO:SubProcess create_model() end ==================================
2023-11-05 12:46:54,421:INFO:Creating metrics dataframe
2023-11-05 12:46:54,433:INFO:Initializing Extreme Gradient Boosting
2023-11-05 12:46:54,433:INFO:Total runtime is 2.9758320252100625 minutes
2023-11-05 12:46:54,437:INFO:SubProcess create_model() called ==================================
2023-11-05 12:46:54,437:INFO:Initializing create_model()
2023-11-05 12:46:54,437:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C01C98C40>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94D62460>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:46:54,437:INFO:Checking exceptions
2023-11-05 12:46:54,437:INFO:Importing libraries
2023-11-05 12:46:54,437:INFO:Copying training dataset
2023-11-05 12:46:54,480:INFO:Defining folds
2023-11-05 12:46:54,480:INFO:Declaring metric variables
2023-11-05 12:46:54,483:INFO:Importing untrained model
2023-11-05 12:46:54,487:INFO:Extreme Gradient Boosting Imported successfully
2023-11-05 12:46:54,494:INFO:Starting cross validation
2023-11-05 12:46:54,495:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:46:58,203:INFO:Calculating mean and std
2023-11-05 12:46:58,204:INFO:Creating metrics dataframe
2023-11-05 12:46:58,207:INFO:Uploading results into container
2023-11-05 12:46:58,208:INFO:Uploading model into container now
2023-11-05 12:46:58,208:INFO:_master_model_container: 13
2023-11-05 12:46:58,208:INFO:_display_container: 2
2023-11-05 12:46:58,209:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2023-11-05 12:46:58,209:INFO:create_model() successfully completed......................................
2023-11-05 12:46:58,326:INFO:SubProcess create_model() end ==================================
2023-11-05 12:46:58,327:INFO:Creating metrics dataframe
2023-11-05 12:46:58,339:INFO:Initializing Light Gradient Boosting Machine
2023-11-05 12:46:58,339:INFO:Total runtime is 3.0409360567728676 minutes
2023-11-05 12:46:58,342:INFO:SubProcess create_model() called ==================================
2023-11-05 12:46:58,343:INFO:Initializing create_model()
2023-11-05 12:46:58,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C01C98C40>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94D62460>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:46:58,343:INFO:Checking exceptions
2023-11-05 12:46:58,343:INFO:Importing libraries
2023-11-05 12:46:58,343:INFO:Copying training dataset
2023-11-05 12:46:58,384:INFO:Defining folds
2023-11-05 12:46:58,384:INFO:Declaring metric variables
2023-11-05 12:46:58,387:INFO:Importing untrained model
2023-11-05 12:46:58,391:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-05 12:46:58,396:INFO:Starting cross validation
2023-11-05 12:46:58,397:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:47:03,382:INFO:Calculating mean and std
2023-11-05 12:47:03,384:INFO:Creating metrics dataframe
2023-11-05 12:47:03,387:INFO:Uploading results into container
2023-11-05 12:47:03,387:INFO:Uploading model into container now
2023-11-05 12:47:03,388:INFO:_master_model_container: 14
2023-11-05 12:47:03,388:INFO:_display_container: 2
2023-11-05 12:47:03,388:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 12:47:03,388:INFO:create_model() successfully completed......................................
2023-11-05 12:47:03,506:INFO:SubProcess create_model() end ==================================
2023-11-05 12:47:03,506:INFO:Creating metrics dataframe
2023-11-05 12:47:03,519:INFO:Initializing Dummy Classifier
2023-11-05 12:47:03,519:INFO:Total runtime is 3.127269391218821 minutes
2023-11-05 12:47:03,522:INFO:SubProcess create_model() called ==================================
2023-11-05 12:47:03,522:INFO:Initializing create_model()
2023-11-05 12:47:03,522:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C01C98C40>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94D62460>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:47:03,522:INFO:Checking exceptions
2023-11-05 12:47:03,523:INFO:Importing libraries
2023-11-05 12:47:03,523:INFO:Copying training dataset
2023-11-05 12:47:03,564:INFO:Defining folds
2023-11-05 12:47:03,564:INFO:Declaring metric variables
2023-11-05 12:47:03,567:INFO:Importing untrained model
2023-11-05 12:47:03,572:INFO:Dummy Classifier Imported successfully
2023-11-05 12:47:03,579:INFO:Starting cross validation
2023-11-05 12:47:03,580:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:47:03,787:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:47:03,842:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:47:03,858:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:47:03,864:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:47:03,876:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:47:03,891:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:47:03,893:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:47:03,901:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:47:03,909:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:47:03,930:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:47:04,065:INFO:Calculating mean and std
2023-11-05 12:47:04,066:INFO:Creating metrics dataframe
2023-11-05 12:47:04,070:INFO:Uploading results into container
2023-11-05 12:47:04,071:INFO:Uploading model into container now
2023-11-05 12:47:04,071:INFO:_master_model_container: 15
2023-11-05 12:47:04,071:INFO:_display_container: 2
2023-11-05 12:47:04,072:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-11-05 12:47:04,072:INFO:create_model() successfully completed......................................
2023-11-05 12:47:04,180:INFO:SubProcess create_model() end ==================================
2023-11-05 12:47:04,182:INFO:Creating metrics dataframe
2023-11-05 12:47:04,204:INFO:Initializing create_model()
2023-11-05 12:47:04,204:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C01C98C40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:47:04,204:INFO:Checking exceptions
2023-11-05 12:47:04,206:INFO:Importing libraries
2023-11-05 12:47:04,206:INFO:Copying training dataset
2023-11-05 12:47:04,246:INFO:Defining folds
2023-11-05 12:47:04,246:INFO:Declaring metric variables
2023-11-05 12:47:04,246:INFO:Importing untrained model
2023-11-05 12:47:04,246:INFO:Declaring custom model
2023-11-05 12:47:04,247:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-05 12:47:04,248:INFO:Cross validation set to False
2023-11-05 12:47:04,248:INFO:Fitting Model
2023-11-05 12:47:04,381:INFO:[LightGBM] [Info] Number of positive: 29322, number of negative: 97741
2023-11-05 12:47:04,399:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004141 seconds.
2023-11-05 12:47:04,399:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-05 12:47:04,400:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-05 12:47:04,400:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-05 12:47:04,400:INFO:[LightGBM] [Info] Number of data points in the train set: 127063, number of used features: 19
2023-11-05 12:47:04,401:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230767 -> initscore=-1.203983
2023-11-05 12:47:04,401:INFO:[LightGBM] [Info] Start training from score -1.203983
2023-11-05 12:47:04,786:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 12:47:04,786:INFO:create_model() successfully completed......................................
2023-11-05 12:47:04,950:INFO:_master_model_container: 15
2023-11-05 12:47:04,950:INFO:_display_container: 2
2023-11-05 12:47:04,951:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 12:47:04,951:INFO:compare_models() successfully completed......................................
2023-11-05 12:47:04,997:INFO:Initializing create_model()
2023-11-05 12:47:04,998:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C01C98C40>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:47:04,998:INFO:Checking exceptions
2023-11-05 12:47:05,012:INFO:Importing libraries
2023-11-05 12:47:05,013:INFO:Copying training dataset
2023-11-05 12:47:05,066:INFO:Defining folds
2023-11-05 12:47:05,066:INFO:Declaring metric variables
2023-11-05 12:47:05,069:INFO:Importing untrained model
2023-11-05 12:47:05,074:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-05 12:47:05,082:INFO:Starting cross validation
2023-11-05 12:47:05,083:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:47:09,559:INFO:Calculating mean and std
2023-11-05 12:47:09,560:INFO:Creating metrics dataframe
2023-11-05 12:47:09,566:INFO:Finalizing model
2023-11-05 12:47:09,709:INFO:[LightGBM] [Info] Number of positive: 29322, number of negative: 97741
2023-11-05 12:47:09,727:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003694 seconds.
2023-11-05 12:47:09,727:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-05 12:47:09,727:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-05 12:47:09,727:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-05 12:47:09,728:INFO:[LightGBM] [Info] Number of data points in the train set: 127063, number of used features: 19
2023-11-05 12:47:09,728:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230767 -> initscore=-1.203983
2023-11-05 12:47:09,729:INFO:[LightGBM] [Info] Start training from score -1.203983
2023-11-05 12:47:10,125:INFO:Uploading results into container
2023-11-05 12:47:10,126:INFO:Uploading model into container now
2023-11-05 12:47:10,138:INFO:_master_model_container: 16
2023-11-05 12:47:10,138:INFO:_display_container: 3
2023-11-05 12:47:10,139:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 12:47:10,139:INFO:create_model() successfully completed......................................
2023-11-05 12:47:10,296:INFO:Initializing predict_model()
2023-11-05 12:47:10,296:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C01C98C40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022B94A59CA0>)
2023-11-05 12:47:10,296:INFO:Checking exceptions
2023-11-05 12:47:10,296:INFO:Preloading libraries
2023-11-05 12:47:10,788:INFO:Initializing evaluate_model()
2023-11-05 12:47:10,788:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C01C98C40>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-11-05 12:47:10,820:INFO:Initializing plot_model()
2023-11-05 12:47:10,821:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C01C98C40>, system=True)
2023-11-05 12:47:10,821:INFO:Checking exceptions
2023-11-05 12:47:10,846:INFO:Preloading libraries
2023-11-05 12:47:10,852:INFO:Copying training dataset
2023-11-05 12:47:10,852:INFO:Plot type: pipeline
2023-11-05 12:47:10,945:INFO:Visual Rendered Successfully
2023-11-05 12:47:11,065:INFO:plot_model() successfully completed......................................
2023-11-05 12:47:11,106:INFO:Initializing interpret_model()
2023-11-05 12:47:11,107:INFO:interpret_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=feature_importance, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C01C98C40>)
2023-11-05 12:47:11,107:INFO:Checking exceptions
2023-11-05 12:47:11,107:INFO:Soft dependency imported: shap: 0.43.0
2023-11-05 12:47:11,156:INFO:plot type: summary
2023-11-05 12:47:11,156:INFO:Creating TreeExplainer
2023-11-05 12:47:11,284:INFO:Compiling shap values
2023-11-05 12:47:22,325:INFO:Visual Rendered Successfully
2023-11-05 12:47:22,325:INFO:interpret_model() successfully completed......................................
2023-11-05 12:48:21,220:INFO:Initializing plot_model()
2023-11-05 12:48:21,220:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C01C98C40>, system=True)
2023-11-05 12:48:21,220:INFO:Checking exceptions
2023-11-05 12:48:21,236:INFO:Preloading libraries
2023-11-05 12:48:21,241:INFO:Copying training dataset
2023-11-05 12:48:21,241:INFO:Plot type: parameter
2023-11-05 12:48:21,246:INFO:Visual Rendered Successfully
2023-11-05 12:48:21,379:INFO:plot_model() successfully completed......................................
2023-11-05 12:56:06,683:INFO:PyCaret ClassificationExperiment
2023-11-05 12:56:06,683:INFO:Logging name: clf-default-name
2023-11-05 12:56:06,683:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-05 12:56:06,683:INFO:version 3.1.0
2023-11-05 12:56:06,683:INFO:Initializing setup()
2023-11-05 12:56:06,683:INFO:self.USI: 63d7
2023-11-05 12:56:06,683:INFO:self._variable_keys: {'logging_param', 'y_test', 'gpu_param', 'y', 'n_jobs_param', 'memory', 'gpu_n_jobs_param', 'html_param', 'seed', 'data', 'X', 'fix_imbalance', 'USI', 'log_plots_param', 'fold_groups_param', 'fold_generator', '_ml_usecase', 'exp_id', 'is_multiclass', '_available_plots', 'X_train', 'exp_name_log', 'fold_shuffle_param', 'X_test', 'pipeline', 'target_param', 'idx', 'y_train'}
2023-11-05 12:56:06,683:INFO:Checking environment
2023-11-05 12:56:06,683:INFO:python_version: 3.9.18
2023-11-05 12:56:06,683:INFO:python_build: ('main', 'Sep 11 2023 14:09:26')
2023-11-05 12:56:06,683:INFO:machine: AMD64
2023-11-05 12:56:06,683:INFO:platform: Windows-10-10.0.19041-SP0
2023-11-05 12:56:06,683:INFO:Memory: svmem(total=25692647424, available=15141740544, percent=41.1, used=10550906880, free=15141740544)
2023-11-05 12:56:06,683:INFO:Physical Core: 8
2023-11-05 12:56:06,683:INFO:Logical Core: 16
2023-11-05 12:56:06,684:INFO:Checking libraries
2023-11-05 12:56:06,684:INFO:System:
2023-11-05 12:56:06,684:INFO:    python: 3.9.18 (main, Sep 11 2023, 14:09:26) [MSC v.1916 64 bit (AMD64)]
2023-11-05 12:56:06,684:INFO:executable: d:\programas\Anaconda3\envs\meli_test2\python.exe
2023-11-05 12:56:06,684:INFO:   machine: Windows-10-10.0.19041-SP0
2023-11-05 12:56:06,684:INFO:PyCaret required dependencies:
2023-11-05 12:56:06,684:INFO:                 pip: 23.3
2023-11-05 12:56:06,684:INFO:          setuptools: 68.0.0
2023-11-05 12:56:06,684:INFO:             pycaret: 3.1.0
2023-11-05 12:56:06,684:INFO:             IPython: 8.17.2
2023-11-05 12:56:06,684:INFO:          ipywidgets: 8.1.1
2023-11-05 12:56:06,684:INFO:                tqdm: 4.66.1
2023-11-05 12:56:06,684:INFO:               numpy: 1.23.5
2023-11-05 12:56:06,684:INFO:              pandas: 1.5.3
2023-11-05 12:56:06,684:INFO:              jinja2: 3.1.2
2023-11-05 12:56:06,684:INFO:               scipy: 1.10.1
2023-11-05 12:56:06,684:INFO:              joblib: 1.3.2
2023-11-05 12:56:06,684:INFO:             sklearn: 1.2.2
2023-11-05 12:56:06,684:INFO:                pyod: 1.1.1
2023-11-05 12:56:06,684:INFO:            imblearn: 0.11.0
2023-11-05 12:56:06,684:INFO:   category_encoders: 2.6.3
2023-11-05 12:56:06,684:INFO:            lightgbm: 4.1.0
2023-11-05 12:56:06,684:INFO:               numba: 0.58.1
2023-11-05 12:56:06,684:INFO:            requests: 2.31.0
2023-11-05 12:56:06,684:INFO:          matplotlib: 3.8.1
2023-11-05 12:56:06,685:INFO:          scikitplot: 0.3.7
2023-11-05 12:56:06,685:INFO:         yellowbrick: 1.5
2023-11-05 12:56:06,685:INFO:              plotly: 5.18.0
2023-11-05 12:56:06,685:INFO:    plotly-resampler: Not installed
2023-11-05 12:56:06,685:INFO:             kaleido: 0.2.1
2023-11-05 12:56:06,685:INFO:           schemdraw: 0.15
2023-11-05 12:56:06,685:INFO:         statsmodels: 0.14.0
2023-11-05 12:56:06,685:INFO:              sktime: 0.21.1
2023-11-05 12:56:06,685:INFO:               tbats: 1.1.3
2023-11-05 12:56:06,685:INFO:            pmdarima: 2.0.4
2023-11-05 12:56:06,685:INFO:              psutil: 5.9.6
2023-11-05 12:56:06,685:INFO:          markupsafe: 2.1.3
2023-11-05 12:56:06,685:INFO:             pickle5: Not installed
2023-11-05 12:56:06,685:INFO:         cloudpickle: 3.0.0
2023-11-05 12:56:06,685:INFO:         deprecation: 2.1.0
2023-11-05 12:56:06,685:INFO:              xxhash: 3.4.1
2023-11-05 12:56:06,685:INFO:           wurlitzer: Not installed
2023-11-05 12:56:06,685:INFO:PyCaret optional dependencies:
2023-11-05 12:56:06,685:INFO:                shap: 0.43.0
2023-11-05 12:56:06,685:INFO:           interpret: Not installed
2023-11-05 12:56:06,685:INFO:                umap: Not installed
2023-11-05 12:56:06,685:INFO:     ydata_profiling: Not installed
2023-11-05 12:56:06,685:INFO:  explainerdashboard: Not installed
2023-11-05 12:56:06,685:INFO:             autoviz: Not installed
2023-11-05 12:56:06,685:INFO:           fairlearn: Not installed
2023-11-05 12:56:06,686:INFO:          deepchecks: Not installed
2023-11-05 12:56:06,686:INFO:             xgboost: 2.0.1
2023-11-05 12:56:06,686:INFO:            catboost: Not installed
2023-11-05 12:56:06,686:INFO:              kmodes: Not installed
2023-11-05 12:56:06,686:INFO:             mlxtend: Not installed
2023-11-05 12:56:06,686:INFO:       statsforecast: Not installed
2023-11-05 12:56:06,686:INFO:        tune_sklearn: Not installed
2023-11-05 12:56:06,686:INFO:                 ray: Not installed
2023-11-05 12:56:06,686:INFO:            hyperopt: Not installed
2023-11-05 12:56:06,686:INFO:              optuna: Not installed
2023-11-05 12:56:06,686:INFO:               skopt: Not installed
2023-11-05 12:56:06,686:INFO:              mlflow: Not installed
2023-11-05 12:56:06,686:INFO:              gradio: Not installed
2023-11-05 12:56:06,686:INFO:             fastapi: Not installed
2023-11-05 12:56:06,686:INFO:             uvicorn: Not installed
2023-11-05 12:56:06,686:INFO:              m2cgen: Not installed
2023-11-05 12:56:06,686:INFO:           evidently: Not installed
2023-11-05 12:56:06,686:INFO:               fugue: Not installed
2023-11-05 12:56:06,686:INFO:           streamlit: Not installed
2023-11-05 12:56:06,686:INFO:             prophet: Not installed
2023-11-05 12:56:06,686:INFO:None
2023-11-05 12:56:06,686:INFO:Set up data.
2023-11-05 12:56:06,745:INFO:Set up folding strategy.
2023-11-05 12:56:06,746:INFO:Set up train/test split.
2023-11-05 12:56:06,821:INFO:Set up index.
2023-11-05 12:56:06,824:INFO:Assigning column types.
2023-11-05 12:56:06,853:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-05 12:56:06,906:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-05 12:56:06,907:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 12:56:06,939:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 12:56:06,942:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 12:56:06,995:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-05 12:56:06,995:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 12:56:07,028:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 12:56:07,031:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 12:56:07,031:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-05 12:56:07,084:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 12:56:07,116:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 12:56:07,119:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 12:56:07,172:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 12:56:07,204:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 12:56:07,207:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 12:56:07,208:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-05 12:56:07,292:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 12:56:07,295:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 12:56:07,377:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 12:56:07,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 12:56:07,381:INFO:Preparing preprocessing pipeline...
2023-11-05 12:56:07,386:INFO:Set up simple imputation.
2023-11-05 12:56:07,467:INFO:Finished creating preprocessing pipeline.
2023-11-05 12:56:07,470:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['a', 'b', 'c', 'd', 'e', 'f', 'h',
                                             'k', 'l', 'm', 'n', 'p', 'monto',
                                             'score', 'Country_AR',
                                             'Country_BR', 'Country_US',
                                             'Country_UY', 'Country_otros'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-05 12:56:07,470:INFO:Creating final display dataframe.
2023-11-05 12:56:07,691:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            fraude
2                   Target type            Binary
3           Original data shape      (181519, 20)
4        Transformed data shape      (181519, 20)
5   Transformed train set shape      (127063, 20)
6    Transformed test set shape       (54456, 20)
7              Numeric features                19
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              63d7
2023-11-05 12:56:07,786:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 12:56:07,789:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 12:56:07,880:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 12:56:07,883:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 12:56:07,883:INFO:setup() successfully completed in 1.2s...............
2023-11-05 12:56:07,912:INFO:Initializing compare_models()
2023-11-05 12:56:07,912:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C00204880>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022C00204880>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-11-05 12:56:07,913:INFO:Checking exceptions
2023-11-05 12:56:07,939:INFO:Preparing display monitor
2023-11-05 12:56:07,959:INFO:Initializing Logistic Regression
2023-11-05 12:56:07,960:INFO:Total runtime is 1.671314239501953e-05 minutes
2023-11-05 12:56:07,963:INFO:SubProcess create_model() called ==================================
2023-11-05 12:56:07,963:INFO:Initializing create_model()
2023-11-05 12:56:07,963:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C00204880>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94C07A00>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:56:07,963:INFO:Checking exceptions
2023-11-05 12:56:07,963:INFO:Importing libraries
2023-11-05 12:56:07,964:INFO:Copying training dataset
2023-11-05 12:56:08,006:INFO:Defining folds
2023-11-05 12:56:08,006:INFO:Declaring metric variables
2023-11-05 12:56:08,009:INFO:Importing untrained model
2023-11-05 12:56:08,013:INFO:Logistic Regression Imported successfully
2023-11-05 12:56:08,019:INFO:Starting cross validation
2023-11-05 12:56:08,020:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:56:15,862:INFO:Calculating mean and std
2023-11-05 12:56:15,863:INFO:Creating metrics dataframe
2023-11-05 12:56:15,867:INFO:Uploading results into container
2023-11-05 12:56:15,868:INFO:Uploading model into container now
2023-11-05 12:56:15,868:INFO:_master_model_container: 1
2023-11-05 12:56:15,868:INFO:_display_container: 2
2023-11-05 12:56:15,869:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-05 12:56:15,870:INFO:create_model() successfully completed......................................
2023-11-05 12:56:15,986:INFO:SubProcess create_model() end ==================================
2023-11-05 12:56:15,986:INFO:Creating metrics dataframe
2023-11-05 12:56:15,994:INFO:Initializing K Neighbors Classifier
2023-11-05 12:56:15,994:INFO:Total runtime is 0.13391664425532024 minutes
2023-11-05 12:56:15,998:INFO:SubProcess create_model() called ==================================
2023-11-05 12:56:15,999:INFO:Initializing create_model()
2023-11-05 12:56:15,999:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C00204880>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94C07A00>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:56:15,999:INFO:Checking exceptions
2023-11-05 12:56:15,999:INFO:Importing libraries
2023-11-05 12:56:15,999:INFO:Copying training dataset
2023-11-05 12:56:16,039:INFO:Defining folds
2023-11-05 12:56:16,040:INFO:Declaring metric variables
2023-11-05 12:56:16,043:INFO:Importing untrained model
2023-11-05 12:56:16,046:INFO:K Neighbors Classifier Imported successfully
2023-11-05 12:56:16,052:INFO:Starting cross validation
2023-11-05 12:56:16,053:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:56:43,131:INFO:Calculating mean and std
2023-11-05 12:56:43,132:INFO:Creating metrics dataframe
2023-11-05 12:56:43,136:INFO:Uploading results into container
2023-11-05 12:56:43,136:INFO:Uploading model into container now
2023-11-05 12:56:43,136:INFO:_master_model_container: 2
2023-11-05 12:56:43,136:INFO:_display_container: 2
2023-11-05 12:56:43,137:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-05 12:56:43,137:INFO:create_model() successfully completed......................................
2023-11-05 12:56:43,246:INFO:SubProcess create_model() end ==================================
2023-11-05 12:56:43,246:INFO:Creating metrics dataframe
2023-11-05 12:56:43,255:INFO:Initializing Naive Bayes
2023-11-05 12:56:43,255:INFO:Total runtime is 0.5882778326670328 minutes
2023-11-05 12:56:43,258:INFO:SubProcess create_model() called ==================================
2023-11-05 12:56:43,258:INFO:Initializing create_model()
2023-11-05 12:56:43,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C00204880>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94C07A00>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:56:43,259:INFO:Checking exceptions
2023-11-05 12:56:43,259:INFO:Importing libraries
2023-11-05 12:56:43,259:INFO:Copying training dataset
2023-11-05 12:56:43,300:INFO:Defining folds
2023-11-05 12:56:43,301:INFO:Declaring metric variables
2023-11-05 12:56:43,304:INFO:Importing untrained model
2023-11-05 12:56:43,307:INFO:Naive Bayes Imported successfully
2023-11-05 12:56:43,313:INFO:Starting cross validation
2023-11-05 12:56:43,314:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:56:44,896:INFO:Calculating mean and std
2023-11-05 12:56:44,897:INFO:Creating metrics dataframe
2023-11-05 12:56:44,900:INFO:Uploading results into container
2023-11-05 12:56:44,901:INFO:Uploading model into container now
2023-11-05 12:56:44,901:INFO:_master_model_container: 3
2023-11-05 12:56:44,901:INFO:_display_container: 2
2023-11-05 12:56:44,902:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-05 12:56:44,902:INFO:create_model() successfully completed......................................
2023-11-05 12:56:45,029:INFO:SubProcess create_model() end ==================================
2023-11-05 12:56:45,029:INFO:Creating metrics dataframe
2023-11-05 12:56:45,039:INFO:Initializing Decision Tree Classifier
2023-11-05 12:56:45,040:INFO:Total runtime is 0.6180227319399515 minutes
2023-11-05 12:56:45,043:INFO:SubProcess create_model() called ==================================
2023-11-05 12:56:45,043:INFO:Initializing create_model()
2023-11-05 12:56:45,043:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C00204880>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94C07A00>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:56:45,043:INFO:Checking exceptions
2023-11-05 12:56:45,043:INFO:Importing libraries
2023-11-05 12:56:45,043:INFO:Copying training dataset
2023-11-05 12:56:45,083:INFO:Defining folds
2023-11-05 12:56:45,083:INFO:Declaring metric variables
2023-11-05 12:56:45,086:INFO:Importing untrained model
2023-11-05 12:56:45,090:INFO:Decision Tree Classifier Imported successfully
2023-11-05 12:56:45,095:INFO:Starting cross validation
2023-11-05 12:56:45,096:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:56:47,843:INFO:Calculating mean and std
2023-11-05 12:56:47,844:INFO:Creating metrics dataframe
2023-11-05 12:56:47,848:INFO:Uploading results into container
2023-11-05 12:56:47,848:INFO:Uploading model into container now
2023-11-05 12:56:47,849:INFO:_master_model_container: 4
2023-11-05 12:56:47,849:INFO:_display_container: 2
2023-11-05 12:56:47,849:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-11-05 12:56:47,849:INFO:create_model() successfully completed......................................
2023-11-05 12:56:47,958:INFO:SubProcess create_model() end ==================================
2023-11-05 12:56:47,959:INFO:Creating metrics dataframe
2023-11-05 12:56:47,969:INFO:Initializing SVM - Linear Kernel
2023-11-05 12:56:47,969:INFO:Total runtime is 0.6668338457743326 minutes
2023-11-05 12:56:47,972:INFO:SubProcess create_model() called ==================================
2023-11-05 12:56:47,972:INFO:Initializing create_model()
2023-11-05 12:56:47,972:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C00204880>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94C07A00>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:56:47,972:INFO:Checking exceptions
2023-11-05 12:56:47,972:INFO:Importing libraries
2023-11-05 12:56:47,973:INFO:Copying training dataset
2023-11-05 12:56:48,012:INFO:Defining folds
2023-11-05 12:56:48,012:INFO:Declaring metric variables
2023-11-05 12:56:48,015:INFO:Importing untrained model
2023-11-05 12:56:48,020:INFO:SVM - Linear Kernel Imported successfully
2023-11-05 12:56:48,026:INFO:Starting cross validation
2023-11-05 12:56:48,027:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:56:51,875:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:56:51,922:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:56:52,058:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:56:52,136:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:56:52,165:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:56:52,281:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:56:52,523:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:56:52,724:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:56:53,138:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:56:54,221:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 12:56:54,360:INFO:Calculating mean and std
2023-11-05 12:56:54,362:INFO:Creating metrics dataframe
2023-11-05 12:56:54,365:INFO:Uploading results into container
2023-11-05 12:56:54,366:INFO:Uploading model into container now
2023-11-05 12:56:54,366:INFO:_master_model_container: 5
2023-11-05 12:56:54,366:INFO:_display_container: 2
2023-11-05 12:56:54,367:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-05 12:56:54,367:INFO:create_model() successfully completed......................................
2023-11-05 12:56:54,479:INFO:SubProcess create_model() end ==================================
2023-11-05 12:56:54,480:INFO:Creating metrics dataframe
2023-11-05 12:56:54,489:INFO:Initializing Ridge Classifier
2023-11-05 12:56:54,490:INFO:Total runtime is 0.7755171974500019 minutes
2023-11-05 12:56:54,493:INFO:SubProcess create_model() called ==================================
2023-11-05 12:56:54,493:INFO:Initializing create_model()
2023-11-05 12:56:54,493:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C00204880>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94C07A00>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:56:54,493:INFO:Checking exceptions
2023-11-05 12:56:54,493:INFO:Importing libraries
2023-11-05 12:56:54,493:INFO:Copying training dataset
2023-11-05 12:56:54,532:INFO:Defining folds
2023-11-05 12:56:54,533:INFO:Declaring metric variables
2023-11-05 12:56:54,536:INFO:Importing untrained model
2023-11-05 12:56:54,540:INFO:Ridge Classifier Imported successfully
2023-11-05 12:56:54,546:INFO:Starting cross validation
2023-11-05 12:56:54,547:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:56:54,824:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.02642e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:56:54,847:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:56:54,896:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.04676e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:56:54,903:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.13719e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:56:54,905:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.19282e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:56:54,936:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:56:54,936:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:56:54,941:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.21583e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:56:54,946:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.11761e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:56:54,948:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.20541e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:56:54,961:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.20378e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:56:54,965:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:56:54,965:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:56:54,966:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.16596e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:56:54,966:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:56:54,977:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:56:54,989:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:56:54,995:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.11314e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 12:56:55,006:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 12:56:55,153:INFO:Calculating mean and std
2023-11-05 12:56:55,155:INFO:Creating metrics dataframe
2023-11-05 12:56:55,159:INFO:Uploading results into container
2023-11-05 12:56:55,160:INFO:Uploading model into container now
2023-11-05 12:56:55,161:INFO:_master_model_container: 6
2023-11-05 12:56:55,161:INFO:_display_container: 2
2023-11-05 12:56:55,161:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-11-05 12:56:55,161:INFO:create_model() successfully completed......................................
2023-11-05 12:56:55,286:INFO:SubProcess create_model() end ==================================
2023-11-05 12:56:55,286:INFO:Creating metrics dataframe
2023-11-05 12:56:55,296:INFO:Initializing Random Forest Classifier
2023-11-05 12:56:55,296:INFO:Total runtime is 0.788950475056966 minutes
2023-11-05 12:56:55,299:INFO:SubProcess create_model() called ==================================
2023-11-05 12:56:55,299:INFO:Initializing create_model()
2023-11-05 12:56:55,299:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C00204880>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94C07A00>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:56:55,300:INFO:Checking exceptions
2023-11-05 12:56:55,300:INFO:Importing libraries
2023-11-05 12:56:55,300:INFO:Copying training dataset
2023-11-05 12:56:55,339:INFO:Defining folds
2023-11-05 12:56:55,339:INFO:Declaring metric variables
2023-11-05 12:56:55,342:INFO:Importing untrained model
2023-11-05 12:56:55,346:INFO:Random Forest Classifier Imported successfully
2023-11-05 12:56:55,352:INFO:Starting cross validation
2023-11-05 12:56:55,352:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:57:33,518:INFO:Calculating mean and std
2023-11-05 12:57:33,520:INFO:Creating metrics dataframe
2023-11-05 12:57:33,524:INFO:Uploading results into container
2023-11-05 12:57:33,525:INFO:Uploading model into container now
2023-11-05 12:57:33,525:INFO:_master_model_container: 7
2023-11-05 12:57:33,526:INFO:_display_container: 2
2023-11-05 12:57:33,526:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-11-05 12:57:33,526:INFO:create_model() successfully completed......................................
2023-11-05 12:57:33,667:INFO:SubProcess create_model() end ==================================
2023-11-05 12:57:33,667:INFO:Creating metrics dataframe
2023-11-05 12:57:33,678:INFO:Initializing Quadratic Discriminant Analysis
2023-11-05 12:57:33,678:INFO:Total runtime is 1.4286504626274108 minutes
2023-11-05 12:57:33,682:INFO:SubProcess create_model() called ==================================
2023-11-05 12:57:33,682:INFO:Initializing create_model()
2023-11-05 12:57:33,682:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C00204880>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94C07A00>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:57:33,682:INFO:Checking exceptions
2023-11-05 12:57:33,682:INFO:Importing libraries
2023-11-05 12:57:33,682:INFO:Copying training dataset
2023-11-05 12:57:33,731:INFO:Defining folds
2023-11-05 12:57:33,732:INFO:Declaring metric variables
2023-11-05 12:57:33,735:INFO:Importing untrained model
2023-11-05 12:57:33,739:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-05 12:57:33,746:INFO:Starting cross validation
2023-11-05 12:57:33,747:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:57:34,532:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:57:34,560:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:57:34,570:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:57:34,649:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:57:34,727:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:57:34,746:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:57:34,774:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:57:34,829:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:57:34,865:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:57:34,930:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 12:57:35,123:INFO:Calculating mean and std
2023-11-05 12:57:35,124:INFO:Creating metrics dataframe
2023-11-05 12:57:35,128:INFO:Uploading results into container
2023-11-05 12:57:35,129:INFO:Uploading model into container now
2023-11-05 12:57:35,129:INFO:_master_model_container: 8
2023-11-05 12:57:35,129:INFO:_display_container: 2
2023-11-05 12:57:35,130:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-05 12:57:35,130:INFO:create_model() successfully completed......................................
2023-11-05 12:57:35,245:INFO:SubProcess create_model() end ==================================
2023-11-05 12:57:35,246:INFO:Creating metrics dataframe
2023-11-05 12:57:35,258:INFO:Initializing Ada Boost Classifier
2023-11-05 12:57:35,258:INFO:Total runtime is 1.4549877723058064 minutes
2023-11-05 12:57:35,261:INFO:SubProcess create_model() called ==================================
2023-11-05 12:57:35,261:INFO:Initializing create_model()
2023-11-05 12:57:35,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C00204880>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94C07A00>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:57:35,261:INFO:Checking exceptions
2023-11-05 12:57:35,262:INFO:Importing libraries
2023-11-05 12:57:35,262:INFO:Copying training dataset
2023-11-05 12:57:35,302:INFO:Defining folds
2023-11-05 12:57:35,303:INFO:Declaring metric variables
2023-11-05 12:57:35,306:INFO:Importing untrained model
2023-11-05 12:57:35,309:INFO:Ada Boost Classifier Imported successfully
2023-11-05 12:57:35,315:INFO:Starting cross validation
2023-11-05 12:57:35,316:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:57:48,888:INFO:Calculating mean and std
2023-11-05 12:57:48,889:INFO:Creating metrics dataframe
2023-11-05 12:57:48,892:INFO:Uploading results into container
2023-11-05 12:57:48,893:INFO:Uploading model into container now
2023-11-05 12:57:48,893:INFO:_master_model_container: 9
2023-11-05 12:57:48,893:INFO:_display_container: 2
2023-11-05 12:57:48,893:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-11-05 12:57:48,894:INFO:create_model() successfully completed......................................
2023-11-05 12:57:49,012:INFO:SubProcess create_model() end ==================================
2023-11-05 12:57:49,013:INFO:Creating metrics dataframe
2023-11-05 12:57:49,025:INFO:Initializing Gradient Boosting Classifier
2023-11-05 12:57:49,026:INFO:Total runtime is 1.6844539960225422 minutes
2023-11-05 12:57:49,029:INFO:SubProcess create_model() called ==================================
2023-11-05 12:57:49,029:INFO:Initializing create_model()
2023-11-05 12:57:49,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C00204880>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94C07A00>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:57:49,029:INFO:Checking exceptions
2023-11-05 12:57:49,029:INFO:Importing libraries
2023-11-05 12:57:49,030:INFO:Copying training dataset
2023-11-05 12:57:49,070:INFO:Defining folds
2023-11-05 12:57:49,070:INFO:Declaring metric variables
2023-11-05 12:57:49,073:INFO:Importing untrained model
2023-11-05 12:57:49,077:INFO:Gradient Boosting Classifier Imported successfully
2023-11-05 12:57:49,083:INFO:Starting cross validation
2023-11-05 12:57:49,084:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:58:45,565:INFO:Calculating mean and std
2023-11-05 12:58:45,566:INFO:Creating metrics dataframe
2023-11-05 12:58:45,570:INFO:Uploading results into container
2023-11-05 12:58:45,570:INFO:Uploading model into container now
2023-11-05 12:58:45,571:INFO:_master_model_container: 10
2023-11-05 12:58:45,571:INFO:_display_container: 2
2023-11-05 12:58:45,571:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-11-05 12:58:45,572:INFO:create_model() successfully completed......................................
2023-11-05 12:58:45,697:INFO:SubProcess create_model() end ==================================
2023-11-05 12:58:45,697:INFO:Creating metrics dataframe
2023-11-05 12:58:45,709:INFO:Initializing Linear Discriminant Analysis
2023-11-05 12:58:45,710:INFO:Total runtime is 2.629187293847402 minutes
2023-11-05 12:58:45,714:INFO:SubProcess create_model() called ==================================
2023-11-05 12:58:45,714:INFO:Initializing create_model()
2023-11-05 12:58:45,715:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C00204880>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94C07A00>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:58:45,715:INFO:Checking exceptions
2023-11-05 12:58:45,715:INFO:Importing libraries
2023-11-05 12:58:45,715:INFO:Copying training dataset
2023-11-05 12:58:45,764:INFO:Defining folds
2023-11-05 12:58:45,765:INFO:Declaring metric variables
2023-11-05 12:58:45,768:INFO:Importing untrained model
2023-11-05 12:58:45,772:INFO:Linear Discriminant Analysis Imported successfully
2023-11-05 12:58:45,782:INFO:Starting cross validation
2023-11-05 12:58:45,783:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:58:47,391:INFO:Calculating mean and std
2023-11-05 12:58:47,393:INFO:Creating metrics dataframe
2023-11-05 12:58:47,397:INFO:Uploading results into container
2023-11-05 12:58:47,398:INFO:Uploading model into container now
2023-11-05 12:58:47,398:INFO:_master_model_container: 11
2023-11-05 12:58:47,399:INFO:_display_container: 2
2023-11-05 12:58:47,399:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-05 12:58:47,399:INFO:create_model() successfully completed......................................
2023-11-05 12:58:47,532:INFO:SubProcess create_model() end ==================================
2023-11-05 12:58:47,533:INFO:Creating metrics dataframe
2023-11-05 12:58:47,546:INFO:Initializing Extra Trees Classifier
2023-11-05 12:58:47,546:INFO:Total runtime is 2.65978733698527 minutes
2023-11-05 12:58:47,549:INFO:SubProcess create_model() called ==================================
2023-11-05 12:58:47,550:INFO:Initializing create_model()
2023-11-05 12:58:47,550:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C00204880>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94C07A00>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:58:47,550:INFO:Checking exceptions
2023-11-05 12:58:47,550:INFO:Importing libraries
2023-11-05 12:58:47,550:INFO:Copying training dataset
2023-11-05 12:58:47,593:INFO:Defining folds
2023-11-05 12:58:47,593:INFO:Declaring metric variables
2023-11-05 12:58:47,597:INFO:Importing untrained model
2023-11-05 12:58:47,600:INFO:Extra Trees Classifier Imported successfully
2023-11-05 12:58:47,607:INFO:Starting cross validation
2023-11-05 12:58:47,608:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:59:12,965:INFO:Calculating mean and std
2023-11-05 12:59:12,966:INFO:Creating metrics dataframe
2023-11-05 12:59:12,970:INFO:Uploading results into container
2023-11-05 12:59:12,970:INFO:Uploading model into container now
2023-11-05 12:59:12,971:INFO:_master_model_container: 12
2023-11-05 12:59:12,971:INFO:_display_container: 2
2023-11-05 12:59:12,971:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-11-05 12:59:12,971:INFO:create_model() successfully completed......................................
2023-11-05 12:59:13,112:INFO:SubProcess create_model() end ==================================
2023-11-05 12:59:13,114:INFO:Creating metrics dataframe
2023-11-05 12:59:13,127:INFO:Initializing Extreme Gradient Boosting
2023-11-05 12:59:13,127:INFO:Total runtime is 3.086137294769287 minutes
2023-11-05 12:59:13,130:INFO:SubProcess create_model() called ==================================
2023-11-05 12:59:13,131:INFO:Initializing create_model()
2023-11-05 12:59:13,131:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C00204880>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94C07A00>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:59:13,131:INFO:Checking exceptions
2023-11-05 12:59:13,131:INFO:Importing libraries
2023-11-05 12:59:13,131:INFO:Copying training dataset
2023-11-05 12:59:13,176:INFO:Defining folds
2023-11-05 12:59:13,177:INFO:Declaring metric variables
2023-11-05 12:59:13,180:INFO:Importing untrained model
2023-11-05 12:59:13,184:INFO:Extreme Gradient Boosting Imported successfully
2023-11-05 12:59:13,191:INFO:Starting cross validation
2023-11-05 12:59:13,193:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:59:16,600:INFO:Calculating mean and std
2023-11-05 12:59:16,601:INFO:Creating metrics dataframe
2023-11-05 12:59:16,604:INFO:Uploading results into container
2023-11-05 12:59:16,605:INFO:Uploading model into container now
2023-11-05 12:59:16,605:INFO:_master_model_container: 13
2023-11-05 12:59:16,605:INFO:_display_container: 2
2023-11-05 12:59:16,606:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2023-11-05 12:59:16,606:INFO:create_model() successfully completed......................................
2023-11-05 12:59:16,720:INFO:SubProcess create_model() end ==================================
2023-11-05 12:59:16,720:INFO:Creating metrics dataframe
2023-11-05 12:59:16,732:INFO:Initializing Light Gradient Boosting Machine
2023-11-05 12:59:16,733:INFO:Total runtime is 3.1462325930595396 minutes
2023-11-05 12:59:16,736:INFO:SubProcess create_model() called ==================================
2023-11-05 12:59:16,736:INFO:Initializing create_model()
2023-11-05 12:59:16,736:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C00204880>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94C07A00>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:59:16,736:INFO:Checking exceptions
2023-11-05 12:59:16,737:INFO:Importing libraries
2023-11-05 12:59:16,737:INFO:Copying training dataset
2023-11-05 12:59:16,776:INFO:Defining folds
2023-11-05 12:59:16,776:INFO:Declaring metric variables
2023-11-05 12:59:16,780:INFO:Importing untrained model
2023-11-05 12:59:16,783:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-05 12:59:16,790:INFO:Starting cross validation
2023-11-05 12:59:16,791:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:59:21,466:INFO:Calculating mean and std
2023-11-05 12:59:21,468:INFO:Creating metrics dataframe
2023-11-05 12:59:21,471:INFO:Uploading results into container
2023-11-05 12:59:21,471:INFO:Uploading model into container now
2023-11-05 12:59:21,472:INFO:_master_model_container: 14
2023-11-05 12:59:21,472:INFO:_display_container: 2
2023-11-05 12:59:21,472:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 12:59:21,473:INFO:create_model() successfully completed......................................
2023-11-05 12:59:21,583:INFO:SubProcess create_model() end ==================================
2023-11-05 12:59:21,584:INFO:Creating metrics dataframe
2023-11-05 12:59:21,596:INFO:Initializing Dummy Classifier
2023-11-05 12:59:21,596:INFO:Total runtime is 3.22728259563446 minutes
2023-11-05 12:59:21,600:INFO:SubProcess create_model() called ==================================
2023-11-05 12:59:21,601:INFO:Initializing create_model()
2023-11-05 12:59:21,601:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C00204880>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022B94C07A00>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:59:21,601:INFO:Checking exceptions
2023-11-05 12:59:21,601:INFO:Importing libraries
2023-11-05 12:59:21,601:INFO:Copying training dataset
2023-11-05 12:59:21,642:INFO:Defining folds
2023-11-05 12:59:21,642:INFO:Declaring metric variables
2023-11-05 12:59:21,646:INFO:Importing untrained model
2023-11-05 12:59:21,650:INFO:Dummy Classifier Imported successfully
2023-11-05 12:59:21,658:INFO:Starting cross validation
2023-11-05 12:59:21,659:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:59:21,887:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:59:21,895:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:59:21,913:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:59:21,929:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:59:21,933:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:59:21,955:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:59:21,965:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:59:21,986:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:59:21,986:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:59:21,991:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 12:59:22,113:INFO:Calculating mean and std
2023-11-05 12:59:22,114:INFO:Creating metrics dataframe
2023-11-05 12:59:22,117:INFO:Uploading results into container
2023-11-05 12:59:22,118:INFO:Uploading model into container now
2023-11-05 12:59:22,119:INFO:_master_model_container: 15
2023-11-05 12:59:22,119:INFO:_display_container: 2
2023-11-05 12:59:22,119:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-11-05 12:59:22,119:INFO:create_model() successfully completed......................................
2023-11-05 12:59:22,255:INFO:SubProcess create_model() end ==================================
2023-11-05 12:59:22,256:INFO:Creating metrics dataframe
2023-11-05 12:59:22,279:INFO:Initializing create_model()
2023-11-05 12:59:22,279:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C00204880>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:59:22,279:INFO:Checking exceptions
2023-11-05 12:59:22,281:INFO:Importing libraries
2023-11-05 12:59:22,281:INFO:Copying training dataset
2023-11-05 12:59:22,322:INFO:Defining folds
2023-11-05 12:59:22,322:INFO:Declaring metric variables
2023-11-05 12:59:22,322:INFO:Importing untrained model
2023-11-05 12:59:22,322:INFO:Declaring custom model
2023-11-05 12:59:22,323:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-05 12:59:22,324:INFO:Cross validation set to False
2023-11-05 12:59:22,324:INFO:Fitting Model
2023-11-05 12:59:22,463:INFO:[LightGBM] [Info] Number of positive: 29322, number of negative: 97741
2023-11-05 12:59:22,481:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003988 seconds.
2023-11-05 12:59:22,481:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-05 12:59:22,481:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-05 12:59:22,481:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-05 12:59:22,481:INFO:[LightGBM] [Info] Number of data points in the train set: 127063, number of used features: 19
2023-11-05 12:59:22,482:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230767 -> initscore=-1.203983
2023-11-05 12:59:22,482:INFO:[LightGBM] [Info] Start training from score -1.203983
2023-11-05 12:59:22,895:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 12:59:22,895:INFO:create_model() successfully completed......................................
2023-11-05 12:59:23,057:INFO:_master_model_container: 15
2023-11-05 12:59:23,057:INFO:_display_container: 2
2023-11-05 12:59:23,057:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 12:59:23,058:INFO:compare_models() successfully completed......................................
2023-11-05 12:59:23,104:INFO:Initializing create_model()
2023-11-05 12:59:23,105:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C00204880>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-05 12:59:23,105:INFO:Checking exceptions
2023-11-05 12:59:23,118:INFO:Importing libraries
2023-11-05 12:59:23,118:INFO:Copying training dataset
2023-11-05 12:59:23,162:INFO:Defining folds
2023-11-05 12:59:23,162:INFO:Declaring metric variables
2023-11-05 12:59:23,166:INFO:Importing untrained model
2023-11-05 12:59:23,169:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-05 12:59:23,175:INFO:Starting cross validation
2023-11-05 12:59:23,176:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 12:59:27,875:INFO:Calculating mean and std
2023-11-05 12:59:27,877:INFO:Creating metrics dataframe
2023-11-05 12:59:27,883:INFO:Finalizing model
2023-11-05 12:59:28,027:INFO:[LightGBM] [Info] Number of positive: 29322, number of negative: 97741
2023-11-05 12:59:28,046:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004677 seconds.
2023-11-05 12:59:28,047:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-05 12:59:28,047:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-05 12:59:28,047:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-05 12:59:28,047:INFO:[LightGBM] [Info] Number of data points in the train set: 127063, number of used features: 19
2023-11-05 12:59:28,048:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230767 -> initscore=-1.203983
2023-11-05 12:59:28,048:INFO:[LightGBM] [Info] Start training from score -1.203983
2023-11-05 12:59:28,529:INFO:Uploading results into container
2023-11-05 12:59:28,530:INFO:Uploading model into container now
2023-11-05 12:59:28,543:INFO:_master_model_container: 16
2023-11-05 12:59:28,543:INFO:_display_container: 3
2023-11-05 12:59:28,544:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 12:59:28,544:INFO:create_model() successfully completed......................................
2023-11-05 12:59:28,726:INFO:Initializing predict_model()
2023-11-05 12:59:28,727:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C00204880>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000022C000DA820>)
2023-11-05 12:59:28,727:INFO:Checking exceptions
2023-11-05 12:59:28,727:INFO:Preloading libraries
2023-11-05 12:59:29,257:INFO:Initializing evaluate_model()
2023-11-05 12:59:29,257:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C00204880>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-11-05 12:59:29,282:INFO:Initializing plot_model()
2023-11-05 12:59:29,282:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C00204880>, system=True)
2023-11-05 12:59:29,282:INFO:Checking exceptions
2023-11-05 12:59:29,300:INFO:Preloading libraries
2023-11-05 12:59:29,305:INFO:Copying training dataset
2023-11-05 12:59:29,306:INFO:Plot type: pipeline
2023-11-05 12:59:29,397:INFO:Visual Rendered Successfully
2023-11-05 12:59:29,520:INFO:plot_model() successfully completed......................................
2023-11-05 12:59:29,558:INFO:Initializing interpret_model()
2023-11-05 12:59:29,559:INFO:interpret_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=feature_importance, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022C00204880>)
2023-11-05 12:59:29,559:INFO:Checking exceptions
2023-11-05 12:59:29,559:INFO:Soft dependency imported: shap: 0.43.0
2023-11-05 12:59:29,604:INFO:plot type: summary
2023-11-05 12:59:29,605:INFO:Creating TreeExplainer
2023-11-05 12:59:29,733:INFO:Compiling shap values
2023-11-05 12:59:40,944:INFO:Visual Rendered Successfully
2023-11-05 12:59:40,944:INFO:interpret_model() successfully completed......................................
2023-11-05 15:37:27,525:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-05 15:37:27,526:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-05 15:37:27,526:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-05 15:37:27,526:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-05 15:37:29,253:INFO:PyCaret ClassificationExperiment
2023-11-05 15:37:29,253:INFO:Logging name: clf-default-name
2023-11-05 15:37:29,253:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-05 15:37:29,253:INFO:version 3.1.0
2023-11-05 15:37:29,253:INFO:Initializing setup()
2023-11-05 15:37:29,253:INFO:self.USI: 1dc6
2023-11-05 15:37:29,253:INFO:self._variable_keys: {'idx', 'html_param', 'exp_id', '_ml_usecase', 'logging_param', 'pipeline', 'exp_name_log', 'y_train', 'X_test', 'fold_generator', 'y_test', 'X_train', 'n_jobs_param', 'fold_shuffle_param', 'log_plots_param', 'fold_groups_param', 'gpu_n_jobs_param', 'is_multiclass', 'gpu_param', 'X', 'data', 'fix_imbalance', 'seed', 'target_param', 'USI', 'y', 'memory', '_available_plots'}
2023-11-05 15:37:29,253:INFO:Checking environment
2023-11-05 15:37:29,253:INFO:python_version: 3.9.18
2023-11-05 15:37:29,253:INFO:python_build: ('main', 'Sep 11 2023 14:09:26')
2023-11-05 15:37:29,253:INFO:machine: AMD64
2023-11-05 15:37:29,253:INFO:platform: Windows-10-10.0.19041-SP0
2023-11-05 15:37:29,253:INFO:Memory: svmem(total=25692647424, available=12182777856, percent=52.6, used=13509869568, free=12182777856)
2023-11-05 15:37:29,254:INFO:Physical Core: 8
2023-11-05 15:37:29,254:INFO:Logical Core: 16
2023-11-05 15:37:29,254:INFO:Checking libraries
2023-11-05 15:37:29,254:INFO:System:
2023-11-05 15:37:29,254:INFO:    python: 3.9.18 (main, Sep 11 2023, 14:09:26) [MSC v.1916 64 bit (AMD64)]
2023-11-05 15:37:29,254:INFO:executable: d:\programas\Anaconda3\envs\meli_test2\python.exe
2023-11-05 15:37:29,254:INFO:   machine: Windows-10-10.0.19041-SP0
2023-11-05 15:37:29,254:INFO:PyCaret required dependencies:
2023-11-05 15:37:29,277:INFO:                 pip: 23.3
2023-11-05 15:37:29,277:INFO:          setuptools: 68.0.0
2023-11-05 15:37:29,277:INFO:             pycaret: 3.1.0
2023-11-05 15:37:29,278:INFO:             IPython: 8.17.2
2023-11-05 15:37:29,278:INFO:          ipywidgets: 8.1.1
2023-11-05 15:37:29,278:INFO:                tqdm: 4.66.1
2023-11-05 15:37:29,278:INFO:               numpy: 1.23.5
2023-11-05 15:37:29,278:INFO:              pandas: 1.5.3
2023-11-05 15:37:29,278:INFO:              jinja2: 3.1.2
2023-11-05 15:37:29,278:INFO:               scipy: 1.10.1
2023-11-05 15:37:29,278:INFO:              joblib: 1.3.2
2023-11-05 15:37:29,278:INFO:             sklearn: 1.2.2
2023-11-05 15:37:29,278:INFO:                pyod: 1.1.1
2023-11-05 15:37:29,278:INFO:            imblearn: 0.11.0
2023-11-05 15:37:29,278:INFO:   category_encoders: 2.6.3
2023-11-05 15:37:29,278:INFO:            lightgbm: 4.1.0
2023-11-05 15:37:29,278:INFO:               numba: 0.58.1
2023-11-05 15:37:29,278:INFO:            requests: 2.31.0
2023-11-05 15:37:29,278:INFO:          matplotlib: 3.8.1
2023-11-05 15:37:29,278:INFO:          scikitplot: 0.3.7
2023-11-05 15:37:29,278:INFO:         yellowbrick: 1.5
2023-11-05 15:37:29,278:INFO:              plotly: 5.18.0
2023-11-05 15:37:29,278:INFO:    plotly-resampler: Not installed
2023-11-05 15:37:29,278:INFO:             kaleido: 0.2.1
2023-11-05 15:37:29,278:INFO:           schemdraw: 0.15
2023-11-05 15:37:29,278:INFO:         statsmodels: 0.14.0
2023-11-05 15:37:29,278:INFO:              sktime: 0.21.1
2023-11-05 15:37:29,279:INFO:               tbats: 1.1.3
2023-11-05 15:37:29,279:INFO:            pmdarima: 2.0.4
2023-11-05 15:37:29,279:INFO:              psutil: 5.9.6
2023-11-05 15:37:29,279:INFO:          markupsafe: 2.1.3
2023-11-05 15:37:29,279:INFO:             pickle5: Not installed
2023-11-05 15:37:29,279:INFO:         cloudpickle: 2.2.1
2023-11-05 15:37:29,279:INFO:         deprecation: 2.1.0
2023-11-05 15:37:29,279:INFO:              xxhash: 3.4.1
2023-11-05 15:37:29,279:INFO:           wurlitzer: Not installed
2023-11-05 15:37:29,279:INFO:PyCaret optional dependencies:
2023-11-05 15:37:29,328:INFO:                shap: 0.43.0
2023-11-05 15:37:29,328:INFO:           interpret: Not installed
2023-11-05 15:37:29,329:INFO:                umap: Not installed
2023-11-05 15:37:29,329:INFO:     ydata_profiling: Not installed
2023-11-05 15:37:29,329:INFO:  explainerdashboard: Not installed
2023-11-05 15:37:29,329:INFO:             autoviz: Not installed
2023-11-05 15:37:29,329:INFO:           fairlearn: Not installed
2023-11-05 15:37:29,329:INFO:          deepchecks: Not installed
2023-11-05 15:37:29,329:INFO:             xgboost: 2.0.1
2023-11-05 15:37:29,329:INFO:            catboost: Not installed
2023-11-05 15:37:29,329:INFO:              kmodes: Not installed
2023-11-05 15:37:29,329:INFO:             mlxtend: Not installed
2023-11-05 15:37:29,329:INFO:       statsforecast: Not installed
2023-11-05 15:37:29,329:INFO:        tune_sklearn: Not installed
2023-11-05 15:37:29,329:INFO:                 ray: Not installed
2023-11-05 15:37:29,329:INFO:            hyperopt: Not installed
2023-11-05 15:37:29,329:INFO:              optuna: Not installed
2023-11-05 15:37:29,329:INFO:               skopt: Not installed
2023-11-05 15:37:29,329:INFO:              mlflow: 2.8.0
2023-11-05 15:37:29,329:INFO:              gradio: Not installed
2023-11-05 15:37:29,329:INFO:             fastapi: Not installed
2023-11-05 15:37:29,329:INFO:             uvicorn: Not installed
2023-11-05 15:37:29,329:INFO:              m2cgen: Not installed
2023-11-05 15:37:29,329:INFO:           evidently: Not installed
2023-11-05 15:37:29,329:INFO:               fugue: Not installed
2023-11-05 15:37:29,329:INFO:           streamlit: Not installed
2023-11-05 15:37:29,329:INFO:             prophet: Not installed
2023-11-05 15:37:29,329:INFO:None
2023-11-05 15:37:29,329:INFO:Set up data.
2023-11-05 15:37:29,399:INFO:Set up folding strategy.
2023-11-05 15:37:29,399:INFO:Set up train/test split.
2023-11-05 15:37:29,483:INFO:Set up index.
2023-11-05 15:37:29,488:INFO:Assigning column types.
2023-11-05 15:37:29,526:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-05 15:37:29,580:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-05 15:37:29,582:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 15:37:29,632:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 15:37:29,635:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 15:37:29,690:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-05 15:37:29,691:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 15:37:29,724:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 15:37:29,727:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 15:37:29,727:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-05 15:37:29,782:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 15:37:29,815:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 15:37:29,818:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 15:37:29,873:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-05 15:37:29,907:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 15:37:29,910:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 15:37:29,910:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-05 15:37:29,997:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 15:37:30,000:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 15:37:30,089:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 15:37:30,093:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 15:37:30,095:INFO:Preparing preprocessing pipeline...
2023-11-05 15:37:30,100:INFO:Set up simple imputation.
2023-11-05 15:37:30,196:INFO:Finished creating preprocessing pipeline.
2023-11-05 15:37:30,206:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['a', 'b', 'c', 'd', 'e', 'f', 'h',
                                             'k', 'l', 'm', 'n', 'p', 'monto',
                                             'score', 'Country_AR',
                                             'Country_BR', 'Country_US',
                                             'Country_UY', 'Country_otros'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-05 15:37:30,206:INFO:Creating final display dataframe.
2023-11-05 15:37:30,494:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            fraude
2                   Target type            Binary
3           Original data shape      (181519, 20)
4        Transformed data shape      (181519, 20)
5   Transformed train set shape      (127063, 20)
6    Transformed test set shape       (54456, 20)
7              Numeric features                19
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              1dc6
2023-11-05 15:37:30,593:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 15:37:30,596:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 15:37:30,685:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-05 15:37:30,689:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-05 15:37:30,690:INFO:setup() successfully completed in 1.44s...............
2023-11-05 15:37:30,710:INFO:Initializing compare_models()
2023-11-05 15:37:30,710:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F8188BA00>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000027F8188BA00>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-11-05 15:37:30,710:INFO:Checking exceptions
2023-11-05 15:37:30,744:INFO:Preparing display monitor
2023-11-05 15:37:30,767:INFO:Initializing Logistic Regression
2023-11-05 15:37:30,768:INFO:Total runtime is 1.6657511393229165e-05 minutes
2023-11-05 15:37:30,771:INFO:SubProcess create_model() called ==================================
2023-11-05 15:37:30,772:INFO:Initializing create_model()
2023-11-05 15:37:30,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F8188BA00>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FB1F10DF0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 15:37:30,772:INFO:Checking exceptions
2023-11-05 15:37:30,772:INFO:Importing libraries
2023-11-05 15:37:30,773:INFO:Copying training dataset
2023-11-05 15:37:30,824:INFO:Defining folds
2023-11-05 15:37:30,824:INFO:Declaring metric variables
2023-11-05 15:37:30,827:INFO:Importing untrained model
2023-11-05 15:37:30,831:INFO:Logistic Regression Imported successfully
2023-11-05 15:37:30,838:INFO:Starting cross validation
2023-11-05 15:37:30,839:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 15:37:39,183:INFO:Calculating mean and std
2023-11-05 15:37:39,184:INFO:Creating metrics dataframe
2023-11-05 15:37:39,189:INFO:Uploading results into container
2023-11-05 15:37:39,190:INFO:Uploading model into container now
2023-11-05 15:37:39,190:INFO:_master_model_container: 1
2023-11-05 15:37:39,190:INFO:_display_container: 2
2023-11-05 15:37:39,191:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-05 15:37:39,191:INFO:create_model() successfully completed......................................
2023-11-05 15:37:39,272:INFO:SubProcess create_model() end ==================================
2023-11-05 15:37:39,272:INFO:Creating metrics dataframe
2023-11-05 15:37:39,283:INFO:Initializing K Neighbors Classifier
2023-11-05 15:37:39,283:INFO:Total runtime is 0.14193564653396606 minutes
2023-11-05 15:37:39,287:INFO:SubProcess create_model() called ==================================
2023-11-05 15:37:39,288:INFO:Initializing create_model()
2023-11-05 15:37:39,288:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F8188BA00>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FB1F10DF0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 15:37:39,288:INFO:Checking exceptions
2023-11-05 15:37:39,288:INFO:Importing libraries
2023-11-05 15:37:39,288:INFO:Copying training dataset
2023-11-05 15:37:39,354:INFO:Defining folds
2023-11-05 15:37:39,354:INFO:Declaring metric variables
2023-11-05 15:37:39,358:INFO:Importing untrained model
2023-11-05 15:37:39,361:INFO:K Neighbors Classifier Imported successfully
2023-11-05 15:37:39,368:INFO:Starting cross validation
2023-11-05 15:37:39,370:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 15:38:08,754:INFO:Calculating mean and std
2023-11-05 15:38:08,755:INFO:Creating metrics dataframe
2023-11-05 15:38:08,759:INFO:Uploading results into container
2023-11-05 15:38:08,760:INFO:Uploading model into container now
2023-11-05 15:38:08,760:INFO:_master_model_container: 2
2023-11-05 15:38:08,760:INFO:_display_container: 2
2023-11-05 15:38:08,761:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-05 15:38:08,761:INFO:create_model() successfully completed......................................
2023-11-05 15:38:08,842:INFO:SubProcess create_model() end ==================================
2023-11-05 15:38:08,842:INFO:Creating metrics dataframe
2023-11-05 15:38:08,853:INFO:Initializing Naive Bayes
2023-11-05 15:38:08,853:INFO:Total runtime is 0.6347632845242819 minutes
2023-11-05 15:38:08,856:INFO:SubProcess create_model() called ==================================
2023-11-05 15:38:08,857:INFO:Initializing create_model()
2023-11-05 15:38:08,857:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F8188BA00>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FB1F10DF0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 15:38:08,857:INFO:Checking exceptions
2023-11-05 15:38:08,857:INFO:Importing libraries
2023-11-05 15:38:08,857:INFO:Copying training dataset
2023-11-05 15:38:08,905:INFO:Defining folds
2023-11-05 15:38:08,905:INFO:Declaring metric variables
2023-11-05 15:38:08,908:INFO:Importing untrained model
2023-11-05 15:38:08,912:INFO:Naive Bayes Imported successfully
2023-11-05 15:38:08,923:INFO:Starting cross validation
2023-11-05 15:38:08,924:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 15:38:09,547:INFO:Calculating mean and std
2023-11-05 15:38:09,549:INFO:Creating metrics dataframe
2023-11-05 15:38:09,554:INFO:Uploading results into container
2023-11-05 15:38:09,554:INFO:Uploading model into container now
2023-11-05 15:38:09,555:INFO:_master_model_container: 3
2023-11-05 15:38:09,555:INFO:_display_container: 2
2023-11-05 15:38:09,555:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-05 15:38:09,555:INFO:create_model() successfully completed......................................
2023-11-05 15:38:09,632:INFO:SubProcess create_model() end ==================================
2023-11-05 15:38:09,633:INFO:Creating metrics dataframe
2023-11-05 15:38:09,642:INFO:Initializing Decision Tree Classifier
2023-11-05 15:38:09,643:INFO:Total runtime is 0.6479315598805746 minutes
2023-11-05 15:38:09,646:INFO:SubProcess create_model() called ==================================
2023-11-05 15:38:09,646:INFO:Initializing create_model()
2023-11-05 15:38:09,647:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F8188BA00>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FB1F10DF0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 15:38:09,647:INFO:Checking exceptions
2023-11-05 15:38:09,647:INFO:Importing libraries
2023-11-05 15:38:09,647:INFO:Copying training dataset
2023-11-05 15:38:09,692:INFO:Defining folds
2023-11-05 15:38:09,692:INFO:Declaring metric variables
2023-11-05 15:38:09,696:INFO:Importing untrained model
2023-11-05 15:38:09,700:INFO:Decision Tree Classifier Imported successfully
2023-11-05 15:38:09,708:INFO:Starting cross validation
2023-11-05 15:38:09,710:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 15:38:12,533:INFO:Calculating mean and std
2023-11-05 15:38:12,534:INFO:Creating metrics dataframe
2023-11-05 15:38:12,538:INFO:Uploading results into container
2023-11-05 15:38:12,539:INFO:Uploading model into container now
2023-11-05 15:38:12,539:INFO:_master_model_container: 4
2023-11-05 15:38:12,539:INFO:_display_container: 2
2023-11-05 15:38:12,540:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-11-05 15:38:12,540:INFO:create_model() successfully completed......................................
2023-11-05 15:38:12,621:INFO:SubProcess create_model() end ==================================
2023-11-05 15:38:12,621:INFO:Creating metrics dataframe
2023-11-05 15:38:12,632:INFO:Initializing SVM - Linear Kernel
2023-11-05 15:38:12,632:INFO:Total runtime is 0.6977482557296754 minutes
2023-11-05 15:38:12,636:INFO:SubProcess create_model() called ==================================
2023-11-05 15:38:12,636:INFO:Initializing create_model()
2023-11-05 15:38:12,636:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F8188BA00>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FB1F10DF0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 15:38:12,636:INFO:Checking exceptions
2023-11-05 15:38:12,636:INFO:Importing libraries
2023-11-05 15:38:12,636:INFO:Copying training dataset
2023-11-05 15:38:12,684:INFO:Defining folds
2023-11-05 15:38:12,684:INFO:Declaring metric variables
2023-11-05 15:38:12,687:INFO:Importing untrained model
2023-11-05 15:38:12,691:INFO:SVM - Linear Kernel Imported successfully
2023-11-05 15:38:12,699:INFO:Starting cross validation
2023-11-05 15:38:12,700:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 15:38:17,025:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 15:38:17,040:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 15:38:17,327:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 15:38:17,340:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 15:38:17,446:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 15:38:17,530:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 15:38:17,904:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 15:38:18,230:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 15:38:18,638:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 15:38:20,058:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-05 15:38:20,087:INFO:Calculating mean and std
2023-11-05 15:38:20,088:INFO:Creating metrics dataframe
2023-11-05 15:38:20,091:INFO:Uploading results into container
2023-11-05 15:38:20,092:INFO:Uploading model into container now
2023-11-05 15:38:20,092:INFO:_master_model_container: 5
2023-11-05 15:38:20,093:INFO:_display_container: 2
2023-11-05 15:38:20,093:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-05 15:38:20,093:INFO:create_model() successfully completed......................................
2023-11-05 15:38:20,177:INFO:SubProcess create_model() end ==================================
2023-11-05 15:38:20,178:INFO:Creating metrics dataframe
2023-11-05 15:38:20,188:INFO:Initializing Ridge Classifier
2023-11-05 15:38:20,188:INFO:Total runtime is 0.8236749132474264 minutes
2023-11-05 15:38:20,192:INFO:SubProcess create_model() called ==================================
2023-11-05 15:38:20,192:INFO:Initializing create_model()
2023-11-05 15:38:20,192:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F8188BA00>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FB1F10DF0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 15:38:20,192:INFO:Checking exceptions
2023-11-05 15:38:20,192:INFO:Importing libraries
2023-11-05 15:38:20,192:INFO:Copying training dataset
2023-11-05 15:38:20,238:INFO:Defining folds
2023-11-05 15:38:20,238:INFO:Declaring metric variables
2023-11-05 15:38:20,242:INFO:Importing untrained model
2023-11-05 15:38:20,246:INFO:Ridge Classifier Imported successfully
2023-11-05 15:38:20,252:INFO:Starting cross validation
2023-11-05 15:38:20,253:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 15:38:20,521:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.13719e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 15:38:20,531:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.02642e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 15:38:20,557:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 15:38:20,569:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 15:38:20,583:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.11761e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 15:38:20,584:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.19282e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 15:38:20,610:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 15:38:20,614:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.04676e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 15:38:20,615:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 15:38:20,633:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 15:38:20,641:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.21583e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 15:38:20,660:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 15:38:20,663:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.20541e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 15:38:20,681:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.16596e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 15:38:20,684:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.20378e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 15:38:20,684:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 15:38:20,694:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.11314e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-05 15:38:20,699:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 15:38:20,701:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 15:38:20,706:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-05 15:38:20,845:INFO:Calculating mean and std
2023-11-05 15:38:20,846:INFO:Creating metrics dataframe
2023-11-05 15:38:20,850:INFO:Uploading results into container
2023-11-05 15:38:20,850:INFO:Uploading model into container now
2023-11-05 15:38:20,851:INFO:_master_model_container: 6
2023-11-05 15:38:20,851:INFO:_display_container: 2
2023-11-05 15:38:20,851:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-11-05 15:38:20,852:INFO:create_model() successfully completed......................................
2023-11-05 15:38:20,942:INFO:SubProcess create_model() end ==================================
2023-11-05 15:38:20,943:INFO:Creating metrics dataframe
2023-11-05 15:38:20,953:INFO:Initializing Random Forest Classifier
2023-11-05 15:38:20,953:INFO:Total runtime is 0.8364284992218017 minutes
2023-11-05 15:38:20,957:INFO:SubProcess create_model() called ==================================
2023-11-05 15:38:20,957:INFO:Initializing create_model()
2023-11-05 15:38:20,957:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F8188BA00>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FB1F10DF0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 15:38:20,957:INFO:Checking exceptions
2023-11-05 15:38:20,957:INFO:Importing libraries
2023-11-05 15:38:20,957:INFO:Copying training dataset
2023-11-05 15:38:21,001:INFO:Defining folds
2023-11-05 15:38:21,001:INFO:Declaring metric variables
2023-11-05 15:38:21,005:INFO:Importing untrained model
2023-11-05 15:38:21,008:INFO:Random Forest Classifier Imported successfully
2023-11-05 15:38:21,015:INFO:Starting cross validation
2023-11-05 15:38:21,016:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 15:38:59,874:INFO:Calculating mean and std
2023-11-05 15:38:59,875:INFO:Creating metrics dataframe
2023-11-05 15:38:59,879:INFO:Uploading results into container
2023-11-05 15:38:59,880:INFO:Uploading model into container now
2023-11-05 15:38:59,880:INFO:_master_model_container: 7
2023-11-05 15:38:59,881:INFO:_display_container: 2
2023-11-05 15:38:59,881:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-11-05 15:38:59,881:INFO:create_model() successfully completed......................................
2023-11-05 15:39:00,005:INFO:SubProcess create_model() end ==================================
2023-11-05 15:39:00,005:INFO:Creating metrics dataframe
2023-11-05 15:39:00,019:INFO:Initializing Quadratic Discriminant Analysis
2023-11-05 15:39:00,019:INFO:Total runtime is 1.4875297943751016 minutes
2023-11-05 15:39:00,024:INFO:SubProcess create_model() called ==================================
2023-11-05 15:39:00,025:INFO:Initializing create_model()
2023-11-05 15:39:00,025:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F8188BA00>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FB1F10DF0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 15:39:00,026:INFO:Checking exceptions
2023-11-05 15:39:00,026:INFO:Importing libraries
2023-11-05 15:39:00,026:INFO:Copying training dataset
2023-11-05 15:39:00,082:INFO:Defining folds
2023-11-05 15:39:00,083:INFO:Declaring metric variables
2023-11-05 15:39:00,086:INFO:Importing untrained model
2023-11-05 15:39:00,091:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-05 15:39:00,099:INFO:Starting cross validation
2023-11-05 15:39:00,101:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 15:39:00,696:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 15:39:00,771:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 15:39:00,899:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 15:39:00,965:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 15:39:01,019:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 15:39:01,058:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 15:39:01,116:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 15:39:01,164:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 15:39:01,205:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 15:39:01,218:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-05 15:39:01,437:INFO:Calculating mean and std
2023-11-05 15:39:01,439:INFO:Creating metrics dataframe
2023-11-05 15:39:01,443:INFO:Uploading results into container
2023-11-05 15:39:01,444:INFO:Uploading model into container now
2023-11-05 15:39:01,444:INFO:_master_model_container: 8
2023-11-05 15:39:01,444:INFO:_display_container: 2
2023-11-05 15:39:01,445:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-05 15:39:01,445:INFO:create_model() successfully completed......................................
2023-11-05 15:39:01,545:INFO:SubProcess create_model() end ==================================
2023-11-05 15:39:01,545:INFO:Creating metrics dataframe
2023-11-05 15:39:01,558:INFO:Initializing Ada Boost Classifier
2023-11-05 15:39:01,559:INFO:Total runtime is 1.5131964286168416 minutes
2023-11-05 15:39:01,563:INFO:SubProcess create_model() called ==================================
2023-11-05 15:39:01,563:INFO:Initializing create_model()
2023-11-05 15:39:01,563:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F8188BA00>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FB1F10DF0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 15:39:01,564:INFO:Checking exceptions
2023-11-05 15:39:01,564:INFO:Importing libraries
2023-11-05 15:39:01,564:INFO:Copying training dataset
2023-11-05 15:39:01,616:INFO:Defining folds
2023-11-05 15:39:01,616:INFO:Declaring metric variables
2023-11-05 15:39:01,621:INFO:Importing untrained model
2023-11-05 15:39:01,625:INFO:Ada Boost Classifier Imported successfully
2023-11-05 15:39:01,633:INFO:Starting cross validation
2023-11-05 15:39:01,634:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 15:39:16,575:INFO:Calculating mean and std
2023-11-05 15:39:16,577:INFO:Creating metrics dataframe
2023-11-05 15:39:16,580:INFO:Uploading results into container
2023-11-05 15:39:16,581:INFO:Uploading model into container now
2023-11-05 15:39:16,581:INFO:_master_model_container: 9
2023-11-05 15:39:16,581:INFO:_display_container: 2
2023-11-05 15:39:16,581:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-11-05 15:39:16,582:INFO:create_model() successfully completed......................................
2023-11-05 15:39:16,665:INFO:SubProcess create_model() end ==================================
2023-11-05 15:39:16,665:INFO:Creating metrics dataframe
2023-11-05 15:39:16,676:INFO:Initializing Gradient Boosting Classifier
2023-11-05 15:39:16,676:INFO:Total runtime is 1.7651545127232868 minutes
2023-11-05 15:39:16,680:INFO:SubProcess create_model() called ==================================
2023-11-05 15:39:16,680:INFO:Initializing create_model()
2023-11-05 15:39:16,680:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F8188BA00>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FB1F10DF0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 15:39:16,680:INFO:Checking exceptions
2023-11-05 15:39:16,680:INFO:Importing libraries
2023-11-05 15:39:16,680:INFO:Copying training dataset
2023-11-05 15:39:16,728:INFO:Defining folds
2023-11-05 15:39:16,728:INFO:Declaring metric variables
2023-11-05 15:39:16,732:INFO:Importing untrained model
2023-11-05 15:39:16,736:INFO:Gradient Boosting Classifier Imported successfully
2023-11-05 15:39:16,744:INFO:Starting cross validation
2023-11-05 15:39:16,745:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 15:40:15,316:INFO:Calculating mean and std
2023-11-05 15:40:15,318:INFO:Creating metrics dataframe
2023-11-05 15:40:15,321:INFO:Uploading results into container
2023-11-05 15:40:15,322:INFO:Uploading model into container now
2023-11-05 15:40:15,322:INFO:_master_model_container: 10
2023-11-05 15:40:15,322:INFO:_display_container: 2
2023-11-05 15:40:15,323:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-11-05 15:40:15,323:INFO:create_model() successfully completed......................................
2023-11-05 15:40:15,404:INFO:SubProcess create_model() end ==================================
2023-11-05 15:40:15,404:INFO:Creating metrics dataframe
2023-11-05 15:40:15,417:INFO:Initializing Linear Discriminant Analysis
2023-11-05 15:40:15,417:INFO:Total runtime is 2.744165511926015 minutes
2023-11-05 15:40:15,420:INFO:SubProcess create_model() called ==================================
2023-11-05 15:40:15,421:INFO:Initializing create_model()
2023-11-05 15:40:15,421:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F8188BA00>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FB1F10DF0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 15:40:15,421:INFO:Checking exceptions
2023-11-05 15:40:15,421:INFO:Importing libraries
2023-11-05 15:40:15,421:INFO:Copying training dataset
2023-11-05 15:40:15,469:INFO:Defining folds
2023-11-05 15:40:15,469:INFO:Declaring metric variables
2023-11-05 15:40:15,473:INFO:Importing untrained model
2023-11-05 15:40:15,477:INFO:Linear Discriminant Analysis Imported successfully
2023-11-05 15:40:15,485:INFO:Starting cross validation
2023-11-05 15:40:15,486:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 15:40:17,055:INFO:Calculating mean and std
2023-11-05 15:40:17,057:INFO:Creating metrics dataframe
2023-11-05 15:40:17,060:INFO:Uploading results into container
2023-11-05 15:40:17,061:INFO:Uploading model into container now
2023-11-05 15:40:17,062:INFO:_master_model_container: 11
2023-11-05 15:40:17,062:INFO:_display_container: 2
2023-11-05 15:40:17,062:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-05 15:40:17,062:INFO:create_model() successfully completed......................................
2023-11-05 15:40:17,141:INFO:SubProcess create_model() end ==================================
2023-11-05 15:40:17,141:INFO:Creating metrics dataframe
2023-11-05 15:40:17,154:INFO:Initializing Extra Trees Classifier
2023-11-05 15:40:17,155:INFO:Total runtime is 2.7731284658114115 minutes
2023-11-05 15:40:17,158:INFO:SubProcess create_model() called ==================================
2023-11-05 15:40:17,158:INFO:Initializing create_model()
2023-11-05 15:40:17,158:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F8188BA00>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FB1F10DF0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 15:40:17,159:INFO:Checking exceptions
2023-11-05 15:40:17,159:INFO:Importing libraries
2023-11-05 15:40:17,159:INFO:Copying training dataset
2023-11-05 15:40:17,202:INFO:Defining folds
2023-11-05 15:40:17,202:INFO:Declaring metric variables
2023-11-05 15:40:17,206:INFO:Importing untrained model
2023-11-05 15:40:17,209:INFO:Extra Trees Classifier Imported successfully
2023-11-05 15:40:17,216:INFO:Starting cross validation
2023-11-05 15:40:17,218:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 15:40:43,396:INFO:Calculating mean and std
2023-11-05 15:40:43,398:INFO:Creating metrics dataframe
2023-11-05 15:40:43,404:INFO:Uploading results into container
2023-11-05 15:40:43,405:INFO:Uploading model into container now
2023-11-05 15:40:43,405:INFO:_master_model_container: 12
2023-11-05 15:40:43,405:INFO:_display_container: 2
2023-11-05 15:40:43,406:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-11-05 15:40:43,406:INFO:create_model() successfully completed......................................
2023-11-05 15:40:43,506:INFO:SubProcess create_model() end ==================================
2023-11-05 15:40:43,506:INFO:Creating metrics dataframe
2023-11-05 15:40:43,519:INFO:Initializing Extreme Gradient Boosting
2023-11-05 15:40:43,519:INFO:Total runtime is 3.212532385190328 minutes
2023-11-05 15:40:43,523:INFO:SubProcess create_model() called ==================================
2023-11-05 15:40:43,523:INFO:Initializing create_model()
2023-11-05 15:40:43,523:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F8188BA00>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FB1F10DF0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 15:40:43,524:INFO:Checking exceptions
2023-11-05 15:40:43,524:INFO:Importing libraries
2023-11-05 15:40:43,524:INFO:Copying training dataset
2023-11-05 15:40:43,571:INFO:Defining folds
2023-11-05 15:40:43,571:INFO:Declaring metric variables
2023-11-05 15:40:43,575:INFO:Importing untrained model
2023-11-05 15:40:43,579:INFO:Extreme Gradient Boosting Imported successfully
2023-11-05 15:40:43,587:INFO:Starting cross validation
2023-11-05 15:40:43,588:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 15:40:47,535:INFO:Calculating mean and std
2023-11-05 15:40:47,536:INFO:Creating metrics dataframe
2023-11-05 15:40:47,541:INFO:Uploading results into container
2023-11-05 15:40:47,541:INFO:Uploading model into container now
2023-11-05 15:40:47,542:INFO:_master_model_container: 13
2023-11-05 15:40:47,542:INFO:_display_container: 2
2023-11-05 15:40:47,543:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2023-11-05 15:40:47,543:INFO:create_model() successfully completed......................................
2023-11-05 15:40:47,620:INFO:SubProcess create_model() end ==================================
2023-11-05 15:40:47,620:INFO:Creating metrics dataframe
2023-11-05 15:40:47,634:INFO:Initializing Light Gradient Boosting Machine
2023-11-05 15:40:47,634:INFO:Total runtime is 3.2811111211776733 minutes
2023-11-05 15:40:47,638:INFO:SubProcess create_model() called ==================================
2023-11-05 15:40:47,638:INFO:Initializing create_model()
2023-11-05 15:40:47,638:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F8188BA00>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FB1F10DF0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 15:40:47,638:INFO:Checking exceptions
2023-11-05 15:40:47,638:INFO:Importing libraries
2023-11-05 15:40:47,639:INFO:Copying training dataset
2023-11-05 15:40:47,681:INFO:Defining folds
2023-11-05 15:40:47,682:INFO:Declaring metric variables
2023-11-05 15:40:47,685:INFO:Importing untrained model
2023-11-05 15:40:47,689:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-05 15:40:47,696:INFO:Starting cross validation
2023-11-05 15:40:47,698:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 15:40:54,295:INFO:Calculating mean and std
2023-11-05 15:40:54,297:INFO:Creating metrics dataframe
2023-11-05 15:40:54,301:INFO:Uploading results into container
2023-11-05 15:40:54,301:INFO:Uploading model into container now
2023-11-05 15:40:54,302:INFO:_master_model_container: 14
2023-11-05 15:40:54,302:INFO:_display_container: 2
2023-11-05 15:40:54,303:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 15:40:54,303:INFO:create_model() successfully completed......................................
2023-11-05 15:40:54,395:INFO:SubProcess create_model() end ==================================
2023-11-05 15:40:54,395:INFO:Creating metrics dataframe
2023-11-05 15:40:54,409:INFO:Initializing Dummy Classifier
2023-11-05 15:40:54,410:INFO:Total runtime is 3.39404981136322 minutes
2023-11-05 15:40:54,414:INFO:SubProcess create_model() called ==================================
2023-11-05 15:40:54,414:INFO:Initializing create_model()
2023-11-05 15:40:54,414:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F8188BA00>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027FB1F10DF0>, model_only=True, return_train_score=False, kwargs={})
2023-11-05 15:40:54,414:INFO:Checking exceptions
2023-11-05 15:40:54,415:INFO:Importing libraries
2023-11-05 15:40:54,415:INFO:Copying training dataset
2023-11-05 15:40:54,460:INFO:Defining folds
2023-11-05 15:40:54,461:INFO:Declaring metric variables
2023-11-05 15:40:54,464:INFO:Importing untrained model
2023-11-05 15:40:54,468:INFO:Dummy Classifier Imported successfully
2023-11-05 15:40:54,475:INFO:Starting cross validation
2023-11-05 15:40:54,476:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 15:40:54,710:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 15:40:54,725:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 15:40:54,766:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 15:40:54,788:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 15:40:54,802:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 15:40:54,825:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 15:40:54,839:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 15:40:54,853:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 15:40:54,868:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 15:40:54,873:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-05 15:40:55,000:INFO:Calculating mean and std
2023-11-05 15:40:55,001:INFO:Creating metrics dataframe
2023-11-05 15:40:55,005:INFO:Uploading results into container
2023-11-05 15:40:55,005:INFO:Uploading model into container now
2023-11-05 15:40:55,006:INFO:_master_model_container: 15
2023-11-05 15:40:55,006:INFO:_display_container: 2
2023-11-05 15:40:55,006:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-11-05 15:40:55,006:INFO:create_model() successfully completed......................................
2023-11-05 15:40:55,098:INFO:SubProcess create_model() end ==================================
2023-11-05 15:40:55,098:INFO:Creating metrics dataframe
2023-11-05 15:40:55,123:INFO:Initializing create_model()
2023-11-05 15:40:55,123:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F8188BA00>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-05 15:40:55,124:INFO:Checking exceptions
2023-11-05 15:40:55,126:INFO:Importing libraries
2023-11-05 15:40:55,126:INFO:Copying training dataset
2023-11-05 15:40:55,172:INFO:Defining folds
2023-11-05 15:40:55,172:INFO:Declaring metric variables
2023-11-05 15:40:55,173:INFO:Importing untrained model
2023-11-05 15:40:55,173:INFO:Declaring custom model
2023-11-05 15:40:55,173:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-05 15:40:55,174:INFO:Cross validation set to False
2023-11-05 15:40:55,174:INFO:Fitting Model
2023-11-05 15:40:55,341:INFO:[LightGBM] [Info] Number of positive: 29322, number of negative: 97741
2023-11-05 15:40:55,362:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015171 seconds.
2023-11-05 15:40:55,362:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-05 15:40:55,362:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-05 15:40:55,363:INFO:[LightGBM] [Info] Number of data points in the train set: 127063, number of used features: 19
2023-11-05 15:40:55,364:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230767 -> initscore=-1.203983
2023-11-05 15:40:55,364:INFO:[LightGBM] [Info] Start training from score -1.203983
2023-11-05 15:40:55,867:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 15:40:55,867:INFO:create_model() successfully completed......................................
2023-11-05 15:40:56,002:INFO:_master_model_container: 15
2023-11-05 15:40:56,002:INFO:_display_container: 2
2023-11-05 15:40:56,002:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 15:40:56,003:INFO:compare_models() successfully completed......................................
2023-11-05 15:40:56,044:INFO:Initializing create_model()
2023-11-05 15:40:56,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F8188BA00>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-05 15:40:56,045:INFO:Checking exceptions
2023-11-05 15:40:56,069:INFO:Importing libraries
2023-11-05 15:40:56,069:INFO:Copying training dataset
2023-11-05 15:40:56,143:INFO:Defining folds
2023-11-05 15:40:56,143:INFO:Declaring metric variables
2023-11-05 15:40:56,148:INFO:Importing untrained model
2023-11-05 15:40:56,152:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-05 15:40:56,160:INFO:Starting cross validation
2023-11-05 15:40:56,161:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-05 15:41:02,704:INFO:Calculating mean and std
2023-11-05 15:41:02,706:INFO:Creating metrics dataframe
2023-11-05 15:41:02,712:INFO:Finalizing model
2023-11-05 15:41:02,874:INFO:[LightGBM] [Info] Number of positive: 29322, number of negative: 97741
2023-11-05 15:41:02,898:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004483 seconds.
2023-11-05 15:41:02,898:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-05 15:41:02,898:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-05 15:41:02,898:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-05 15:41:02,898:INFO:[LightGBM] [Info] Number of data points in the train set: 127063, number of used features: 19
2023-11-05 15:41:02,899:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230767 -> initscore=-1.203983
2023-11-05 15:41:02,899:INFO:[LightGBM] [Info] Start training from score -1.203983
2023-11-05 15:41:03,428:INFO:Uploading results into container
2023-11-05 15:41:03,429:INFO:Uploading model into container now
2023-11-05 15:41:03,444:INFO:_master_model_container: 16
2023-11-05 15:41:03,444:INFO:_display_container: 3
2023-11-05 15:41:03,445:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-05 15:41:03,445:INFO:create_model() successfully completed......................................
2023-11-05 15:41:03,577:INFO:Initializing predict_model()
2023-11-05 15:41:03,577:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F8188BA00>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027F8E214AF0>)
2023-11-05 15:41:03,577:INFO:Checking exceptions
2023-11-05 15:41:03,577:INFO:Preloading libraries
2023-11-05 15:41:04,094:INFO:Initializing evaluate_model()
2023-11-05 15:41:04,094:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F8188BA00>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-11-05 15:41:04,128:INFO:Initializing plot_model()
2023-11-05 15:41:04,128:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F8188BA00>, system=True)
2023-11-05 15:41:04,128:INFO:Checking exceptions
2023-11-05 15:41:04,146:INFO:Preloading libraries
2023-11-05 15:41:04,153:INFO:Copying training dataset
2023-11-05 15:41:04,153:INFO:Plot type: pipeline
2023-11-05 15:41:04,365:INFO:Visual Rendered Successfully
2023-11-05 15:41:04,451:INFO:plot_model() successfully completed......................................
2023-11-05 15:41:04,495:INFO:Initializing interpret_model()
2023-11-05 15:41:04,496:INFO:interpret_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=feature_importance, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027F8188BA00>)
2023-11-05 15:41:04,496:INFO:Checking exceptions
2023-11-05 15:41:04,496:INFO:Soft dependency imported: shap: 0.43.0
2023-11-05 15:41:06,324:INFO:plot type: summary
2023-11-05 15:41:06,324:INFO:Creating TreeExplainer
2023-11-05 15:41:06,456:INFO:Compiling shap values
2023-11-05 15:41:19,119:INFO:Visual Rendered Successfully
2023-11-05 15:41:19,119:INFO:interpret_model() successfully completed......................................
2023-11-06 09:14:47,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-06 09:14:47,129:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-06 09:14:47,129:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-06 09:14:47,129:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-11-06 09:14:51,577:INFO:PyCaret ClassificationExperiment
2023-11-06 09:14:51,577:INFO:Logging name: clf-default-name
2023-11-06 09:14:51,577:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-11-06 09:14:51,577:INFO:version 3.1.0
2023-11-06 09:14:51,577:INFO:Initializing setup()
2023-11-06 09:14:51,577:INFO:self.USI: a736
2023-11-06 09:14:51,578:INFO:self._variable_keys: {'gpu_param', 'memory', 'fold_shuffle_param', 'y_train', 'target_param', 'gpu_n_jobs_param', 'USI', 'fix_imbalance', 'y', 'pipeline', 'y_test', 'seed', 'X', 'X_test', '_available_plots', 'data', '_ml_usecase', 'fold_groups_param', 'exp_id', 'n_jobs_param', 'is_multiclass', 'exp_name_log', 'html_param', 'logging_param', 'fold_generator', 'idx', 'X_train', 'log_plots_param'}
2023-11-06 09:14:51,578:INFO:Checking environment
2023-11-06 09:14:51,578:INFO:python_version: 3.9.18
2023-11-06 09:14:51,578:INFO:python_build: ('main', 'Sep 11 2023 14:09:26')
2023-11-06 09:14:51,578:INFO:machine: AMD64
2023-11-06 09:14:51,578:INFO:platform: Windows-10-10.0.19041-SP0
2023-11-06 09:14:51,578:INFO:Memory: svmem(total=25692647424, available=4544417792, percent=82.3, used=21148229632, free=4544417792)
2023-11-06 09:14:51,578:INFO:Physical Core: 8
2023-11-06 09:14:51,578:INFO:Logical Core: 16
2023-11-06 09:14:51,578:INFO:Checking libraries
2023-11-06 09:14:51,578:INFO:System:
2023-11-06 09:14:51,578:INFO:    python: 3.9.18 (main, Sep 11 2023, 14:09:26) [MSC v.1916 64 bit (AMD64)]
2023-11-06 09:14:51,578:INFO:executable: d:\programas\Anaconda3\envs\meli_test2\python.exe
2023-11-06 09:14:51,578:INFO:   machine: Windows-10-10.0.19041-SP0
2023-11-06 09:14:51,578:INFO:PyCaret required dependencies:
2023-11-06 09:14:51,674:INFO:                 pip: 23.3
2023-11-06 09:14:51,674:INFO:          setuptools: 68.0.0
2023-11-06 09:14:51,674:INFO:             pycaret: 3.1.0
2023-11-06 09:14:51,674:INFO:             IPython: 8.17.2
2023-11-06 09:14:51,674:INFO:          ipywidgets: 8.1.1
2023-11-06 09:14:51,674:INFO:                tqdm: 4.66.1
2023-11-06 09:14:51,674:INFO:               numpy: 1.23.5
2023-11-06 09:14:51,674:INFO:              pandas: 1.5.3
2023-11-06 09:14:51,674:INFO:              jinja2: 3.1.2
2023-11-06 09:14:51,674:INFO:               scipy: 1.10.1
2023-11-06 09:14:51,674:INFO:              joblib: 1.3.2
2023-11-06 09:14:51,674:INFO:             sklearn: 1.2.2
2023-11-06 09:14:51,674:INFO:                pyod: 1.1.1
2023-11-06 09:14:51,674:INFO:            imblearn: 0.11.0
2023-11-06 09:14:51,674:INFO:   category_encoders: 2.6.3
2023-11-06 09:14:51,675:INFO:            lightgbm: 4.1.0
2023-11-06 09:14:51,675:INFO:               numba: 0.58.1
2023-11-06 09:14:51,675:INFO:            requests: 2.31.0
2023-11-06 09:14:51,675:INFO:          matplotlib: 3.8.1
2023-11-06 09:14:51,675:INFO:          scikitplot: 0.3.7
2023-11-06 09:14:51,675:INFO:         yellowbrick: 1.5
2023-11-06 09:14:51,675:INFO:              plotly: 5.18.0
2023-11-06 09:14:51,675:INFO:    plotly-resampler: Not installed
2023-11-06 09:14:51,675:INFO:             kaleido: 0.2.1
2023-11-06 09:14:51,675:INFO:           schemdraw: 0.15
2023-11-06 09:14:51,675:INFO:         statsmodels: 0.14.0
2023-11-06 09:14:51,675:INFO:              sktime: 0.21.1
2023-11-06 09:14:51,675:INFO:               tbats: 1.1.3
2023-11-06 09:14:51,675:INFO:            pmdarima: 2.0.4
2023-11-06 09:14:51,675:INFO:              psutil: 5.9.6
2023-11-06 09:14:51,675:INFO:          markupsafe: 2.1.3
2023-11-06 09:14:51,675:INFO:             pickle5: Not installed
2023-11-06 09:14:51,675:INFO:         cloudpickle: 2.2.1
2023-11-06 09:14:51,675:INFO:         deprecation: 2.1.0
2023-11-06 09:14:51,675:INFO:              xxhash: 3.4.1
2023-11-06 09:14:51,675:INFO:           wurlitzer: Not installed
2023-11-06 09:14:51,675:INFO:PyCaret optional dependencies:
2023-11-06 09:14:52,574:INFO:                shap: 0.43.0
2023-11-06 09:14:52,574:INFO:           interpret: Not installed
2023-11-06 09:14:52,574:INFO:                umap: Not installed
2023-11-06 09:14:52,574:INFO:     ydata_profiling: Not installed
2023-11-06 09:14:52,574:INFO:  explainerdashboard: Not installed
2023-11-06 09:14:52,574:INFO:             autoviz: Not installed
2023-11-06 09:14:52,574:INFO:           fairlearn: Not installed
2023-11-06 09:14:52,574:INFO:          deepchecks: Not installed
2023-11-06 09:14:52,574:INFO:             xgboost: 2.0.1
2023-11-06 09:14:52,574:INFO:            catboost: Not installed
2023-11-06 09:14:52,574:INFO:              kmodes: Not installed
2023-11-06 09:14:52,574:INFO:             mlxtend: Not installed
2023-11-06 09:14:52,574:INFO:       statsforecast: Not installed
2023-11-06 09:14:52,574:INFO:        tune_sklearn: Not installed
2023-11-06 09:14:52,574:INFO:                 ray: Not installed
2023-11-06 09:14:52,574:INFO:            hyperopt: Not installed
2023-11-06 09:14:52,574:INFO:              optuna: Not installed
2023-11-06 09:14:52,574:INFO:               skopt: Not installed
2023-11-06 09:14:52,574:INFO:              mlflow: 2.8.0
2023-11-06 09:14:52,574:INFO:              gradio: Not installed
2023-11-06 09:14:52,574:INFO:             fastapi: 0.104.1
2023-11-06 09:14:52,574:INFO:             uvicorn: 0.24.0
2023-11-06 09:14:52,575:INFO:              m2cgen: Not installed
2023-11-06 09:14:52,575:INFO:           evidently: Not installed
2023-11-06 09:14:52,575:INFO:               fugue: Not installed
2023-11-06 09:14:52,575:INFO:           streamlit: Not installed
2023-11-06 09:14:52,575:INFO:             prophet: Not installed
2023-11-06 09:14:52,575:INFO:None
2023-11-06 09:14:52,575:INFO:Set up data.
2023-11-06 09:14:52,674:INFO:Set up folding strategy.
2023-11-06 09:14:52,674:INFO:Set up train/test split.
2023-11-06 09:14:52,837:INFO:Set up index.
2023-11-06 09:14:52,842:INFO:Assigning column types.
2023-11-06 09:14:52,877:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-11-06 09:14:52,929:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-06 09:14:52,944:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-06 09:14:52,991:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-06 09:14:52,994:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-06 09:14:53,049:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-11-06 09:14:53,050:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-06 09:14:53,082:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-06 09:14:53,085:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-06 09:14:53,085:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-11-06 09:14:53,138:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-06 09:14:53,170:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-06 09:14:53,173:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-06 09:14:53,226:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-11-06 09:14:53,258:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-06 09:14:53,261:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-06 09:14:53,262:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-11-06 09:14:53,348:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-06 09:14:53,351:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-06 09:14:53,437:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-06 09:14:53,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-06 09:14:53,460:INFO:Preparing preprocessing pipeline...
2023-11-06 09:14:53,484:INFO:Set up simple imputation.
2023-11-06 09:14:53,621:INFO:Finished creating preprocessing pipeline.
2023-11-06 09:14:53,632:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\USER\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['a', 'b', 'c', 'd', 'e', 'f', 'h',
                                             'k', 'l', 'm', 'n', 'p', 'monto',
                                             'score', 'Country_AR',
                                             'Country_BR', 'Country_US',
                                             'Country_UY', 'Country_otros',
                                             'hour_early'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-11-06 09:14:53,632:INFO:Creating final display dataframe.
2023-11-06 09:14:53,897:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            fraude
2                   Target type            Binary
3           Original data shape      (181519, 21)
4        Transformed data shape      (181519, 21)
5   Transformed train set shape      (127063, 21)
6    Transformed test set shape       (54456, 21)
7              Numeric features                20
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              a736
2023-11-06 09:14:53,996:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-06 09:14:54,000:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-06 09:14:54,086:INFO:Soft dependency imported: xgboost: 2.0.1
2023-11-06 09:14:54,089:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-11-06 09:14:54,090:INFO:setup() successfully completed in 2.51s...............
2023-11-06 09:14:57,050:INFO:Initializing compare_models()
2023-11-06 09:14:57,051:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-11-06 09:14:57,051:INFO:Checking exceptions
2023-11-06 09:14:57,081:INFO:Preparing display monitor
2023-11-06 09:14:57,103:INFO:Initializing Logistic Regression
2023-11-06 09:14:57,103:INFO:Total runtime is 0.0 minutes
2023-11-06 09:14:57,107:INFO:SubProcess create_model() called ==================================
2023-11-06 09:14:57,107:INFO:Initializing create_model()
2023-11-06 09:14:57,107:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002402C68C640>, model_only=True, return_train_score=False, kwargs={})
2023-11-06 09:14:57,107:INFO:Checking exceptions
2023-11-06 09:14:57,107:INFO:Importing libraries
2023-11-06 09:14:57,107:INFO:Copying training dataset
2023-11-06 09:14:57,164:INFO:Defining folds
2023-11-06 09:14:57,164:INFO:Declaring metric variables
2023-11-06 09:14:57,168:INFO:Importing untrained model
2023-11-06 09:14:57,172:INFO:Logistic Regression Imported successfully
2023-11-06 09:14:57,179:INFO:Starting cross validation
2023-11-06 09:14:57,180:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-06 09:15:03,891:INFO:Calculating mean and std
2023-11-06 09:15:03,893:INFO:Creating metrics dataframe
2023-11-06 09:15:03,898:INFO:Uploading results into container
2023-11-06 09:15:03,898:INFO:Uploading model into container now
2023-11-06 09:15:03,930:INFO:_master_model_container: 1
2023-11-06 09:15:03,930:INFO:_display_container: 2
2023-11-06 09:15:03,930:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-06 09:15:03,930:INFO:create_model() successfully completed......................................
2023-11-06 09:15:04,029:INFO:SubProcess create_model() end ==================================
2023-11-06 09:15:04,029:INFO:Creating metrics dataframe
2023-11-06 09:15:04,036:INFO:Initializing K Neighbors Classifier
2023-11-06 09:15:04,037:INFO:Total runtime is 0.1155760924021403 minutes
2023-11-06 09:15:04,041:INFO:SubProcess create_model() called ==================================
2023-11-06 09:15:04,041:INFO:Initializing create_model()
2023-11-06 09:15:04,041:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002402C68C640>, model_only=True, return_train_score=False, kwargs={})
2023-11-06 09:15:04,041:INFO:Checking exceptions
2023-11-06 09:15:04,043:INFO:Importing libraries
2023-11-06 09:15:04,043:INFO:Copying training dataset
2023-11-06 09:15:04,112:INFO:Defining folds
2023-11-06 09:15:04,112:INFO:Declaring metric variables
2023-11-06 09:15:04,116:INFO:Importing untrained model
2023-11-06 09:15:04,119:INFO:K Neighbors Classifier Imported successfully
2023-11-06 09:15:04,127:INFO:Starting cross validation
2023-11-06 09:15:04,128:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-06 09:15:32,927:INFO:Calculating mean and std
2023-11-06 09:15:32,928:INFO:Creating metrics dataframe
2023-11-06 09:15:32,934:INFO:Uploading results into container
2023-11-06 09:15:32,935:INFO:Uploading model into container now
2023-11-06 09:15:32,936:INFO:_master_model_container: 2
2023-11-06 09:15:32,936:INFO:_display_container: 2
2023-11-06 09:15:32,936:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-11-06 09:15:32,936:INFO:create_model() successfully completed......................................
2023-11-06 09:15:33,024:INFO:SubProcess create_model() end ==================================
2023-11-06 09:15:33,024:INFO:Creating metrics dataframe
2023-11-06 09:15:33,041:INFO:Initializing Naive Bayes
2023-11-06 09:15:33,041:INFO:Total runtime is 0.5989663402239481 minutes
2023-11-06 09:15:33,044:INFO:SubProcess create_model() called ==================================
2023-11-06 09:15:33,044:INFO:Initializing create_model()
2023-11-06 09:15:33,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002402C68C640>, model_only=True, return_train_score=False, kwargs={})
2023-11-06 09:15:33,045:INFO:Checking exceptions
2023-11-06 09:15:33,045:INFO:Importing libraries
2023-11-06 09:15:33,045:INFO:Copying training dataset
2023-11-06 09:15:33,088:INFO:Defining folds
2023-11-06 09:15:33,089:INFO:Declaring metric variables
2023-11-06 09:15:33,092:INFO:Importing untrained model
2023-11-06 09:15:33,095:INFO:Naive Bayes Imported successfully
2023-11-06 09:15:33,102:INFO:Starting cross validation
2023-11-06 09:15:33,102:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-06 09:15:33,989:INFO:Calculating mean and std
2023-11-06 09:15:33,990:INFO:Creating metrics dataframe
2023-11-06 09:15:33,996:INFO:Uploading results into container
2023-11-06 09:15:33,997:INFO:Uploading model into container now
2023-11-06 09:15:33,998:INFO:_master_model_container: 3
2023-11-06 09:15:33,998:INFO:_display_container: 2
2023-11-06 09:15:33,999:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-11-06 09:15:33,999:INFO:create_model() successfully completed......................................
2023-11-06 09:15:34,093:INFO:SubProcess create_model() end ==================================
2023-11-06 09:15:34,093:INFO:Creating metrics dataframe
2023-11-06 09:15:34,102:INFO:Initializing Decision Tree Classifier
2023-11-06 09:15:34,102:INFO:Total runtime is 0.6166436155637105 minutes
2023-11-06 09:15:34,106:INFO:SubProcess create_model() called ==================================
2023-11-06 09:15:34,106:INFO:Initializing create_model()
2023-11-06 09:15:34,106:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002402C68C640>, model_only=True, return_train_score=False, kwargs={})
2023-11-06 09:15:34,106:INFO:Checking exceptions
2023-11-06 09:15:34,106:INFO:Importing libraries
2023-11-06 09:15:34,106:INFO:Copying training dataset
2023-11-06 09:15:34,155:INFO:Defining folds
2023-11-06 09:15:34,156:INFO:Declaring metric variables
2023-11-06 09:15:34,159:INFO:Importing untrained model
2023-11-06 09:15:34,163:INFO:Decision Tree Classifier Imported successfully
2023-11-06 09:15:34,169:INFO:Starting cross validation
2023-11-06 09:15:34,170:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-06 09:15:37,969:INFO:Calculating mean and std
2023-11-06 09:15:37,971:INFO:Creating metrics dataframe
2023-11-06 09:15:37,975:INFO:Uploading results into container
2023-11-06 09:15:37,976:INFO:Uploading model into container now
2023-11-06 09:15:37,976:INFO:_master_model_container: 4
2023-11-06 09:15:37,976:INFO:_display_container: 2
2023-11-06 09:15:37,977:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-11-06 09:15:37,977:INFO:create_model() successfully completed......................................
2023-11-06 09:15:38,061:INFO:SubProcess create_model() end ==================================
2023-11-06 09:15:38,061:INFO:Creating metrics dataframe
2023-11-06 09:15:38,072:INFO:Initializing SVM - Linear Kernel
2023-11-06 09:15:38,072:INFO:Total runtime is 0.6828213612238566 minutes
2023-11-06 09:15:38,075:INFO:SubProcess create_model() called ==================================
2023-11-06 09:15:38,075:INFO:Initializing create_model()
2023-11-06 09:15:38,075:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002402C68C640>, model_only=True, return_train_score=False, kwargs={})
2023-11-06 09:15:38,075:INFO:Checking exceptions
2023-11-06 09:15:38,076:INFO:Importing libraries
2023-11-06 09:15:38,076:INFO:Copying training dataset
2023-11-06 09:15:38,121:INFO:Defining folds
2023-11-06 09:15:38,121:INFO:Declaring metric variables
2023-11-06 09:15:38,124:INFO:Importing untrained model
2023-11-06 09:15:38,129:INFO:SVM - Linear Kernel Imported successfully
2023-11-06 09:15:38,136:INFO:Starting cross validation
2023-11-06 09:15:38,137:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-06 09:15:41,529:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-06 09:15:42,100:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-06 09:15:42,154:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-06 09:15:42,933:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-06 09:15:42,978:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-06 09:15:43,420:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-06 09:15:43,499:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-06 09:15:43,682:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-06 09:15:43,689:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-06 09:15:44,125:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-11-06 09:15:44,255:INFO:Calculating mean and std
2023-11-06 09:15:44,256:INFO:Creating metrics dataframe
2023-11-06 09:15:44,260:INFO:Uploading results into container
2023-11-06 09:15:44,260:INFO:Uploading model into container now
2023-11-06 09:15:44,261:INFO:_master_model_container: 5
2023-11-06 09:15:44,261:INFO:_display_container: 2
2023-11-06 09:15:44,261:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-11-06 09:15:44,262:INFO:create_model() successfully completed......................................
2023-11-06 09:15:44,346:INFO:SubProcess create_model() end ==================================
2023-11-06 09:15:44,347:INFO:Creating metrics dataframe
2023-11-06 09:15:44,357:INFO:Initializing Ridge Classifier
2023-11-06 09:15:44,357:INFO:Total runtime is 0.7875612298647563 minutes
2023-11-06 09:15:44,361:INFO:SubProcess create_model() called ==================================
2023-11-06 09:15:44,361:INFO:Initializing create_model()
2023-11-06 09:15:44,362:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002402C68C640>, model_only=True, return_train_score=False, kwargs={})
2023-11-06 09:15:44,362:INFO:Checking exceptions
2023-11-06 09:15:44,362:INFO:Importing libraries
2023-11-06 09:15:44,362:INFO:Copying training dataset
2023-11-06 09:15:44,405:INFO:Defining folds
2023-11-06 09:15:44,405:INFO:Declaring metric variables
2023-11-06 09:15:44,409:INFO:Importing untrained model
2023-11-06 09:15:44,413:INFO:Ridge Classifier Imported successfully
2023-11-06 09:15:44,420:INFO:Starting cross validation
2023-11-06 09:15:44,421:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-06 09:15:44,853:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.16773e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-06 09:15:44,853:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.16164e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-06 09:15:44,853:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.07032e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-06 09:15:44,853:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.0926e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-06 09:15:44,853:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.07473e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-06 09:15:44,853:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.00691e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-06 09:15:44,853:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\linear_model\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.16051e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2023-11-06 09:15:44,872:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-06 09:15:44,873:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-06 09:15:44,876:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-06 09:15:44,876:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-06 09:15:44,877:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-06 09:15:44,879:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-06 09:15:44,879:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-06 09:15:44,879:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-06 09:15:44,879:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-11-06 09:15:45,019:INFO:Calculating mean and std
2023-11-06 09:15:45,020:INFO:Creating metrics dataframe
2023-11-06 09:15:45,025:INFO:Uploading results into container
2023-11-06 09:15:45,025:INFO:Uploading model into container now
2023-11-06 09:15:45,026:INFO:_master_model_container: 6
2023-11-06 09:15:45,026:INFO:_display_container: 2
2023-11-06 09:15:45,027:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-11-06 09:15:45,027:INFO:create_model() successfully completed......................................
2023-11-06 09:15:45,110:INFO:SubProcess create_model() end ==================================
2023-11-06 09:15:45,110:INFO:Creating metrics dataframe
2023-11-06 09:15:45,121:INFO:Initializing Random Forest Classifier
2023-11-06 09:15:45,121:INFO:Total runtime is 0.8002946575482687 minutes
2023-11-06 09:15:45,124:INFO:SubProcess create_model() called ==================================
2023-11-06 09:15:45,124:INFO:Initializing create_model()
2023-11-06 09:15:45,125:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002402C68C640>, model_only=True, return_train_score=False, kwargs={})
2023-11-06 09:15:45,125:INFO:Checking exceptions
2023-11-06 09:15:45,125:INFO:Importing libraries
2023-11-06 09:15:45,125:INFO:Copying training dataset
2023-11-06 09:15:45,177:INFO:Defining folds
2023-11-06 09:15:45,177:INFO:Declaring metric variables
2023-11-06 09:15:45,181:INFO:Importing untrained model
2023-11-06 09:15:45,184:INFO:Random Forest Classifier Imported successfully
2023-11-06 09:15:45,193:INFO:Starting cross validation
2023-11-06 09:15:45,195:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-06 09:16:22,408:INFO:Calculating mean and std
2023-11-06 09:16:22,410:INFO:Creating metrics dataframe
2023-11-06 09:16:22,414:INFO:Uploading results into container
2023-11-06 09:16:22,415:INFO:Uploading model into container now
2023-11-06 09:16:22,415:INFO:_master_model_container: 7
2023-11-06 09:16:22,416:INFO:_display_container: 2
2023-11-06 09:16:22,416:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-11-06 09:16:22,417:INFO:create_model() successfully completed......................................
2023-11-06 09:16:22,509:INFO:SubProcess create_model() end ==================================
2023-11-06 09:16:22,509:INFO:Creating metrics dataframe
2023-11-06 09:16:22,521:INFO:Initializing Quadratic Discriminant Analysis
2023-11-06 09:16:22,521:INFO:Total runtime is 1.4236366311709086 minutes
2023-11-06 09:16:22,524:INFO:SubProcess create_model() called ==================================
2023-11-06 09:16:22,525:INFO:Initializing create_model()
2023-11-06 09:16:22,525:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002402C68C640>, model_only=True, return_train_score=False, kwargs={})
2023-11-06 09:16:22,525:INFO:Checking exceptions
2023-11-06 09:16:22,525:INFO:Importing libraries
2023-11-06 09:16:22,525:INFO:Copying training dataset
2023-11-06 09:16:22,571:INFO:Defining folds
2023-11-06 09:16:22,571:INFO:Declaring metric variables
2023-11-06 09:16:22,575:INFO:Importing untrained model
2023-11-06 09:16:22,579:INFO:Quadratic Discriminant Analysis Imported successfully
2023-11-06 09:16:22,586:INFO:Starting cross validation
2023-11-06 09:16:22,587:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-06 09:16:23,498:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-06 09:16:23,499:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-06 09:16:23,499:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-06 09:16:23,499:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-06 09:16:23,499:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-06 09:16:23,499:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-06 09:16:23,499:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-06 09:16:23,499:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-11-06 09:16:23,853:INFO:Calculating mean and std
2023-11-06 09:16:23,854:INFO:Creating metrics dataframe
2023-11-06 09:16:23,860:INFO:Uploading results into container
2023-11-06 09:16:23,860:INFO:Uploading model into container now
2023-11-06 09:16:23,861:INFO:_master_model_container: 8
2023-11-06 09:16:23,861:INFO:_display_container: 2
2023-11-06 09:16:23,861:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-11-06 09:16:23,861:INFO:create_model() successfully completed......................................
2023-11-06 09:16:23,946:INFO:SubProcess create_model() end ==================================
2023-11-06 09:16:23,946:INFO:Creating metrics dataframe
2023-11-06 09:16:23,957:INFO:Initializing Ada Boost Classifier
2023-11-06 09:16:23,957:INFO:Total runtime is 1.4475699543952942 minutes
2023-11-06 09:16:23,961:INFO:SubProcess create_model() called ==================================
2023-11-06 09:16:23,961:INFO:Initializing create_model()
2023-11-06 09:16:23,961:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002402C68C640>, model_only=True, return_train_score=False, kwargs={})
2023-11-06 09:16:23,961:INFO:Checking exceptions
2023-11-06 09:16:23,962:INFO:Importing libraries
2023-11-06 09:16:23,962:INFO:Copying training dataset
2023-11-06 09:16:24,004:INFO:Defining folds
2023-11-06 09:16:24,004:INFO:Declaring metric variables
2023-11-06 09:16:24,008:INFO:Importing untrained model
2023-11-06 09:16:24,013:INFO:Ada Boost Classifier Imported successfully
2023-11-06 09:16:24,019:INFO:Starting cross validation
2023-11-06 09:16:24,020:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-06 09:16:36,318:INFO:Calculating mean and std
2023-11-06 09:16:36,320:INFO:Creating metrics dataframe
2023-11-06 09:16:36,324:INFO:Uploading results into container
2023-11-06 09:16:36,325:INFO:Uploading model into container now
2023-11-06 09:16:36,325:INFO:_master_model_container: 9
2023-11-06 09:16:36,325:INFO:_display_container: 2
2023-11-06 09:16:36,326:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-11-06 09:16:36,326:INFO:create_model() successfully completed......................................
2023-11-06 09:16:36,417:INFO:SubProcess create_model() end ==================================
2023-11-06 09:16:36,417:INFO:Creating metrics dataframe
2023-11-06 09:16:36,432:INFO:Initializing Gradient Boosting Classifier
2023-11-06 09:16:36,432:INFO:Total runtime is 1.6554879705111185 minutes
2023-11-06 09:16:36,435:INFO:SubProcess create_model() called ==================================
2023-11-06 09:16:36,436:INFO:Initializing create_model()
2023-11-06 09:16:36,436:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002402C68C640>, model_only=True, return_train_score=False, kwargs={})
2023-11-06 09:16:36,442:INFO:Checking exceptions
2023-11-06 09:16:36,442:INFO:Importing libraries
2023-11-06 09:16:36,442:INFO:Copying training dataset
2023-11-06 09:16:36,483:INFO:Defining folds
2023-11-06 09:16:36,483:INFO:Declaring metric variables
2023-11-06 09:16:36,487:INFO:Importing untrained model
2023-11-06 09:16:36,492:INFO:Gradient Boosting Classifier Imported successfully
2023-11-06 09:16:36,499:INFO:Starting cross validation
2023-11-06 09:16:36,500:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-06 09:17:34,725:INFO:Calculating mean and std
2023-11-06 09:17:34,727:INFO:Creating metrics dataframe
2023-11-06 09:17:34,733:INFO:Uploading results into container
2023-11-06 09:17:34,734:INFO:Uploading model into container now
2023-11-06 09:17:34,735:INFO:_master_model_container: 10
2023-11-06 09:17:34,735:INFO:_display_container: 2
2023-11-06 09:17:34,736:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-11-06 09:17:34,736:INFO:create_model() successfully completed......................................
2023-11-06 09:17:34,829:INFO:SubProcess create_model() end ==================================
2023-11-06 09:17:34,829:INFO:Creating metrics dataframe
2023-11-06 09:17:34,841:INFO:Initializing Linear Discriminant Analysis
2023-11-06 09:17:34,841:INFO:Total runtime is 2.6289654334386188 minutes
2023-11-06 09:17:34,845:INFO:SubProcess create_model() called ==================================
2023-11-06 09:17:34,845:INFO:Initializing create_model()
2023-11-06 09:17:34,845:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002402C68C640>, model_only=True, return_train_score=False, kwargs={})
2023-11-06 09:17:34,845:INFO:Checking exceptions
2023-11-06 09:17:34,845:INFO:Importing libraries
2023-11-06 09:17:34,846:INFO:Copying training dataset
2023-11-06 09:17:34,889:INFO:Defining folds
2023-11-06 09:17:34,889:INFO:Declaring metric variables
2023-11-06 09:17:34,893:INFO:Importing untrained model
2023-11-06 09:17:34,897:INFO:Linear Discriminant Analysis Imported successfully
2023-11-06 09:17:34,904:INFO:Starting cross validation
2023-11-06 09:17:34,905:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-06 09:17:36,550:INFO:Calculating mean and std
2023-11-06 09:17:36,552:INFO:Creating metrics dataframe
2023-11-06 09:17:36,555:INFO:Uploading results into container
2023-11-06 09:17:36,556:INFO:Uploading model into container now
2023-11-06 09:17:36,556:INFO:_master_model_container: 11
2023-11-06 09:17:36,556:INFO:_display_container: 2
2023-11-06 09:17:36,557:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-11-06 09:17:36,557:INFO:create_model() successfully completed......................................
2023-11-06 09:17:36,648:INFO:SubProcess create_model() end ==================================
2023-11-06 09:17:36,648:INFO:Creating metrics dataframe
2023-11-06 09:17:36,662:INFO:Initializing Extra Trees Classifier
2023-11-06 09:17:36,662:INFO:Total runtime is 2.6593170126279193 minutes
2023-11-06 09:17:36,667:INFO:SubProcess create_model() called ==================================
2023-11-06 09:17:36,667:INFO:Initializing create_model()
2023-11-06 09:17:36,667:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002402C68C640>, model_only=True, return_train_score=False, kwargs={})
2023-11-06 09:17:36,667:INFO:Checking exceptions
2023-11-06 09:17:36,667:INFO:Importing libraries
2023-11-06 09:17:36,667:INFO:Copying training dataset
2023-11-06 09:17:36,714:INFO:Defining folds
2023-11-06 09:17:36,714:INFO:Declaring metric variables
2023-11-06 09:17:36,718:INFO:Importing untrained model
2023-11-06 09:17:36,722:INFO:Extra Trees Classifier Imported successfully
2023-11-06 09:17:36,729:INFO:Starting cross validation
2023-11-06 09:17:36,730:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-06 09:18:03,266:INFO:Calculating mean and std
2023-11-06 09:18:03,267:INFO:Creating metrics dataframe
2023-11-06 09:18:03,271:INFO:Uploading results into container
2023-11-06 09:18:03,271:INFO:Uploading model into container now
2023-11-06 09:18:03,272:INFO:_master_model_container: 12
2023-11-06 09:18:03,272:INFO:_display_container: 2
2023-11-06 09:18:03,272:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-11-06 09:18:03,272:INFO:create_model() successfully completed......................................
2023-11-06 09:18:03,382:INFO:SubProcess create_model() end ==================================
2023-11-06 09:18:03,382:INFO:Creating metrics dataframe
2023-11-06 09:18:03,397:INFO:Initializing Extreme Gradient Boosting
2023-11-06 09:18:03,397:INFO:Total runtime is 3.104905331134796 minutes
2023-11-06 09:18:03,401:INFO:SubProcess create_model() called ==================================
2023-11-06 09:18:03,402:INFO:Initializing create_model()
2023-11-06 09:18:03,402:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002402C68C640>, model_only=True, return_train_score=False, kwargs={})
2023-11-06 09:18:03,402:INFO:Checking exceptions
2023-11-06 09:18:03,402:INFO:Importing libraries
2023-11-06 09:18:03,402:INFO:Copying training dataset
2023-11-06 09:18:03,453:INFO:Defining folds
2023-11-06 09:18:03,453:INFO:Declaring metric variables
2023-11-06 09:18:03,457:INFO:Importing untrained model
2023-11-06 09:18:03,462:INFO:Extreme Gradient Boosting Imported successfully
2023-11-06 09:18:03,469:INFO:Starting cross validation
2023-11-06 09:18:03,470:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-06 09:18:11,350:INFO:Calculating mean and std
2023-11-06 09:18:11,352:INFO:Creating metrics dataframe
2023-11-06 09:18:11,355:INFO:Uploading results into container
2023-11-06 09:18:11,356:INFO:Uploading model into container now
2023-11-06 09:18:11,357:INFO:_master_model_container: 13
2023-11-06 09:18:11,357:INFO:_display_container: 2
2023-11-06 09:18:11,358:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2023-11-06 09:18:11,358:INFO:create_model() successfully completed......................................
2023-11-06 09:18:11,447:INFO:SubProcess create_model() end ==================================
2023-11-06 09:18:11,447:INFO:Creating metrics dataframe
2023-11-06 09:18:11,461:INFO:Initializing Light Gradient Boosting Machine
2023-11-06 09:18:11,462:INFO:Total runtime is 3.2393249909083046 minutes
2023-11-06 09:18:11,465:INFO:SubProcess create_model() called ==================================
2023-11-06 09:18:11,466:INFO:Initializing create_model()
2023-11-06 09:18:11,466:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002402C68C640>, model_only=True, return_train_score=False, kwargs={})
2023-11-06 09:18:11,466:INFO:Checking exceptions
2023-11-06 09:18:11,466:INFO:Importing libraries
2023-11-06 09:18:11,466:INFO:Copying training dataset
2023-11-06 09:18:11,511:INFO:Defining folds
2023-11-06 09:18:11,511:INFO:Declaring metric variables
2023-11-06 09:18:11,515:INFO:Importing untrained model
2023-11-06 09:18:11,520:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-06 09:18:11,528:INFO:Starting cross validation
2023-11-06 09:18:11,529:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-06 09:18:16,834:INFO:Calculating mean and std
2023-11-06 09:18:16,836:INFO:Creating metrics dataframe
2023-11-06 09:18:16,840:INFO:Uploading results into container
2023-11-06 09:18:16,841:INFO:Uploading model into container now
2023-11-06 09:18:16,841:INFO:_master_model_container: 14
2023-11-06 09:18:16,841:INFO:_display_container: 2
2023-11-06 09:18:16,842:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-06 09:18:16,842:INFO:create_model() successfully completed......................................
2023-11-06 09:18:16,941:INFO:SubProcess create_model() end ==================================
2023-11-06 09:18:16,941:INFO:Creating metrics dataframe
2023-11-06 09:18:16,955:INFO:Initializing Dummy Classifier
2023-11-06 09:18:16,955:INFO:Total runtime is 3.3308596293131507 minutes
2023-11-06 09:18:16,959:INFO:SubProcess create_model() called ==================================
2023-11-06 09:18:16,959:INFO:Initializing create_model()
2023-11-06 09:18:16,959:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002402C68C640>, model_only=True, return_train_score=False, kwargs={})
2023-11-06 09:18:16,960:INFO:Checking exceptions
2023-11-06 09:18:16,960:INFO:Importing libraries
2023-11-06 09:18:16,960:INFO:Copying training dataset
2023-11-06 09:18:17,004:INFO:Defining folds
2023-11-06 09:18:17,004:INFO:Declaring metric variables
2023-11-06 09:18:17,008:INFO:Importing untrained model
2023-11-06 09:18:17,011:INFO:Dummy Classifier Imported successfully
2023-11-06 09:18:17,018:INFO:Starting cross validation
2023-11-06 09:18:17,019:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-06 09:18:17,218:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-06 09:18:17,264:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-06 09:18:17,268:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-06 09:18:17,272:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-06 09:18:17,289:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-06 09:18:17,303:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-06 09:18:17,308:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-06 09:18:17,341:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-06 09:18:17,349:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-06 09:18:17,351:WARNING:d:\programas\Anaconda3\envs\meli_test2\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-11-06 09:18:17,481:INFO:Calculating mean and std
2023-11-06 09:18:17,483:INFO:Creating metrics dataframe
2023-11-06 09:18:17,486:INFO:Uploading results into container
2023-11-06 09:18:17,487:INFO:Uploading model into container now
2023-11-06 09:18:17,487:INFO:_master_model_container: 15
2023-11-06 09:18:17,487:INFO:_display_container: 2
2023-11-06 09:18:17,487:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-11-06 09:18:17,487:INFO:create_model() successfully completed......................................
2023-11-06 09:18:17,572:INFO:SubProcess create_model() end ==================================
2023-11-06 09:18:17,572:INFO:Creating metrics dataframe
2023-11-06 09:18:17,596:INFO:Initializing create_model()
2023-11-06 09:18:17,597:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-06 09:18:17,597:INFO:Checking exceptions
2023-11-06 09:18:17,599:INFO:Importing libraries
2023-11-06 09:18:17,599:INFO:Copying training dataset
2023-11-06 09:18:17,641:INFO:Defining folds
2023-11-06 09:18:17,641:INFO:Declaring metric variables
2023-11-06 09:18:17,641:INFO:Importing untrained model
2023-11-06 09:18:17,641:INFO:Declaring custom model
2023-11-06 09:18:17,642:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-06 09:18:17,643:INFO:Cross validation set to False
2023-11-06 09:18:17,643:INFO:Fitting Model
2023-11-06 09:18:17,817:INFO:[LightGBM] [Info] Number of positive: 29322, number of negative: 97741
2023-11-06 09:18:17,834:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004593 seconds.
2023-11-06 09:18:17,834:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:18:17,834:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:18:17,834:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:18:17,834:INFO:[LightGBM] [Info] Number of data points in the train set: 127063, number of used features: 20
2023-11-06 09:18:17,835:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230767 -> initscore=-1.203983
2023-11-06 09:18:17,836:INFO:[LightGBM] [Info] Start training from score -1.203983
2023-11-06 09:18:18,294:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-06 09:18:18,294:INFO:create_model() successfully completed......................................
2023-11-06 09:18:18,433:INFO:_master_model_container: 15
2023-11-06 09:18:18,433:INFO:_display_container: 2
2023-11-06 09:18:18,434:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-06 09:18:18,434:INFO:compare_models() successfully completed......................................
2023-11-06 09:20:21,601:INFO:Initializing create_model()
2023-11-06 09:20:21,601:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-11-06 09:20:21,601:INFO:Checking exceptions
2023-11-06 09:20:21,627:INFO:Importing libraries
2023-11-06 09:20:21,627:INFO:Copying training dataset
2023-11-06 09:20:21,705:INFO:Defining folds
2023-11-06 09:20:21,706:INFO:Declaring metric variables
2023-11-06 09:20:21,710:INFO:Importing untrained model
2023-11-06 09:20:21,715:INFO:Light Gradient Boosting Machine Imported successfully
2023-11-06 09:20:21,722:INFO:Starting cross validation
2023-11-06 09:20:21,724:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-06 09:20:29,173:INFO:Calculating mean and std
2023-11-06 09:20:29,175:INFO:Creating metrics dataframe
2023-11-06 09:20:29,187:INFO:Finalizing model
2023-11-06 09:20:29,375:INFO:[LightGBM] [Info] Number of positive: 29322, number of negative: 97741
2023-11-06 09:20:29,393:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012661 seconds.
2023-11-06 09:20:29,393:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:20:29,393:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:20:29,394:INFO:[LightGBM] [Info] Number of data points in the train set: 127063, number of used features: 20
2023-11-06 09:20:29,394:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230767 -> initscore=-1.203983
2023-11-06 09:20:29,394:INFO:[LightGBM] [Info] Start training from score -1.203983
2023-11-06 09:20:29,858:INFO:Uploading results into container
2023-11-06 09:20:29,860:INFO:Uploading model into container now
2023-11-06 09:20:29,876:INFO:_master_model_container: 16
2023-11-06 09:20:29,876:INFO:_display_container: 3
2023-11-06 09:20:29,877:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-11-06 09:20:29,877:INFO:create_model() successfully completed......................................
2023-11-06 09:21:46,296:INFO:Initializing predict_model()
2023-11-06 09:21:46,296:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002405F364550>)
2023-11-06 09:21:46,296:INFO:Checking exceptions
2023-11-06 09:21:46,296:INFO:Preloading libraries
2023-11-06 09:21:49,709:INFO:Initializing evaluate_model()
2023-11-06 09:21:49,709:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-11-06 09:21:49,761:INFO:Initializing plot_model()
2023-11-06 09:21:49,761:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, system=True)
2023-11-06 09:21:49,761:INFO:Checking exceptions
2023-11-06 09:21:49,778:INFO:Preloading libraries
2023-11-06 09:21:49,784:INFO:Copying training dataset
2023-11-06 09:21:49,784:INFO:Plot type: pipeline
2023-11-06 09:21:50,123:INFO:Visual Rendered Successfully
2023-11-06 09:21:50,214:INFO:plot_model() successfully completed......................................
2023-11-06 09:21:58,943:INFO:Initializing plot_model()
2023-11-06 09:21:58,944:INFO:plot_model(plot=rfe, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, system=True)
2023-11-06 09:21:58,944:INFO:Checking exceptions
2023-11-06 09:21:58,963:INFO:Preloading libraries
2023-11-06 09:21:58,969:INFO:Copying training dataset
2023-11-06 09:21:58,969:INFO:Plot type: rfe
2023-11-06 09:21:59,310:INFO:Fitting Model
2023-11-06 09:21:59,433:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:21:59,450:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003788 seconds.
2023-11-06 09:21:59,450:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:21:59,450:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:21:59,450:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:21:59,451:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 20
2023-11-06 09:21:59,451:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:21:59,452:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:21:59,973:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:21:59,994:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003957 seconds.
2023-11-06 09:21:59,994:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:21:59,994:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:21:59,994:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:21:59,994:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 19
2023-11-06 09:21:59,995:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:21:59,995:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:22:00,539:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:22:00,558:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003297 seconds.
2023-11-06 09:22:00,558:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:00,558:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:00,558:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:22:00,559:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 18
2023-11-06 09:22:00,559:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:22:00,560:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:22:01,110:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:22:01,127:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004030 seconds.
2023-11-06 09:22:01,127:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:01,127:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:01,128:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:22:01,128:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 17
2023-11-06 09:22:01,129:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:22:01,129:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:22:01,680:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:22:01,696:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012647 seconds.
2023-11-06 09:22:01,696:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:01,697:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:22:01,697:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 16
2023-11-06 09:22:01,698:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:22:01,698:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:22:02,217:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:22:02,233:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011935 seconds.
2023-11-06 09:22:02,233:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:02,234:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:22:02,234:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 15
2023-11-06 09:22:02,235:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:22:02,235:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:22:02,721:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:22:02,729:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004442 seconds.
2023-11-06 09:22:02,729:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:02,729:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:22:02,730:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 14
2023-11-06 09:22:02,730:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:22:02,730:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:22:03,247:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:22:03,253:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003645 seconds.
2023-11-06 09:22:03,253:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:03,253:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:22:03,254:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 13
2023-11-06 09:22:03,255:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:22:03,255:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:22:03,712:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:22:03,717:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003484 seconds.
2023-11-06 09:22:03,717:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:03,717:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:22:03,718:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 12
2023-11-06 09:22:03,719:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:22:03,719:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:22:04,130:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:22:04,134:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003116 seconds.
2023-11-06 09:22:04,134:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:04,135:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:22:04,135:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 11
2023-11-06 09:22:04,136:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:22:04,136:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:22:04,549:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:22:04,553:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002848 seconds.
2023-11-06 09:22:04,553:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:04,553:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:22:04,553:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 10
2023-11-06 09:22:04,554:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:22:04,555:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:22:05,026:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:22:05,030:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002923 seconds.
2023-11-06 09:22:05,030:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:05,030:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:22:05,030:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 9
2023-11-06 09:22:05,031:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:22:05,032:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:22:05,410:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:22:05,414:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002810 seconds.
2023-11-06 09:22:05,414:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:05,414:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:22:05,415:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 8
2023-11-06 09:22:05,416:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:22:05,416:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:22:05,806:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:22:05,808:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001871 seconds.
2023-11-06 09:22:05,809:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:05,809:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:22:05,809:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 7
2023-11-06 09:22:05,809:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:22:05,810:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:22:06,160:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:22:06,162:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000669 seconds.
2023-11-06 09:22:06,162:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:06,162:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:06,162:INFO:[LightGBM] [Info] Total Bins 1376
2023-11-06 09:22:06,162:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 6
2023-11-06 09:22:06,163:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:22:06,163:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:22:06,518:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:22:06,520:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000464 seconds.
2023-11-06 09:22:06,520:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:06,520:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:06,520:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:22:06,520:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 5
2023-11-06 09:22:06,521:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:22:06,522:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:22:06,870:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:22:06,873:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000784 seconds.
2023-11-06 09:22:06,873:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:06,873:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:06,873:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:22:06,873:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 4
2023-11-06 09:22:06,874:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:22:06,874:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:22:07,210:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:22:07,213:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000765 seconds.
2023-11-06 09:22:07,213:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:07,213:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:07,213:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:22:07,213:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 3
2023-11-06 09:22:07,214:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:22:07,214:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:22:07,532:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:22:07,534:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.
2023-11-06 09:22:07,534:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:07,534:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:07,534:INFO:[LightGBM] [Info] Total Bins 510
2023-11-06 09:22:07,534:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 2
2023-11-06 09:22:07,535:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:22:07,535:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:22:07,816:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:22:07,818:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000281 seconds.
2023-11-06 09:22:07,818:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:07,818:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:07,818:INFO:[LightGBM] [Info] Total Bins 255
2023-11-06 09:22:07,818:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 1
2023-11-06 09:22:07,819:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:22:07,819:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:22:08,173:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:08,191:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005013 seconds.
2023-11-06 09:22:08,191:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:08,191:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:08,191:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:22:08,191:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 20
2023-11-06 09:22:08,192:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:08,192:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:08,743:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:08,758:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010394 seconds.
2023-11-06 09:22:08,758:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:08,759:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:22:08,759:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 19
2023-11-06 09:22:08,760:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:08,760:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:09,261:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:09,278:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004223 seconds.
2023-11-06 09:22:09,278:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:09,278:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:09,279:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:22:09,279:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 18
2023-11-06 09:22:09,280:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:09,280:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:09,798:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:09,814:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003579 seconds.
2023-11-06 09:22:09,814:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:09,814:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:09,814:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:22:09,815:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 17
2023-11-06 09:22:09,815:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:09,816:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:10,340:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:10,356:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003690 seconds.
2023-11-06 09:22:10,356:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:10,357:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:10,357:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:22:10,357:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 16
2023-11-06 09:22:10,358:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:10,358:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:10,889:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:10,915:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003611 seconds.
2023-11-06 09:22:10,915:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:10,915:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:10,915:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:22:10,916:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 15
2023-11-06 09:22:10,916:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:10,916:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:11,460:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:11,467:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004465 seconds.
2023-11-06 09:22:11,467:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:11,468:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:22:11,468:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 14
2023-11-06 09:22:11,469:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:11,469:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:11,971:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:11,978:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004242 seconds.
2023-11-06 09:22:11,978:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:11,978:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:22:11,979:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 13
2023-11-06 09:22:11,980:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:11,980:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:12,462:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:12,467:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003839 seconds.
2023-11-06 09:22:12,467:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:12,468:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:22:12,468:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 12
2023-11-06 09:22:12,469:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:12,469:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:12,890:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:12,895:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003490 seconds.
2023-11-06 09:22:12,895:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:12,895:INFO:[LightGBM] [Info] Total Bins 2205
2023-11-06 09:22:12,896:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 11
2023-11-06 09:22:12,897:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:12,897:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:13,323:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:13,327:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003309 seconds.
2023-11-06 09:22:13,327:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:13,328:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:22:13,328:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 10
2023-11-06 09:22:13,329:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:13,329:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:13,753:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:13,757:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002942 seconds.
2023-11-06 09:22:13,757:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:13,757:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:22:13,758:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 9
2023-11-06 09:22:13,759:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:13,759:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:14,189:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:14,192:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002570 seconds.
2023-11-06 09:22:14,193:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:14,193:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:22:14,193:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 8
2023-11-06 09:22:14,195:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:14,195:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:14,609:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:14,612:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002080 seconds.
2023-11-06 09:22:14,612:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:14,612:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:22:14,612:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 7
2023-11-06 09:22:14,613:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:14,613:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:14,970:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:14,972:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000674 seconds.
2023-11-06 09:22:14,972:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:14,972:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:14,972:INFO:[LightGBM] [Info] Total Bins 1376
2023-11-06 09:22:14,972:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 6
2023-11-06 09:22:14,973:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:14,973:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:15,346:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:15,348:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000497 seconds.
2023-11-06 09:22:15,348:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:15,348:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:15,348:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:22:15,349:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 5
2023-11-06 09:22:15,349:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:15,349:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:15,709:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:15,711:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000824 seconds.
2023-11-06 09:22:15,711:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:15,711:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:15,711:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:22:15,711:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 4
2023-11-06 09:22:15,712:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:15,712:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:16,039:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:16,041:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000396 seconds.
2023-11-06 09:22:16,041:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:16,041:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:16,041:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:22:16,041:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 3
2023-11-06 09:22:16,042:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:16,042:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:16,353:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:16,354:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000788 seconds.
2023-11-06 09:22:16,354:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:16,354:INFO:[LightGBM] [Info] Total Bins 510
2023-11-06 09:22:16,354:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 2
2023-11-06 09:22:16,355:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:16,355:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:16,646:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:16,647:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000225 seconds.
2023-11-06 09:22:16,647:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:16,647:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:16,647:INFO:[LightGBM] [Info] Total Bins 255
2023-11-06 09:22:16,648:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 1
2023-11-06 09:22:16,648:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:16,648:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:17,025:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:17,043:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004805 seconds.
2023-11-06 09:22:17,043:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:17,043:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:17,043:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:22:17,043:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 20
2023-11-06 09:22:17,044:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:17,044:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:17,595:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:17,610:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010634 seconds.
2023-11-06 09:22:17,610:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:17,610:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:22:17,611:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 19
2023-11-06 09:22:17,611:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:17,612:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:18,128:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:18,143:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003729 seconds.
2023-11-06 09:22:18,143:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:18,144:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:18,144:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:22:18,144:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 18
2023-11-06 09:22:18,144:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:18,145:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:18,670:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:18,685:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003904 seconds.
2023-11-06 09:22:18,685:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:18,685:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:18,685:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:22:18,685:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 17
2023-11-06 09:22:18,686:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:18,686:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:19,211:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:19,225:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010426 seconds.
2023-11-06 09:22:19,226:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:19,226:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:22:19,226:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 16
2023-11-06 09:22:19,227:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:19,227:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:19,741:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:19,757:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011971 seconds.
2023-11-06 09:22:19,757:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:19,758:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:22:19,758:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 15
2023-11-06 09:22:19,759:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:19,759:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:20,217:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:20,224:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004435 seconds.
2023-11-06 09:22:20,224:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:20,224:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:22:20,225:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 14
2023-11-06 09:22:20,225:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:20,225:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:20,704:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:20,710:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004071 seconds.
2023-11-06 09:22:20,710:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:20,711:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:22:20,711:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 13
2023-11-06 09:22:20,711:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:20,712:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:21,163:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:21,167:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003568 seconds.
2023-11-06 09:22:21,167:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:21,167:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:22:21,167:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 12
2023-11-06 09:22:21,168:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:21,168:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:21,603:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:21,607:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001009 seconds.
2023-11-06 09:22:21,607:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:21,607:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:21,607:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:22:21,607:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 11
2023-11-06 09:22:21,608:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:21,608:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:22,083:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:22,087:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002943 seconds.
2023-11-06 09:22:22,087:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:22,087:INFO:[LightGBM] [Info] Total Bins 2396
2023-11-06 09:22:22,087:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 10
2023-11-06 09:22:22,088:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:22,089:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:22,482:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:22,485:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000848 seconds.
2023-11-06 09:22:22,485:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:22,486:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:22,486:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:22:22,486:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 9
2023-11-06 09:22:22,486:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:22,486:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:22,921:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:22,923:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001974 seconds.
2023-11-06 09:22:22,923:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:22,923:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:22:22,924:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 8
2023-11-06 09:22:22,924:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:22,924:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:23,285:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:23,287:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001816 seconds.
2023-11-06 09:22:23,288:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:23,288:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:22:23,288:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 7
2023-11-06 09:22:23,288:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:23,288:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:23,635:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:23,637:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000683 seconds.
2023-11-06 09:22:23,637:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:23,637:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:23,637:INFO:[LightGBM] [Info] Total Bins 1376
2023-11-06 09:22:23,637:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 6
2023-11-06 09:22:23,638:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:23,638:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:23,998:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:24,000:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001443 seconds.
2023-11-06 09:22:24,000:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:24,000:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:22:24,000:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 5
2023-11-06 09:22:24,001:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:24,001:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:24,312:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:24,314:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000800 seconds.
2023-11-06 09:22:24,314:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:24,314:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:24,314:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:22:24,314:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 4
2023-11-06 09:22:24,315:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:24,315:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:24,625:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:24,627:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000758 seconds.
2023-11-06 09:22:24,627:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:24,627:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:24,627:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:22:24,627:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 3
2023-11-06 09:22:24,628:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:24,628:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:24,939:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:24,940:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.
2023-11-06 09:22:24,940:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:24,940:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:24,940:INFO:[LightGBM] [Info] Total Bins 510
2023-11-06 09:22:24,940:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 2
2023-11-06 09:22:24,941:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:24,941:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:25,256:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:22:25,257:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000216 seconds.
2023-11-06 09:22:25,257:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:25,257:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:25,257:INFO:[LightGBM] [Info] Total Bins 255
2023-11-06 09:22:25,257:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 1
2023-11-06 09:22:25,258:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:22:25,258:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:22:25,635:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:25,648:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003617 seconds.
2023-11-06 09:22:25,648:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:25,648:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:25,648:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:22:25,648:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:22:25,649:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:25,649:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:26,193:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:26,213:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003460 seconds.
2023-11-06 09:22:26,214:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:26,214:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:26,214:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:22:26,214:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:22:26,214:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:26,215:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:26,740:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:26,756:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003867 seconds.
2023-11-06 09:22:26,756:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:26,756:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:26,757:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:22:26,757:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:22:26,758:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:26,758:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:27,277:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:27,296:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003722 seconds.
2023-11-06 09:22:27,297:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:27,297:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:27,297:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:22:27,297:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:22:27,298:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:27,299:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:27,891:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:27,904:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009051 seconds.
2023-11-06 09:22:27,904:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:27,904:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:22:27,904:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:22:27,905:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:27,905:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:28,367:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:28,382:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011764 seconds.
2023-11-06 09:22:28,382:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:28,382:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:22:28,383:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:22:28,383:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:28,384:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:28,900:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:28,908:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004481 seconds.
2023-11-06 09:22:28,908:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:28,908:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:22:28,908:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:22:28,909:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:28,909:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:29,411:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:29,418:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003556 seconds.
2023-11-06 09:22:29,418:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:29,418:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:29,418:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:22:29,418:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:22:29,419:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:29,419:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:29,926:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:29,930:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001047 seconds.
2023-11-06 09:22:29,930:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:29,930:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:29,930:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:22:29,931:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:22:29,931:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:29,931:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:30,436:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:30,440:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003422 seconds.
2023-11-06 09:22:30,440:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:30,441:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:22:30,441:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:22:30,442:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:30,442:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:30,857:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:30,861:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000948 seconds.
2023-11-06 09:22:30,861:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:30,861:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:30,861:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:22:30,861:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:22:30,861:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:30,862:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:31,344:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:31,347:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000927 seconds.
2023-11-06 09:22:31,348:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:31,348:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:31,348:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:22:31,348:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:22:31,348:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:31,348:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:31,790:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:31,793:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000894 seconds.
2023-11-06 09:22:31,793:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:31,793:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:31,793:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:22:31,793:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:22:31,794:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:31,794:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:32,204:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:32,207:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000740 seconds.
2023-11-06 09:22:32,207:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:32,207:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:32,207:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:22:32,208:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:22:32,208:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:32,208:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:32,596:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:32,598:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001719 seconds.
2023-11-06 09:22:32,598:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:32,598:INFO:[LightGBM] [Info] Total Bins 1376
2023-11-06 09:22:32,598:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:22:32,599:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:32,599:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:32,930:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:32,933:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000583 seconds.
2023-11-06 09:22:32,933:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:32,933:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:32,933:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:22:32,933:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:22:32,933:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:32,933:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:33,266:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:33,268:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000427 seconds.
2023-11-06 09:22:33,268:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:33,268:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:33,268:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:22:33,268:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:22:33,269:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:33,269:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:33,636:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:33,638:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000427 seconds.
2023-11-06 09:22:33,638:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:33,638:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:33,638:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:22:33,638:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 3
2023-11-06 09:22:33,639:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:33,639:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:33,963:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:33,964:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000294 seconds.
2023-11-06 09:22:33,964:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:33,964:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:33,964:INFO:[LightGBM] [Info] Total Bins 510
2023-11-06 09:22:33,964:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 2
2023-11-06 09:22:33,965:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:33,965:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:34,249:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:34,250:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000209 seconds.
2023-11-06 09:22:34,250:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:34,250:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:34,250:INFO:[LightGBM] [Info] Total Bins 255
2023-11-06 09:22:34,250:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 1
2023-11-06 09:22:34,251:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:34,251:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:34,599:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:34,616:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004143 seconds.
2023-11-06 09:22:34,616:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:34,616:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:34,616:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:22:34,617:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:22:34,617:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:34,618:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:35,127:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:35,147:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004255 seconds.
2023-11-06 09:22:35,147:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:35,147:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:35,147:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:22:35,147:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:22:35,148:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:35,148:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:35,679:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:35,694:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003242 seconds.
2023-11-06 09:22:35,694:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:35,694:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:35,694:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:22:35,694:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:22:35,695:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:35,695:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:36,228:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:36,246:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014633 seconds.
2023-11-06 09:22:36,246:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:36,247:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:22:36,247:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:22:36,248:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:36,248:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:36,744:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:36,756:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003323 seconds.
2023-11-06 09:22:36,756:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:36,756:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:36,756:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:22:36,756:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:22:36,757:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:36,757:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:37,240:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:37,255:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003128 seconds.
2023-11-06 09:22:37,255:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:37,255:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:37,255:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:22:37,255:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:22:37,256:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:37,256:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:37,738:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:37,745:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004436 seconds.
2023-11-06 09:22:37,745:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:37,746:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:22:37,746:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:22:37,746:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:37,746:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:38,209:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:38,217:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003422 seconds.
2023-11-06 09:22:38,217:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:38,217:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:38,217:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:22:38,217:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:22:38,218:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:38,218:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:38,730:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:38,734:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000875 seconds.
2023-11-06 09:22:38,735:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:38,735:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:38,735:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:22:38,735:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:22:38,736:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:38,736:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:39,206:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:39,210:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000915 seconds.
2023-11-06 09:22:39,210:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:39,210:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:39,210:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:22:39,211:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:22:39,211:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:39,211:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:39,674:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:39,678:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000858 seconds.
2023-11-06 09:22:39,678:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:39,678:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:39,678:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:22:39,679:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:22:39,679:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:39,679:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:40,103:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:40,106:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002357 seconds.
2023-11-06 09:22:40,106:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:40,106:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:22:40,106:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:22:40,107:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:40,107:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:40,482:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:40,484:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000833 seconds.
2023-11-06 09:22:40,484:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:40,484:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:40,485:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:22:40,485:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:22:40,485:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:40,485:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:40,877:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:40,879:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000975 seconds.
2023-11-06 09:22:40,880:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:40,880:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:40,880:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:22:40,880:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:22:40,881:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:40,881:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:41,250:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:41,253:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001879 seconds.
2023-11-06 09:22:41,253:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:41,253:INFO:[LightGBM] [Info] Total Bins 1530
2023-11-06 09:22:41,253:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:22:41,253:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:41,254:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:41,593:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:41,595:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000542 seconds.
2023-11-06 09:22:41,595:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:41,596:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:41,596:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:22:41,596:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:22:41,596:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:41,596:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:41,937:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:41,939:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000629 seconds.
2023-11-06 09:22:41,939:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:41,939:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:41,939:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:22:41,940:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:22:41,940:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:41,940:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:42,256:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:42,258:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000557 seconds.
2023-11-06 09:22:42,258:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:42,258:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:42,258:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:22:42,258:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 3
2023-11-06 09:22:42,258:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:42,259:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:42,556:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:42,557:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000321 seconds.
2023-11-06 09:22:42,557:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:42,557:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:42,557:INFO:[LightGBM] [Info] Total Bins 510
2023-11-06 09:22:42,557:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 2
2023-11-06 09:22:42,558:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:42,558:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:42,835:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:42,836:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000226 seconds.
2023-11-06 09:22:42,836:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:42,836:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:42,836:INFO:[LightGBM] [Info] Total Bins 255
2023-11-06 09:22:42,836:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 1
2023-11-06 09:22:42,837:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:42,837:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:43,188:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:43,209:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004729 seconds.
2023-11-06 09:22:43,209:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:43,209:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:43,209:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:22:43,209:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:22:43,210:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:43,210:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:43,737:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:43,750:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004075 seconds.
2023-11-06 09:22:43,750:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:43,750:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:43,750:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:22:43,751:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:22:43,751:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:43,751:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:44,260:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:44,276:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003306 seconds.
2023-11-06 09:22:44,276:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:44,276:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:44,277:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:22:44,277:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:22:44,278:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:44,278:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:44,792:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:44,810:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003526 seconds.
2023-11-06 09:22:44,810:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:44,810:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:44,810:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:22:44,811:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:22:44,811:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:44,811:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:45,333:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:45,348:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002904 seconds.
2023-11-06 09:22:45,348:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:45,348:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:45,348:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:22:45,348:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:22:45,349:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:45,349:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:45,852:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:45,869:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002837 seconds.
2023-11-06 09:22:45,869:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:45,869:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:45,869:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:22:45,869:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:22:45,870:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:45,870:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:46,388:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:46,394:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002958 seconds.
2023-11-06 09:22:46,394:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:46,394:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:46,395:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:22:46,395:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:22:46,395:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:46,396:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:46,893:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:46,899:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003657 seconds.
2023-11-06 09:22:46,899:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:46,899:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:22:46,899:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:22:46,900:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:46,900:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:47,352:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:47,356:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003706 seconds.
2023-11-06 09:22:47,356:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:47,357:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:22:47,357:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:22:47,357:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:47,357:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:47,766:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:47,770:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000985 seconds.
2023-11-06 09:22:47,770:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:47,770:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:47,770:INFO:[LightGBM] [Info] Total Bins 2205
2023-11-06 09:22:47,771:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:22:47,771:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:47,771:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:48,230:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:48,233:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000906 seconds.
2023-11-06 09:22:48,233:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:48,234:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:48,234:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:22:48,234:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:22:48,234:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:48,234:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:48,668:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:48,671:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000786 seconds.
2023-11-06 09:22:48,671:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:48,671:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:48,671:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:22:48,671:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:22:48,672:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:48,672:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:49,086:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:49,089:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001008 seconds.
2023-11-06 09:22:49,089:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:49,089:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:49,089:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:22:49,089:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:22:49,090:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:49,090:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:49,487:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:49,489:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001798 seconds.
2023-11-06 09:22:49,489:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:49,490:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:22:49,490:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:22:49,490:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:49,490:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:49,865:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:49,867:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000567 seconds.
2023-11-06 09:22:49,867:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:49,867:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:49,868:INFO:[LightGBM] [Info] Total Bins 1376
2023-11-06 09:22:49,868:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:22:49,868:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:49,868:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:50,218:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:50,220:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000820 seconds.
2023-11-06 09:22:50,220:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:50,221:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:50,221:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:22:50,221:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:22:50,221:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:50,221:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:50,562:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:50,564:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000458 seconds.
2023-11-06 09:22:50,565:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:50,565:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:50,565:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:22:50,565:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:22:50,565:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:50,566:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:50,888:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:50,889:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.
2023-11-06 09:22:50,889:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:50,889:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:50,889:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:22:50,889:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 3
2023-11-06 09:22:50,890:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:50,890:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:51,182:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:51,184:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000879 seconds.
2023-11-06 09:22:51,184:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:51,184:INFO:[LightGBM] [Info] Total Bins 510
2023-11-06 09:22:51,184:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 2
2023-11-06 09:22:51,184:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:51,185:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:51,465:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:51,466:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000230 seconds.
2023-11-06 09:22:51,466:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:51,466:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:51,466:INFO:[LightGBM] [Info] Total Bins 255
2023-11-06 09:22:51,466:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 1
2023-11-06 09:22:51,467:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:51,467:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:51,823:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:51,838:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003703 seconds.
2023-11-06 09:22:51,838:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:51,838:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:51,838:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:22:51,838:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:22:51,839:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:51,839:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:52,358:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:52,378:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004265 seconds.
2023-11-06 09:22:52,378:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:52,378:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:52,378:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:22:52,378:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:22:52,379:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:52,379:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:52,880:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:52,897:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012882 seconds.
2023-11-06 09:22:52,897:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:52,897:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:22:52,898:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:22:52,898:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:52,898:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:53,382:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:53,394:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003353 seconds.
2023-11-06 09:22:53,394:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:53,394:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:53,394:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:22:53,395:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:22:53,395:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:53,395:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:53,901:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:53,914:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009623 seconds.
2023-11-06 09:22:53,915:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:53,915:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:22:53,915:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:22:53,916:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:53,916:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:54,406:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:54,420:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011064 seconds.
2023-11-06 09:22:54,420:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:54,421:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:22:54,421:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:22:54,421:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:54,421:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:54,920:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:54,928:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004691 seconds.
2023-11-06 09:22:54,928:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:54,929:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:22:54,929:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:22:54,930:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:54,930:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:55,510:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:55,517:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004304 seconds.
2023-11-06 09:22:55,517:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:55,517:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:22:55,517:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:22:55,518:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:55,518:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:56,029:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:56,034:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003819 seconds.
2023-11-06 09:22:56,034:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:56,035:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:22:56,035:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:22:56,036:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:56,036:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:56,558:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:56,562:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000990 seconds.
2023-11-06 09:22:56,562:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:56,562:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:56,562:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:22:56,563:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:22:56,563:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:56,563:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:57,046:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:57,050:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001051 seconds.
2023-11-06 09:22:57,050:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:57,050:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:57,050:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:22:57,050:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:22:57,051:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:57,051:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:57,503:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:57,506:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000962 seconds.
2023-11-06 09:22:57,506:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:57,506:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:57,506:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:22:57,507:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:22:57,507:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:57,507:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:57,968:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:57,970:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002083 seconds.
2023-11-06 09:22:57,970:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:22:57,970:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:22:57,970:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:22:57,971:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:57,971:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:58,397:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:58,400:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001000 seconds.
2023-11-06 09:22:58,400:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:58,400:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:58,400:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:22:58,401:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:22:58,401:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:58,401:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:58,800:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:58,802:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000603 seconds.
2023-11-06 09:22:58,802:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:58,802:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:58,802:INFO:[LightGBM] [Info] Total Bins 1530
2023-11-06 09:22:58,802:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:22:58,803:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:58,803:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:59,171:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:59,173:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000802 seconds.
2023-11-06 09:22:59,174:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:59,174:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:59,174:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:22:59,174:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:22:59,175:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:59,175:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:59,518:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:59,520:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000585 seconds.
2023-11-06 09:22:59,520:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:59,520:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:59,521:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:22:59,521:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:22:59,521:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:59,521:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:22:59,858:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:22:59,860:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000367 seconds.
2023-11-06 09:22:59,860:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:22:59,860:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:22:59,860:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:22:59,860:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 3
2023-11-06 09:22:59,861:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:22:59,861:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:00,184:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:00,185:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000353 seconds.
2023-11-06 09:23:00,185:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:00,185:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:00,185:INFO:[LightGBM] [Info] Total Bins 510
2023-11-06 09:23:00,185:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 2
2023-11-06 09:23:00,186:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:00,186:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:00,473:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:00,474:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000219 seconds.
2023-11-06 09:23:00,474:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:00,474:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:00,474:INFO:[LightGBM] [Info] Total Bins 255
2023-11-06 09:23:00,475:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 1
2023-11-06 09:23:00,475:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:00,475:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:00,846:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:00,863:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004950 seconds.
2023-11-06 09:23:00,863:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:00,863:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:00,863:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:23:00,864:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:23:00,864:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:00,865:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:01,434:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:01,450:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003445 seconds.
2023-11-06 09:23:01,450:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:01,451:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:01,451:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:23:01,451:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:23:01,452:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:01,452:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:01,965:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:01,980:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003992 seconds.
2023-11-06 09:23:01,981:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:01,981:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:01,981:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:23:01,981:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:23:01,982:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:01,982:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:02,533:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:02,547:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003834 seconds.
2023-11-06 09:23:02,547:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:02,547:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:02,547:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:23:02,548:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:23:02,548:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:02,548:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:03,066:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:03,082:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014387 seconds.
2023-11-06 09:23:03,083:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:03,083:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:23:03,083:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:23:03,084:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:03,084:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:03,569:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:03,582:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011187 seconds.
2023-11-06 09:23:03,582:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:03,583:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:23:03,583:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:23:03,583:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:03,584:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:04,081:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:04,088:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004667 seconds.
2023-11-06 09:23:04,088:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:04,089:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:23:04,089:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:23:04,089:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:04,090:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:04,621:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:04,626:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003887 seconds.
2023-11-06 09:23:04,627:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:04,627:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:23:04,627:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:23:04,627:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:04,627:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:05,093:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:05,097:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003606 seconds.
2023-11-06 09:23:05,097:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:05,097:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:23:05,098:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:23:05,098:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:05,098:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:05,544:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:05,547:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003122 seconds.
2023-11-06 09:23:05,547:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:05,548:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:23:05,548:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:23:05,548:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:05,549:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:06,001:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:06,004:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000832 seconds.
2023-11-06 09:23:06,004:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:06,004:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:06,005:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:23:06,005:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:23:06,005:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:06,005:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:06,499:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:06,503:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002989 seconds.
2023-11-06 09:23:06,503:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:06,503:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:23:06,504:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:23:06,505:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:06,505:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:06,922:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:06,924:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002218 seconds.
2023-11-06 09:23:06,925:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:06,925:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:23:06,925:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:23:06,926:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:06,926:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:07,343:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:07,346:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000949 seconds.
2023-11-06 09:23:07,346:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:07,346:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:07,346:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:23:07,346:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:23:07,346:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:07,347:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:07,742:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:07,744:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001843 seconds.
2023-11-06 09:23:07,744:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:07,744:INFO:[LightGBM] [Info] Total Bins 1530
2023-11-06 09:23:07,745:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:23:07,745:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:07,745:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:08,112:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:08,114:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000618 seconds.
2023-11-06 09:23:08,114:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:08,114:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:08,114:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:23:08,114:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:23:08,115:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:08,115:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:08,525:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:08,527:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000863 seconds.
2023-11-06 09:23:08,527:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:08,527:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:08,527:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:23:08,527:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:23:08,528:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:08,528:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:08,895:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:08,897:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.
2023-11-06 09:23:08,898:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:08,898:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:08,898:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:23:08,898:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 3
2023-11-06 09:23:08,898:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:08,899:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:09,226:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:09,228:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.
2023-11-06 09:23:09,228:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:09,228:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:09,228:INFO:[LightGBM] [Info] Total Bins 510
2023-11-06 09:23:09,228:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 2
2023-11-06 09:23:09,228:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:09,228:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:09,536:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:09,537:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000234 seconds.
2023-11-06 09:23:09,537:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:09,537:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:09,537:INFO:[LightGBM] [Info] Total Bins 255
2023-11-06 09:23:09,537:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 1
2023-11-06 09:23:09,537:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:09,537:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:09,910:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:09,930:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004610 seconds.
2023-11-06 09:23:09,930:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:09,930:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:09,930:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:23:09,930:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:23:09,931:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:09,931:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:10,550:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:10,568:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003619 seconds.
2023-11-06 09:23:10,569:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:10,569:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:10,569:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:23:10,569:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:23:10,569:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:10,570:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:11,119:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:11,132:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003799 seconds.
2023-11-06 09:23:11,133:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:11,133:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:11,133:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:23:11,133:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:23:11,134:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:11,134:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:11,688:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:11,704:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012950 seconds.
2023-11-06 09:23:11,704:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:11,705:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:23:11,705:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:23:11,706:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:11,706:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:12,196:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:12,212:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003543 seconds.
2023-11-06 09:23:12,212:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:12,212:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:12,212:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:23:12,212:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:23:12,213:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:12,213:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:12,722:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:12,734:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008361 seconds.
2023-11-06 09:23:12,734:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:12,735:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:23:12,735:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:23:12,736:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:12,736:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:13,219:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:13,226:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003124 seconds.
2023-11-06 09:23:13,226:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:13,226:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:13,226:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:23:13,226:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:23:13,227:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:13,227:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:13,857:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:13,865:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004458 seconds.
2023-11-06 09:23:13,865:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:13,865:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:23:13,866:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:23:13,867:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:13,867:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:14,366:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:14,370:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003548 seconds.
2023-11-06 09:23:14,370:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:14,370:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:23:14,370:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:23:14,371:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:14,371:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:14,833:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:14,837:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003077 seconds.
2023-11-06 09:23:14,837:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:14,837:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:23:14,838:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:23:14,838:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:14,839:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:15,270:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:15,276:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004795 seconds.
2023-11-06 09:23:15,276:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:15,276:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:23:15,276:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:23:15,277:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:15,277:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:15,751:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:15,754:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003322 seconds.
2023-11-06 09:23:15,755:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:15,755:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:23:15,755:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:23:15,756:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:15,756:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:16,179:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:16,182:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002246 seconds.
2023-11-06 09:23:16,182:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:16,182:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:23:16,182:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:23:16,182:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:16,183:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:16,635:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:16,637:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000740 seconds.
2023-11-06 09:23:16,637:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:16,638:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:16,638:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:23:16,638:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:23:16,638:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:16,639:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:17,031:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:17,034:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002281 seconds.
2023-11-06 09:23:17,034:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:17,034:INFO:[LightGBM] [Info] Total Bins 1530
2023-11-06 09:23:17,035:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:23:17,035:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:17,035:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:17,394:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:17,396:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001702 seconds.
2023-11-06 09:23:17,397:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:17,397:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:23:17,397:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:23:17,397:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:17,398:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:17,773:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:17,775:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000497 seconds.
2023-11-06 09:23:17,775:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:17,775:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:17,775:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:23:17,776:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:23:17,776:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:17,776:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:18,116:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:18,118:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000371 seconds.
2023-11-06 09:23:18,118:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:18,118:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:18,118:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:23:18,118:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 3
2023-11-06 09:23:18,119:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:18,119:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:18,453:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:18,455:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001806 seconds.
2023-11-06 09:23:18,455:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:18,455:INFO:[LightGBM] [Info] Total Bins 510
2023-11-06 09:23:18,455:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 2
2023-11-06 09:23:18,456:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:18,456:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:18,771:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:18,772:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000274 seconds.
2023-11-06 09:23:18,773:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:18,773:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:18,773:INFO:[LightGBM] [Info] Total Bins 255
2023-11-06 09:23:18,773:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 1
2023-11-06 09:23:18,773:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:18,773:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:19,241:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:19,259:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004080 seconds.
2023-11-06 09:23:19,259:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:19,259:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:19,259:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:23:19,259:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:23:19,260:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:19,260:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:19,947:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:19,962:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003808 seconds.
2023-11-06 09:23:19,962:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:19,963:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:19,963:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:23:19,963:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:23:19,963:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:19,964:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:20,547:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:20,566:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003748 seconds.
2023-11-06 09:23:20,566:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:20,566:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:20,566:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:23:20,566:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:23:20,567:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:20,567:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:21,089:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:21,103:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003042 seconds.
2023-11-06 09:23:21,104:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:21,104:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:21,104:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:23:21,104:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:23:21,105:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:21,105:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:21,622:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:21,637:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003812 seconds.
2023-11-06 09:23:21,637:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:21,637:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:21,638:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:23:21,638:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:23:21,638:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:21,638:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:22,145:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:22,159:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003601 seconds.
2023-11-06 09:23:22,159:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:22,159:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:22,159:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:23:22,159:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:23:22,160:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:22,160:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:22,694:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:22,701:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003289 seconds.
2023-11-06 09:23:22,701:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:22,702:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:22,702:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:23:22,702:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:23:22,702:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:22,702:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:23,235:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:23,241:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003282 seconds.
2023-11-06 09:23:23,241:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:23,241:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:23,241:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:23:23,242:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:23:23,242:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:23,242:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:23,756:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:23,760:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003343 seconds.
2023-11-06 09:23:23,760:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:23,760:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:23:23,760:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:23:23,761:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:23,761:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:24,264:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:24,268:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003118 seconds.
2023-11-06 09:23:24,268:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:24,268:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:23:24,268:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:23:24,269:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:24,269:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:24,672:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:24,676:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001046 seconds.
2023-11-06 09:23:24,676:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:24,676:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:24,676:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:23:24,676:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:23:24,677:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:24,677:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:25,132:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:25,135:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000799 seconds.
2023-11-06 09:23:25,135:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:25,135:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:25,135:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:23:25,136:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:23:25,136:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:25,136:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:25,589:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:25,592:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002204 seconds.
2023-11-06 09:23:25,592:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:25,592:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:23:25,593:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:23:25,593:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:25,593:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:26,073:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:26,076:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002451 seconds.
2023-11-06 09:23:26,076:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:26,076:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:23:26,076:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:23:26,077:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:26,077:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:26,484:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:26,486:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000685 seconds.
2023-11-06 09:23:26,487:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:26,487:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:26,487:INFO:[LightGBM] [Info] Total Bins 1530
2023-11-06 09:23:26,487:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:23:26,487:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:26,488:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:26,872:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:26,873:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000506 seconds.
2023-11-06 09:23:26,874:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:26,874:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:26,874:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:23:26,874:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:23:26,874:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:26,875:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:27,256:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:27,258:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000826 seconds.
2023-11-06 09:23:27,258:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:27,258:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:27,259:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:23:27,259:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:23:27,259:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:27,259:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:27,615:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:27,617:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000348 seconds.
2023-11-06 09:23:27,617:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:27,617:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:27,618:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:23:27,618:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 3
2023-11-06 09:23:27,618:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:27,618:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:27,935:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:27,936:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000768 seconds.
2023-11-06 09:23:27,936:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:27,936:INFO:[LightGBM] [Info] Total Bins 510
2023-11-06 09:23:27,937:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 2
2023-11-06 09:23:27,937:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:27,937:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:28,236:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:28,238:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000248 seconds.
2023-11-06 09:23:28,238:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:28,238:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:28,238:INFO:[LightGBM] [Info] Total Bins 255
2023-11-06 09:23:28,238:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 1
2023-11-06 09:23:28,239:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:28,239:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:28,613:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:23:28,632:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003614 seconds.
2023-11-06 09:23:28,632:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:28,633:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:28,633:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:23:28,633:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 20
2023-11-06 09:23:28,633:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:23:28,634:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:23:29,159:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:23:29,176:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004131 seconds.
2023-11-06 09:23:29,176:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:29,176:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:29,176:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:23:29,176:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 19
2023-11-06 09:23:29,177:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:23:29,177:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:23:29,700:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:23:29,717:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005240 seconds.
2023-11-06 09:23:29,717:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:29,717:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:29,717:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:23:29,718:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 18
2023-11-06 09:23:29,719:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:23:29,720:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:23:30,252:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:23:30,264:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003221 seconds.
2023-11-06 09:23:30,264:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:30,264:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:30,264:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:23:30,264:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 17
2023-11-06 09:23:30,265:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:23:30,265:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:23:30,822:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:23:30,841:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003224 seconds.
2023-11-06 09:23:30,841:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:30,841:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:30,841:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:23:30,841:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 16
2023-11-06 09:23:30,842:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:23:30,842:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:23:31,355:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:23:31,370:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003414 seconds.
2023-11-06 09:23:31,370:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:31,370:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:31,370:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:23:31,371:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 15
2023-11-06 09:23:31,371:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:23:31,371:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:23:31,871:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:23:31,877:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004407 seconds.
2023-11-06 09:23:31,877:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:31,878:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:23:31,878:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 14
2023-11-06 09:23:31,879:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:23:31,879:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:23:32,370:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:23:32,376:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003625 seconds.
2023-11-06 09:23:32,376:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:32,377:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:23:32,377:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 13
2023-11-06 09:23:32,377:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:23:32,377:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:23:32,867:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:23:32,872:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003470 seconds.
2023-11-06 09:23:32,872:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:32,872:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:23:32,872:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 12
2023-11-06 09:23:32,873:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:23:32,873:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:23:33,307:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:23:33,311:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000863 seconds.
2023-11-06 09:23:33,311:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:33,311:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:33,311:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:23:33,311:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 11
2023-11-06 09:23:33,312:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:23:33,312:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:23:33,797:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:23:33,801:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001086 seconds.
2023-11-06 09:23:33,801:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:33,801:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:33,801:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:23:33,801:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 10
2023-11-06 09:23:33,802:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:23:33,802:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:23:34,317:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:23:34,321:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002654 seconds.
2023-11-06 09:23:34,321:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:34,321:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:23:34,322:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 9
2023-11-06 09:23:34,322:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:23:34,322:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:23:34,696:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:23:34,699:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000804 seconds.
2023-11-06 09:23:34,699:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:34,699:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:34,699:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:23:34,699:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 8
2023-11-06 09:23:34,700:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:23:34,700:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:23:35,132:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:23:35,135:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000619 seconds.
2023-11-06 09:23:35,135:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:35,135:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:35,135:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:23:35,135:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 7
2023-11-06 09:23:35,135:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:23:35,136:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:23:35,534:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:23:35,536:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000535 seconds.
2023-11-06 09:23:35,536:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:35,536:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:35,536:INFO:[LightGBM] [Info] Total Bins 1376
2023-11-06 09:23:35,537:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 6
2023-11-06 09:23:35,537:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:23:35,537:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:23:35,935:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:23:35,936:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000467 seconds.
2023-11-06 09:23:35,936:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:35,937:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:35,937:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:23:35,937:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 5
2023-11-06 09:23:35,937:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:23:35,937:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:23:36,346:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:23:36,349:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000848 seconds.
2023-11-06 09:23:36,349:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:36,349:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:36,349:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:23:36,349:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 4
2023-11-06 09:23:36,350:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:23:36,350:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:23:36,683:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:23:36,685:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000745 seconds.
2023-11-06 09:23:36,685:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:36,685:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:36,685:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:23:36,685:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 3
2023-11-06 09:23:36,686:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:23:36,686:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:23:36,993:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:23:36,995:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000812 seconds.
2023-11-06 09:23:36,995:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:36,995:INFO:[LightGBM] [Info] Total Bins 510
2023-11-06 09:23:36,995:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 2
2023-11-06 09:23:36,995:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:23:36,996:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:23:37,394:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:37,410:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003944 seconds.
2023-11-06 09:23:37,410:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:37,410:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:37,410:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:23:37,410:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 20
2023-11-06 09:23:37,411:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:37,411:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:37,950:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:37,967:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003762 seconds.
2023-11-06 09:23:37,967:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:37,967:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:37,967:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:23:37,967:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 19
2023-11-06 09:23:37,968:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:37,968:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:38,489:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:38,504:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003835 seconds.
2023-11-06 09:23:38,504:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:38,504:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:38,504:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:23:38,505:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 18
2023-11-06 09:23:38,505:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:38,505:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:39,024:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:39,040:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003248 seconds.
2023-11-06 09:23:39,040:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:39,040:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:39,040:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:23:39,041:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 17
2023-11-06 09:23:39,042:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:39,042:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:39,570:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:39,582:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003011 seconds.
2023-11-06 09:23:39,582:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:39,582:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:39,582:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:23:39,582:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 16
2023-11-06 09:23:39,583:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:39,583:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:40,082:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:40,104:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018809 seconds.
2023-11-06 09:23:40,104:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:40,105:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:23:40,105:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 15
2023-11-06 09:23:40,106:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:40,106:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:40,580:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:40,587:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003562 seconds.
2023-11-06 09:23:40,587:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:40,587:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:40,587:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:23:40,587:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 14
2023-11-06 09:23:40,588:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:40,588:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:41,095:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:41,101:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003853 seconds.
2023-11-06 09:23:41,101:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:41,102:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:23:41,102:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 13
2023-11-06 09:23:41,102:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:41,102:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:41,643:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:41,647:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003407 seconds.
2023-11-06 09:23:41,647:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:41,648:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:23:41,648:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 12
2023-11-06 09:23:41,648:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:41,649:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:42,089:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:42,093:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001043 seconds.
2023-11-06 09:23:42,093:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:42,093:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:42,094:INFO:[LightGBM] [Info] Total Bins 2205
2023-11-06 09:23:42,094:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 11
2023-11-06 09:23:42,094:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:42,094:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:42,613:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:42,616:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000873 seconds.
2023-11-06 09:23:42,616:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:42,616:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:42,616:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:23:42,617:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 10
2023-11-06 09:23:42,617:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:42,617:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:43,059:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:43,063:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002644 seconds.
2023-11-06 09:23:43,063:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:43,063:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:23:43,063:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 9
2023-11-06 09:23:43,063:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:43,064:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:43,488:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:43,490:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000790 seconds.
2023-11-06 09:23:43,490:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:43,490:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:43,490:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:23:43,491:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 8
2023-11-06 09:23:43,491:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:43,491:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:43,894:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:43,896:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000658 seconds.
2023-11-06 09:23:43,896:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:43,897:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:43,897:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:23:43,897:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 7
2023-11-06 09:23:43,897:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:43,897:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:44,347:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:44,349:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000605 seconds.
2023-11-06 09:23:44,349:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:44,349:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:44,350:INFO:[LightGBM] [Info] Total Bins 1376
2023-11-06 09:23:44,350:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 6
2023-11-06 09:23:44,350:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:44,350:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:44,719:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:44,721:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000518 seconds.
2023-11-06 09:23:44,721:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:44,722:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:44,722:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:23:44,722:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 5
2023-11-06 09:23:44,722:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:44,722:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:45,114:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:45,116:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000619 seconds.
2023-11-06 09:23:45,116:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:45,116:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:45,116:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:23:45,116:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 4
2023-11-06 09:23:45,116:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:45,116:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:45,491:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:45,493:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2023-11-06 09:23:45,493:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:45,493:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:45,493:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:23:45,493:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 3
2023-11-06 09:23:45,493:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:45,494:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:45,800:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:45,801:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000378 seconds.
2023-11-06 09:23:45,802:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:45,802:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:45,802:INFO:[LightGBM] [Info] Total Bins 510
2023-11-06 09:23:45,802:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 2
2023-11-06 09:23:45,803:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:45,803:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:46,218:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:46,238:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004298 seconds.
2023-11-06 09:23:46,238:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:46,238:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:46,238:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:23:46,239:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 20
2023-11-06 09:23:46,239:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:46,240:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:46,781:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:46,800:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003516 seconds.
2023-11-06 09:23:46,801:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:46,801:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:46,801:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:23:46,801:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 19
2023-11-06 09:23:46,802:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:46,802:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:47,349:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:47,362:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003902 seconds.
2023-11-06 09:23:47,363:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:47,363:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:47,363:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:23:47,363:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 18
2023-11-06 09:23:47,364:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:47,364:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:47,976:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:47,993:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003297 seconds.
2023-11-06 09:23:47,993:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:47,993:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:47,993:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:23:47,993:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 17
2023-11-06 09:23:47,994:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:47,994:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:48,645:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:48,660:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003155 seconds.
2023-11-06 09:23:48,661:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:48,661:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:48,661:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:23:48,661:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 16
2023-11-06 09:23:48,662:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:48,662:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:49,262:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:49,276:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002844 seconds.
2023-11-06 09:23:49,277:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:49,277:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:49,277:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:23:49,277:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 15
2023-11-06 09:23:49,278:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:49,278:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:49,822:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:49,830:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005585 seconds.
2023-11-06 09:23:49,830:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:49,831:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:23:49,831:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 14
2023-11-06 09:23:49,831:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:49,831:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:50,344:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:50,350:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002510 seconds.
2023-11-06 09:23:50,350:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:50,350:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:50,351:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:23:50,351:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 13
2023-11-06 09:23:50,351:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:50,351:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:50,922:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:50,926:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000935 seconds.
2023-11-06 09:23:50,926:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:50,926:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:50,926:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:23:50,927:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 12
2023-11-06 09:23:50,927:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:50,927:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:51,528:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:51,532:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000958 seconds.
2023-11-06 09:23:51,532:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:51,532:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:51,532:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:23:51,533:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 11
2023-11-06 09:23:51,533:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:51,533:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:52,155:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:52,158:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002662 seconds.
2023-11-06 09:23:52,158:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:52,158:INFO:[LightGBM] [Info] Total Bins 2396
2023-11-06 09:23:52,158:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 10
2023-11-06 09:23:52,159:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:52,159:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:52,637:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:52,641:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001076 seconds.
2023-11-06 09:23:52,641:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:52,641:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:52,641:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:23:52,641:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 9
2023-11-06 09:23:52,642:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:52,642:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:53,069:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:53,072:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000732 seconds.
2023-11-06 09:23:53,072:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:53,072:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:53,072:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:23:53,072:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 8
2023-11-06 09:23:53,073:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:53,073:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:53,511:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:53,513:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001756 seconds.
2023-11-06 09:23:53,513:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:53,513:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:23:53,513:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 7
2023-11-06 09:23:53,514:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:53,514:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:53,871:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:53,874:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000663 seconds.
2023-11-06 09:23:53,874:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:53,874:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:53,874:INFO:[LightGBM] [Info] Total Bins 1376
2023-11-06 09:23:53,874:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 6
2023-11-06 09:23:53,875:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:53,875:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:54,243:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:54,245:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000450 seconds.
2023-11-06 09:23:54,245:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:54,245:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:54,245:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:23:54,245:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 5
2023-11-06 09:23:54,246:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:54,246:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:54,601:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:54,603:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000795 seconds.
2023-11-06 09:23:54,603:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:54,603:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:54,603:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:23:54,603:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 4
2023-11-06 09:23:54,604:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:54,604:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:54,949:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:54,951:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000732 seconds.
2023-11-06 09:23:54,951:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:54,951:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:54,951:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:23:54,951:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 3
2023-11-06 09:23:54,952:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:54,952:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:55,281:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:23:55,283:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000335 seconds.
2023-11-06 09:23:55,283:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:55,283:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:55,283:INFO:[LightGBM] [Info] Total Bins 510
2023-11-06 09:23:55,283:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 2
2023-11-06 09:23:55,284:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:23:55,284:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:23:55,695:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:55,710:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005072 seconds.
2023-11-06 09:23:55,710:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:55,710:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:55,710:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:23:55,710:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:23:55,711:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:55,711:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:56,298:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:56,319:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003720 seconds.
2023-11-06 09:23:56,319:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:56,319:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:56,319:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:23:56,319:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:23:56,320:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:56,321:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:56,863:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:56,882:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003474 seconds.
2023-11-06 09:23:56,882:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:56,882:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:56,882:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:23:56,882:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:23:56,883:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:56,883:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:57,528:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:57,546:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003222 seconds.
2023-11-06 09:23:57,547:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:57,547:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:57,547:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:23:57,547:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:23:57,548:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:57,548:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:58,101:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:58,117:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004192 seconds.
2023-11-06 09:23:58,117:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:23:58,117:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:23:58,117:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:23:58,117:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:23:58,117:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:58,118:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:58,692:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:58,705:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009750 seconds.
2023-11-06 09:23:58,705:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:58,706:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:23:58,706:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:23:58,706:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:58,706:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:59,208:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:59,215:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004971 seconds.
2023-11-06 09:23:59,215:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:59,216:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:23:59,216:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:23:59,217:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:59,217:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:23:59,735:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:23:59,742:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003829 seconds.
2023-11-06 09:23:59,742:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:23:59,742:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:23:59,742:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:23:59,743:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:23:59,743:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:00,299:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:00,304:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003855 seconds.
2023-11-06 09:24:00,304:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:00,304:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:24:00,304:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:24:00,305:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:00,305:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:00,755:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:00,760:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004259 seconds.
2023-11-06 09:24:00,760:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:00,760:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:24:00,761:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:24:00,761:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:00,761:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:01,209:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:01,213:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002936 seconds.
2023-11-06 09:24:01,213:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:01,213:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:24:01,213:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:24:01,214:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:01,214:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:01,639:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:01,642:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000752 seconds.
2023-11-06 09:24:01,642:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:01,642:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:01,642:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:24:01,642:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:24:01,643:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:01,643:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:02,103:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:02,106:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001044 seconds.
2023-11-06 09:24:02,106:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:02,106:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:02,106:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:24:02,106:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:24:02,107:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:02,107:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:02,535:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:02,537:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000767 seconds.
2023-11-06 09:24:02,537:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:02,537:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:02,537:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:24:02,537:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:24:02,538:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:02,538:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:02,927:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:02,930:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000608 seconds.
2023-11-06 09:24:02,930:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:02,930:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:02,930:INFO:[LightGBM] [Info] Total Bins 1376
2023-11-06 09:24:02,930:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:24:02,930:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:02,930:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:03,301:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:03,303:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000608 seconds.
2023-11-06 09:24:03,303:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:03,303:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:03,303:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:24:03,303:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:24:03,304:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:03,304:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:03,675:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:03,677:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000507 seconds.
2023-11-06 09:24:03,677:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:03,677:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:03,677:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:24:03,677:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:24:03,678:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:03,678:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:04,010:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:04,012:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000378 seconds.
2023-11-06 09:24:04,012:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:04,012:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:04,012:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:24:04,012:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 3
2023-11-06 09:24:04,013:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:04,013:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:04,351:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:04,352:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000363 seconds.
2023-11-06 09:24:04,352:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:04,353:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:04,353:INFO:[LightGBM] [Info] Total Bins 510
2023-11-06 09:24:04,353:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 2
2023-11-06 09:24:04,353:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:04,353:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:04,751:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:04,772:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005765 seconds.
2023-11-06 09:24:04,772:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:04,772:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:04,772:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:24:04,773:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:24:04,773:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:04,773:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:05,367:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:05,384:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004541 seconds.
2023-11-06 09:24:05,384:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:05,384:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:05,385:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:24:05,385:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:24:05,385:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:05,386:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:06,052:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:06,072:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005567 seconds.
2023-11-06 09:24:06,072:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:06,072:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:06,072:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:24:06,072:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:24:06,073:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:06,073:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:06,694:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:06,709:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003143 seconds.
2023-11-06 09:24:06,709:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:06,709:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:06,709:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:24:06,709:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:24:06,710:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:06,710:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:07,239:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:07,254:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003572 seconds.
2023-11-06 09:24:07,254:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:07,254:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:07,255:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:24:07,255:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:24:07,255:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:07,255:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:07,765:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:07,779:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003112 seconds.
2023-11-06 09:24:07,780:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:07,780:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:07,780:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:24:07,780:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:24:07,781:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:07,781:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:08,355:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:08,362:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004474 seconds.
2023-11-06 09:24:08,362:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:08,363:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:24:08,363:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:24:08,364:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:08,364:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:08,894:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:08,900:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002882 seconds.
2023-11-06 09:24:08,900:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:08,900:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:08,900:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:24:08,900:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:24:08,901:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:08,901:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:09,486:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:09,490:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003667 seconds.
2023-11-06 09:24:09,491:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:09,491:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:24:09,491:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:24:09,492:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:09,492:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:09,938:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:09,943:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003829 seconds.
2023-11-06 09:24:09,943:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:09,943:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:24:09,943:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:24:09,944:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:09,944:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:10,393:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:10,397:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003033 seconds.
2023-11-06 09:24:10,397:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:10,397:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:24:10,397:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:24:10,398:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:10,398:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:10,821:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:10,825:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002725 seconds.
2023-11-06 09:24:10,825:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:10,825:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:24:10,825:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:24:10,826:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:10,826:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:11,220:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:11,223:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002118 seconds.
2023-11-06 09:24:11,223:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:11,223:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:24:11,223:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:24:11,224:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:11,224:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:11,616:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:11,618:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000966 seconds.
2023-11-06 09:24:11,618:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:11,619:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:11,619:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:24:11,619:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:24:11,619:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:11,619:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:12,028:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:12,030:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001783 seconds.
2023-11-06 09:24:12,030:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:12,030:INFO:[LightGBM] [Info] Total Bins 1530
2023-11-06 09:24:12,030:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:24:12,031:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:12,031:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:12,387:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:12,389:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000570 seconds.
2023-11-06 09:24:12,389:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:12,389:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:12,389:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:24:12,389:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:24:12,390:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:12,390:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:12,747:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:12,749:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000833 seconds.
2023-11-06 09:24:12,749:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:12,749:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:12,749:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:24:12,749:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:24:12,750:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:12,750:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:13,077:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:13,079:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000562 seconds.
2023-11-06 09:24:13,079:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:13,079:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:13,079:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:24:13,079:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 3
2023-11-06 09:24:13,080:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:13,080:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:13,397:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:13,398:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000273 seconds.
2023-11-06 09:24:13,398:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:13,398:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:13,398:INFO:[LightGBM] [Info] Total Bins 510
2023-11-06 09:24:13,398:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 2
2023-11-06 09:24:13,399:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:13,399:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:13,805:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:13,821:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003794 seconds.
2023-11-06 09:24:13,821:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:13,821:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:13,821:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:24:13,821:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:24:13,822:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:13,822:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:14,369:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:14,384:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004319 seconds.
2023-11-06 09:24:14,384:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:14,384:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:14,384:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:24:14,385:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:24:14,385:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:14,385:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:14,940:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:14,959:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003426 seconds.
2023-11-06 09:24:14,959:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:14,959:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:14,959:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:24:14,959:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:24:14,960:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:14,960:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:15,504:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:15,520:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003824 seconds.
2023-11-06 09:24:15,520:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:15,520:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:15,520:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:24:15,520:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:24:15,521:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:15,521:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:16,086:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:16,101:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003390 seconds.
2023-11-06 09:24:16,101:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:16,101:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:16,102:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:24:16,102:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:24:16,102:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:16,102:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:16,612:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:16,626:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003041 seconds.
2023-11-06 09:24:16,626:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:16,626:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:16,626:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:24:16,626:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:24:16,627:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:16,627:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:17,127:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:17,134:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004177 seconds.
2023-11-06 09:24:17,134:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:17,134:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:24:17,134:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:24:17,135:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:17,135:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:17,600:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:17,606:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003235 seconds.
2023-11-06 09:24:17,607:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:17,607:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:17,607:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:24:17,607:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:24:17,607:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:17,608:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:18,111:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:18,116:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003757 seconds.
2023-11-06 09:24:18,116:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:18,116:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:24:18,116:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:24:18,117:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:18,117:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:18,536:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:18,540:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000994 seconds.
2023-11-06 09:24:18,540:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:18,540:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:18,540:INFO:[LightGBM] [Info] Total Bins 2205
2023-11-06 09:24:18,541:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:24:18,541:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:18,541:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:19,023:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:19,027:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003588 seconds.
2023-11-06 09:24:19,027:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:19,028:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:24:19,028:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:24:19,029:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:19,029:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:19,478:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:19,481:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001024 seconds.
2023-11-06 09:24:19,481:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:19,482:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:19,482:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:24:19,482:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:24:19,482:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:19,482:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:19,965:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:19,969:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002965 seconds.
2023-11-06 09:24:19,969:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:19,969:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:24:19,969:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:24:19,970:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:19,970:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:20,407:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:20,409:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000725 seconds.
2023-11-06 09:24:20,410:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:20,410:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:20,410:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:24:20,410:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:24:20,410:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:20,410:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:20,835:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:20,838:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000762 seconds.
2023-11-06 09:24:20,838:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:20,838:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:20,838:INFO:[LightGBM] [Info] Total Bins 1376
2023-11-06 09:24:20,838:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:24:20,839:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:20,839:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:21,244:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:21,246:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000835 seconds.
2023-11-06 09:24:21,247:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:21,247:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:21,247:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:24:21,247:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:24:21,248:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:21,248:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:21,614:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:21,616:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000424 seconds.
2023-11-06 09:24:21,616:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:21,616:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:21,616:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:24:21,616:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:24:21,617:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:21,617:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:21,966:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:21,967:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000397 seconds.
2023-11-06 09:24:21,967:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:21,968:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:21,968:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:24:21,968:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 3
2023-11-06 09:24:21,968:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:21,968:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:22,295:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:22,296:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000747 seconds.
2023-11-06 09:24:22,296:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:22,296:INFO:[LightGBM] [Info] Total Bins 510
2023-11-06 09:24:22,296:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 2
2023-11-06 09:24:22,297:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:22,297:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:22,704:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:22,724:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003929 seconds.
2023-11-06 09:24:22,724:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:22,725:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:22,725:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:24:22,725:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:24:22,726:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:22,726:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:23,267:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:23,282:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012537 seconds.
2023-11-06 09:24:23,283:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:23,283:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:24:23,283:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:24:23,284:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:23,284:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:23,799:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:23,817:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003303 seconds.
2023-11-06 09:24:23,817:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:23,817:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:23,818:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:24:23,818:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:24:23,818:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:23,818:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:24,353:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:24,368:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003795 seconds.
2023-11-06 09:24:24,369:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:24,369:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:24,369:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:24:24,369:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:24:24,370:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:24,370:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:24,884:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:24,898:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003907 seconds.
2023-11-06 09:24:24,898:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:24,899:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:24,899:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:24:24,899:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:24:24,899:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:24,899:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:25,415:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:25,432:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003120 seconds.
2023-11-06 09:24:25,432:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:25,432:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:25,432:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:24:25,433:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:24:25,433:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:25,433:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:25,933:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:25,940:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003383 seconds.
2023-11-06 09:24:25,940:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:25,940:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:25,941:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:24:25,941:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:24:25,941:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:25,941:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:26,469:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:26,475:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004068 seconds.
2023-11-06 09:24:26,475:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:26,476:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:24:26,476:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:24:26,476:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:26,476:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:26,975:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:26,978:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003316 seconds.
2023-11-06 09:24:26,978:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:26,979:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:24:26,979:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:24:26,980:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:26,980:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:27,472:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:27,475:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003069 seconds.
2023-11-06 09:24:27,475:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:27,476:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:24:27,476:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:24:27,476:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:27,476:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:27,981:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:27,985:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003385 seconds.
2023-11-06 09:24:27,985:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:27,986:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:24:27,986:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:24:27,986:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:27,986:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:28,413:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:28,416:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000795 seconds.
2023-11-06 09:24:28,417:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:28,417:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:28,417:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:24:28,417:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:24:28,417:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:28,418:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:28,877:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:28,880:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000817 seconds.
2023-11-06 09:24:28,880:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:28,880:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:28,880:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:24:28,881:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:24:28,881:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:28,881:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:29,314:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:29,317:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000970 seconds.
2023-11-06 09:24:29,317:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:29,317:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:29,317:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:24:29,317:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:24:29,318:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:29,318:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:29,747:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:29,750:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001712 seconds.
2023-11-06 09:24:29,750:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:29,750:INFO:[LightGBM] [Info] Total Bins 1530
2023-11-06 09:24:29,750:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:24:29,751:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:29,751:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:30,118:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:30,120:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000546 seconds.
2023-11-06 09:24:30,120:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:30,120:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:30,120:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:24:30,120:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:24:30,121:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:30,121:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:30,484:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:30,486:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000798 seconds.
2023-11-06 09:24:30,486:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:30,487:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:30,487:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:24:30,487:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:24:30,487:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:30,487:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:30,831:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:30,832:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.
2023-11-06 09:24:30,832:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:30,832:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:30,832:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:24:30,833:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 3
2023-11-06 09:24:30,833:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:30,833:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:31,160:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:31,162:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.
2023-11-06 09:24:31,162:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:31,162:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:31,162:INFO:[LightGBM] [Info] Total Bins 510
2023-11-06 09:24:31,162:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 2
2023-11-06 09:24:31,163:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:31,163:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:31,624:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:31,638:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004275 seconds.
2023-11-06 09:24:31,638:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:31,638:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:31,638:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:24:31,638:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:24:31,639:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:31,639:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:32,227:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:32,245:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004443 seconds.
2023-11-06 09:24:32,245:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:32,245:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:32,245:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:24:32,245:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:24:32,246:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:32,246:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:32,873:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:32,896:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003980 seconds.
2023-11-06 09:24:32,896:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:32,896:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:32,896:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:24:32,897:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:24:32,897:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:32,897:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:33,468:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:33,483:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003171 seconds.
2023-11-06 09:24:33,483:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:33,483:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:33,483:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:24:33,484:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:24:33,484:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:33,484:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:34,010:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:34,025:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003421 seconds.
2023-11-06 09:24:34,025:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:34,025:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:34,025:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:24:34,026:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:24:34,026:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:34,026:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:34,603:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:34,617:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002654 seconds.
2023-11-06 09:24:34,617:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:34,617:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:34,617:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:24:34,618:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:24:34,618:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:34,618:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:35,169:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:35,176:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003223 seconds.
2023-11-06 09:24:35,176:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:35,176:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:35,177:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:24:35,177:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:24:35,177:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:35,177:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:35,713:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:35,719:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003223 seconds.
2023-11-06 09:24:35,719:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:35,720:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:35,720:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:24:35,720:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:24:35,720:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:35,720:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:36,225:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:36,229:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003431 seconds.
2023-11-06 09:24:36,229:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:36,229:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:24:36,229:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:24:36,230:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:36,230:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:36,645:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:36,648:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002689 seconds.
2023-11-06 09:24:36,648:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:36,648:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:24:36,649:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:24:36,649:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:36,649:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:37,047:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:37,051:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000850 seconds.
2023-11-06 09:24:37,051:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:37,051:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:37,051:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:24:37,051:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:24:37,051:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:37,051:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:37,490:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:37,493:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000755 seconds.
2023-11-06 09:24:37,493:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:37,493:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:37,493:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:24:37,493:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:24:37,494:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:37,494:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:38,094:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:38,097:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001055 seconds.
2023-11-06 09:24:38,098:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:38,098:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:38,098:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:24:38,098:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:24:38,098:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:38,098:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:38,521:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:38,523:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000754 seconds.
2023-11-06 09:24:38,523:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:38,523:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:38,524:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:24:38,524:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:24:38,525:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:38,525:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:38,917:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:38,919:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000619 seconds.
2023-11-06 09:24:38,920:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:38,920:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:38,920:INFO:[LightGBM] [Info] Total Bins 1530
2023-11-06 09:24:38,920:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:24:38,920:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:38,920:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:39,312:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:39,314:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000624 seconds.
2023-11-06 09:24:39,314:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:39,314:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:39,314:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:24:39,314:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:24:39,314:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:39,314:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:39,671:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:39,673:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000814 seconds.
2023-11-06 09:24:39,673:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:39,673:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:39,674:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:24:39,674:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:24:39,674:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:39,674:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:40,018:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:40,019:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.
2023-11-06 09:24:40,019:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:40,019:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:40,019:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:24:40,020:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 3
2023-11-06 09:24:40,020:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:40,020:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:40,349:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:40,350:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000559 seconds.
2023-11-06 09:24:40,350:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:40,351:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:40,351:INFO:[LightGBM] [Info] Total Bins 510
2023-11-06 09:24:40,351:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 2
2023-11-06 09:24:40,351:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:40,351:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:40,751:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:40,767:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004386 seconds.
2023-11-06 09:24:40,767:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:40,767:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:40,767:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:24:40,768:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:24:40,769:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:40,769:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:41,306:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:41,323:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004019 seconds.
2023-11-06 09:24:41,323:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:41,323:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:41,323:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:24:41,323:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:24:41,324:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:41,324:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:41,877:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:41,901:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005969 seconds.
2023-11-06 09:24:41,901:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:41,901:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:41,902:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:24:41,902:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:24:41,903:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:41,903:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:42,543:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:42,558:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012103 seconds.
2023-11-06 09:24:42,558:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:42,559:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:24:42,559:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:24:42,559:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:42,560:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:43,276:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:43,291:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012810 seconds.
2023-11-06 09:24:43,291:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:43,292:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:24:43,292:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:24:43,293:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:43,294:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:43,986:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:44,002:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012942 seconds.
2023-11-06 09:24:44,002:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:44,002:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:24:44,003:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:24:44,003:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:44,003:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:44,589:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:44,596:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004860 seconds.
2023-11-06 09:24:44,596:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:44,597:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:24:44,597:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:24:44,598:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:44,598:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:45,126:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:45,132:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002531 seconds.
2023-11-06 09:24:45,133:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:45,133:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:45,133:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:24:45,133:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:24:45,133:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:45,134:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:45,658:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:45,662:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003428 seconds.
2023-11-06 09:24:45,662:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:45,662:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:24:45,662:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:24:45,663:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:45,663:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:46,086:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:46,089:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001011 seconds.
2023-11-06 09:24:46,089:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:46,089:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:46,090:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:24:46,090:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:24:46,090:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:46,090:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:46,588:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:46,592:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002775 seconds.
2023-11-06 09:24:46,592:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:46,592:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:24:46,593:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:24:46,593:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:46,594:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:47,006:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:47,009:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000774 seconds.
2023-11-06 09:24:47,009:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:47,010:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:47,010:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:24:47,010:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:24:47,010:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:47,011:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:47,445:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:47,447:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002063 seconds.
2023-11-06 09:24:47,447:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:47,447:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:24:47,447:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:24:47,448:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:47,448:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:47,850:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:47,853:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002523 seconds.
2023-11-06 09:24:47,853:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:47,853:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:24:47,853:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:24:47,854:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:47,854:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:48,240:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:48,242:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000628 seconds.
2023-11-06 09:24:48,242:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:48,242:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:48,242:INFO:[LightGBM] [Info] Total Bins 1530
2023-11-06 09:24:48,242:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:24:48,243:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:48,243:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:48,626:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:48,628:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000547 seconds.
2023-11-06 09:24:48,628:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:48,628:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:48,628:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:24:48,628:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:24:48,629:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:48,629:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:48,982:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:48,984:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000475 seconds.
2023-11-06 09:24:48,984:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:48,984:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:48,984:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:24:48,984:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:24:48,985:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:48,985:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:49,315:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:49,317:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.
2023-11-06 09:24:49,317:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:49,317:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:49,317:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:24:49,317:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 3
2023-11-06 09:24:49,317:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:49,317:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:49,624:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:49,625:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000259 seconds.
2023-11-06 09:24:49,625:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:49,625:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:49,625:INFO:[LightGBM] [Info] Total Bins 510
2023-11-06 09:24:49,625:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 2
2023-11-06 09:24:49,626:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:49,626:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:50,021:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:50,041:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003960 seconds.
2023-11-06 09:24:50,041:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:50,041:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:50,041:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:24:50,041:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:24:50,042:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:50,042:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:50,596:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:50,615:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004679 seconds.
2023-11-06 09:24:50,615:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:50,615:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:50,616:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:24:50,616:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:24:50,616:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:50,616:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:51,158:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:51,172:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003458 seconds.
2023-11-06 09:24:51,172:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:51,173:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:51,173:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:24:51,173:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:24:51,174:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:51,174:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:51,709:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:51,728:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003527 seconds.
2023-11-06 09:24:51,728:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:51,728:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:51,728:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:24:51,728:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:24:51,729:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:51,729:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:52,260:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:52,274:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011263 seconds.
2023-11-06 09:24:52,274:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:52,274:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:24:52,275:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:24:52,275:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:52,275:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:52,745:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:52,760:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003533 seconds.
2023-11-06 09:24:52,760:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:52,760:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:52,761:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:24:52,761:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:24:52,762:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:52,762:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:53,269:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:53,277:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003653 seconds.
2023-11-06 09:24:53,277:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:53,277:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:53,277:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:24:53,277:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:24:53,278:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:53,278:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:53,837:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:53,844:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003215 seconds.
2023-11-06 09:24:53,844:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:53,844:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:53,844:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:24:53,844:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:24:53,845:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:53,845:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:54,397:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:54,402:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004139 seconds.
2023-11-06 09:24:54,402:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:54,402:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:24:54,403:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:24:54,403:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:54,403:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:54,869:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:54,873:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003013 seconds.
2023-11-06 09:24:54,873:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:54,873:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:24:54,873:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:24:54,874:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:54,874:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:55,310:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:55,313:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000990 seconds.
2023-11-06 09:24:55,314:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:55,314:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:55,314:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:24:55,314:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:24:55,314:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:55,315:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:55,767:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:55,770:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000755 seconds.
2023-11-06 09:24:55,770:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:55,770:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:55,770:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:24:55,770:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:24:55,771:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:55,771:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:56,223:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:56,226:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002373 seconds.
2023-11-06 09:24:56,226:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:56,226:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:24:56,227:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:24:56,227:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:56,228:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:56,621:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:56,623:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001851 seconds.
2023-11-06 09:24:56,623:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:56,623:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:24:56,623:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:24:56,624:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:56,624:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:57,020:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:57,022:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001604 seconds.
2023-11-06 09:24:57,022:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:57,022:INFO:[LightGBM] [Info] Total Bins 1530
2023-11-06 09:24:57,022:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:24:57,022:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:57,023:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:57,376:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:57,377:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000482 seconds.
2023-11-06 09:24:57,378:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:57,378:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:57,378:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:24:57,378:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:24:57,378:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:57,378:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:57,754:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:57,756:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000796 seconds.
2023-11-06 09:24:57,756:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:57,757:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:57,757:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:24:57,757:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:24:57,757:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:57,757:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:58,086:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:58,087:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000368 seconds.
2023-11-06 09:24:58,087:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:58,087:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:58,087:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:24:58,087:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 3
2023-11-06 09:24:58,088:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:58,088:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:58,401:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:24:58,402:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000342 seconds.
2023-11-06 09:24:58,403:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:58,403:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:58,403:INFO:[LightGBM] [Info] Total Bins 510
2023-11-06 09:24:58,403:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 2
2023-11-06 09:24:58,404:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:24:58,404:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:24:58,802:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:24:58,823:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003972 seconds.
2023-11-06 09:24:58,823:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:58,823:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:58,823:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:24:58,823:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 20
2023-11-06 09:24:58,824:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:24:58,824:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:24:59,356:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:24:59,375:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015491 seconds.
2023-11-06 09:24:59,375:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:24:59,376:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:24:59,376:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 19
2023-11-06 09:24:59,376:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:24:59,377:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:24:59,887:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:24:59,903:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003995 seconds.
2023-11-06 09:24:59,903:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:24:59,903:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:24:59,904:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:24:59,904:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 18
2023-11-06 09:24:59,904:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:24:59,904:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:25:00,439:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:25:00,458:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003546 seconds.
2023-11-06 09:25:00,458:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:00,458:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:00,458:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:25:00,458:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 17
2023-11-06 09:25:00,459:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:25:00,459:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:25:01,000:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:25:01,014:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011678 seconds.
2023-11-06 09:25:01,014:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:01,014:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:25:01,015:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 16
2023-11-06 09:25:01,015:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:25:01,016:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:25:01,484:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:25:01,501:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002987 seconds.
2023-11-06 09:25:01,502:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:01,502:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:01,502:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:25:01,502:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 15
2023-11-06 09:25:01,503:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:25:01,503:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:25:01,996:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:25:02,004:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004818 seconds.
2023-11-06 09:25:02,004:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:02,004:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:25:02,004:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 14
2023-11-06 09:25:02,005:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:25:02,006:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:25:02,502:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:25:02,508:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003002 seconds.
2023-11-06 09:25:02,508:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:02,508:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:02,508:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:25:02,508:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 13
2023-11-06 09:25:02,509:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:25:02,509:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:25:03,030:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:25:03,034:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003742 seconds.
2023-11-06 09:25:03,034:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:03,034:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:25:03,035:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 12
2023-11-06 09:25:03,035:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:25:03,035:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:25:03,469:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:25:03,473:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001038 seconds.
2023-11-06 09:25:03,473:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:03,473:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:03,473:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:25:03,473:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 11
2023-11-06 09:25:03,474:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:25:03,474:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:25:03,977:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:25:03,983:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003040 seconds.
2023-11-06 09:25:03,983:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:03,983:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:03,983:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:25:03,983:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 10
2023-11-06 09:25:03,984:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:25:03,984:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:25:04,461:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:25:04,464:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002501 seconds.
2023-11-06 09:25:04,464:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:04,464:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:25:04,464:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 9
2023-11-06 09:25:04,465:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:25:04,465:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:25:04,861:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:25:04,864:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002383 seconds.
2023-11-06 09:25:04,864:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:04,864:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:25:04,864:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 8
2023-11-06 09:25:04,865:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:25:04,865:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:25:05,276:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:25:05,279:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000679 seconds.
2023-11-06 09:25:05,279:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:05,279:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:05,279:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:25:05,279:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 7
2023-11-06 09:25:05,280:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:25:05,280:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:25:05,684:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:25:05,686:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000514 seconds.
2023-11-06 09:25:05,686:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:05,686:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:05,686:INFO:[LightGBM] [Info] Total Bins 1376
2023-11-06 09:25:05,686:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 6
2023-11-06 09:25:05,687:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:25:05,687:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:25:06,076:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:25:06,078:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000527 seconds.
2023-11-06 09:25:06,078:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:06,078:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:06,078:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:25:06,078:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 5
2023-11-06 09:25:06,079:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:25:06,079:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:25:06,444:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:25:06,447:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000593 seconds.
2023-11-06 09:25:06,447:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:06,447:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:06,447:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:25:06,447:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 4
2023-11-06 09:25:06,448:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:25:06,448:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:25:06,774:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:25:06,776:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000742 seconds.
2023-11-06 09:25:06,776:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:06,776:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:06,776:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:25:06,776:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 3
2023-11-06 09:25:06,777:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:25:06,777:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:25:07,175:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:07,189:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003905 seconds.
2023-11-06 09:25:07,189:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:07,189:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:07,189:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:25:07,189:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 20
2023-11-06 09:25:07,190:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:07,190:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:07,731:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:07,746:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004129 seconds.
2023-11-06 09:25:07,746:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:07,746:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:07,746:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:25:07,747:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 19
2023-11-06 09:25:07,748:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:07,748:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:08,281:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:08,296:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003486 seconds.
2023-11-06 09:25:08,297:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:08,297:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:08,297:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:25:08,297:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 18
2023-11-06 09:25:08,298:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:08,298:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:08,823:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:08,836:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003567 seconds.
2023-11-06 09:25:08,836:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:08,837:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:08,837:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:25:08,837:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 17
2023-11-06 09:25:08,837:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:08,838:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:09,361:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:09,375:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011516 seconds.
2023-11-06 09:25:09,375:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:09,375:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:25:09,375:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 16
2023-11-06 09:25:09,376:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:09,376:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:09,845:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:09,856:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002912 seconds.
2023-11-06 09:25:09,857:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:09,857:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:09,857:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:25:09,857:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 15
2023-11-06 09:25:09,858:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:09,858:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:10,377:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:10,384:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004221 seconds.
2023-11-06 09:25:10,384:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:10,384:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:25:10,384:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 14
2023-11-06 09:25:10,385:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:10,385:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:10,863:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:10,869:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003084 seconds.
2023-11-06 09:25:10,869:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:10,869:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:10,869:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:25:10,870:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 13
2023-11-06 09:25:10,870:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:10,870:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:11,385:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:11,389:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003315 seconds.
2023-11-06 09:25:11,389:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:11,389:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:25:11,389:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 12
2023-11-06 09:25:11,390:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:11,390:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:11,814:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:11,819:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003058 seconds.
2023-11-06 09:25:11,819:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:11,819:INFO:[LightGBM] [Info] Total Bins 2205
2023-11-06 09:25:11,819:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 11
2023-11-06 09:25:11,820:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:11,821:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:12,235:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:12,239:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003384 seconds.
2023-11-06 09:25:12,239:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:12,240:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:25:12,240:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 10
2023-11-06 09:25:12,240:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:12,240:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:12,646:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:12,649:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002803 seconds.
2023-11-06 09:25:12,649:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:12,649:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:25:12,650:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 9
2023-11-06 09:25:12,650:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:12,651:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:13,028:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:13,031:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000770 seconds.
2023-11-06 09:25:13,031:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:13,031:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:13,031:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:25:13,031:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 8
2023-11-06 09:25:13,032:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:13,032:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:13,460:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:13,463:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002101 seconds.
2023-11-06 09:25:13,463:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:13,463:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:25:13,463:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 7
2023-11-06 09:25:13,463:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:13,464:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:13,834:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:13,837:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000572 seconds.
2023-11-06 09:25:13,837:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:13,837:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:13,837:INFO:[LightGBM] [Info] Total Bins 1376
2023-11-06 09:25:13,837:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 6
2023-11-06 09:25:13,838:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:13,838:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:14,240:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:14,242:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000555 seconds.
2023-11-06 09:25:14,243:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:14,243:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:14,243:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:25:14,243:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 5
2023-11-06 09:25:14,244:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:14,244:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:14,639:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:14,641:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000821 seconds.
2023-11-06 09:25:14,641:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:14,641:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:14,641:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:25:14,641:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 4
2023-11-06 09:25:14,642:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:14,642:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:15,011:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:15,013:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000927 seconds.
2023-11-06 09:25:15,013:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:15,013:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:25:15,013:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 3
2023-11-06 09:25:15,013:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:15,014:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:15,465:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:15,481:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004202 seconds.
2023-11-06 09:25:15,482:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:15,482:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:15,482:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:25:15,482:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 20
2023-11-06 09:25:15,482:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:15,483:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:16,013:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:16,028:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012427 seconds.
2023-11-06 09:25:16,028:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:16,029:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:25:16,029:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 19
2023-11-06 09:25:16,029:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:16,029:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:16,565:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:16,582:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004011 seconds.
2023-11-06 09:25:16,582:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:16,582:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:16,582:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:25:16,583:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 18
2023-11-06 09:25:16,584:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:16,584:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:17,140:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:17,156:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003576 seconds.
2023-11-06 09:25:17,156:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:17,156:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:17,156:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:25:17,156:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 17
2023-11-06 09:25:17,157:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:17,157:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:17,687:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:17,703:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003049 seconds.
2023-11-06 09:25:17,703:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:17,703:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:17,703:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:25:17,703:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 16
2023-11-06 09:25:17,704:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:17,704:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:18,235:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:18,250:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002685 seconds.
2023-11-06 09:25:18,250:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:18,250:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:18,250:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:25:18,250:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 15
2023-11-06 09:25:18,251:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:18,251:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:18,781:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:18,789:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004450 seconds.
2023-11-06 09:25:18,789:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:18,789:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:25:18,790:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 14
2023-11-06 09:25:18,790:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:18,791:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:19,299:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:19,305:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003129 seconds.
2023-11-06 09:25:19,306:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:19,306:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:19,306:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:25:19,306:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 13
2023-11-06 09:25:19,306:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:19,307:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:19,812:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:19,816:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000946 seconds.
2023-11-06 09:25:19,816:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:19,816:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:19,817:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:25:19,817:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 12
2023-11-06 09:25:19,817:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:19,817:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:20,318:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:20,321:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003017 seconds.
2023-11-06 09:25:20,321:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:20,322:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:25:20,322:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 11
2023-11-06 09:25:20,322:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:20,323:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:20,732:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:20,735:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002670 seconds.
2023-11-06 09:25:20,735:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:20,735:INFO:[LightGBM] [Info] Total Bins 2396
2023-11-06 09:25:20,735:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 10
2023-11-06 09:25:20,736:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:20,736:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:21,118:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:21,122:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001020 seconds.
2023-11-06 09:25:21,122:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:21,122:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:21,122:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:25:21,122:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 9
2023-11-06 09:25:21,123:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:21,123:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:21,564:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:21,567:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002115 seconds.
2023-11-06 09:25:21,567:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:21,567:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:25:21,567:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 8
2023-11-06 09:25:21,568:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:21,568:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:21,935:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:21,937:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001780 seconds.
2023-11-06 09:25:21,937:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:21,937:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:25:21,937:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 7
2023-11-06 09:25:21,938:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:21,938:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:22,291:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:22,296:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002816 seconds.
2023-11-06 09:25:22,296:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:22,296:INFO:[LightGBM] [Info] Total Bins 1376
2023-11-06 09:25:22,297:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 6
2023-11-06 09:25:22,297:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:22,297:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:22,652:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:22,654:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000447 seconds.
2023-11-06 09:25:22,654:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:22,654:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:22,654:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:25:22,654:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 5
2023-11-06 09:25:22,655:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:22,655:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:22,995:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:22,997:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000779 seconds.
2023-11-06 09:25:22,998:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:22,998:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:22,998:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:25:22,998:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 4
2023-11-06 09:25:22,998:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:22,998:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:23,327:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:25:23,328:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000748 seconds.
2023-11-06 09:25:23,329:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:23,329:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:23,329:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:25:23,329:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 3
2023-11-06 09:25:23,329:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:25:23,330:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:25:23,797:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:23,811:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004386 seconds.
2023-11-06 09:25:23,811:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:23,811:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:23,811:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:25:23,812:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:25:23,812:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:23,812:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:24,358:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:24,373:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003678 seconds.
2023-11-06 09:25:24,373:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:24,373:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:24,373:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:25:24,373:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:25:24,374:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:24,374:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:24,888:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:24,904:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003704 seconds.
2023-11-06 09:25:24,904:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:24,904:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:24,904:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:25:24,904:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:25:24,905:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:24,905:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:25,423:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:25,438:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003603 seconds.
2023-11-06 09:25:25,438:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:25,438:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:25,438:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:25:25,438:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:25:25,439:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:25,439:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:25,990:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:26,005:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011610 seconds.
2023-11-06 09:25:26,005:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:26,006:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:25:26,006:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:25:26,006:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:26,007:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:26,487:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:26,504:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014910 seconds.
2023-11-06 09:25:26,504:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:26,504:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:25:26,504:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:25:26,505:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:26,505:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:26,987:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:26,993:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002811 seconds.
2023-11-06 09:25:26,993:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:26,993:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:26,994:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:25:26,994:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:25:26,994:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:26,994:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:27,536:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:27,544:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003739 seconds.
2023-11-06 09:25:27,544:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:27,544:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:27,544:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:25:27,545:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:25:27,546:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:27,546:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:28,066:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:28,070:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003898 seconds.
2023-11-06 09:25:28,070:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:28,070:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:25:28,071:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:25:28,071:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:28,071:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:28,569:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:28,573:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003377 seconds.
2023-11-06 09:25:28,573:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:28,573:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:25:28,573:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:25:28,574:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:28,574:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:29,072:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:29,083:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009876 seconds.
2023-11-06 09:25:29,083:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:29,083:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:25:29,084:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:25:29,084:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:29,084:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:29,591:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:29,597:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002937 seconds.
2023-11-06 09:25:29,597:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:29,597:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:29,597:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:25:29,598:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:25:29,598:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:29,598:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:30,153:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:30,160:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004417 seconds.
2023-11-06 09:25:30,160:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:30,160:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:25:30,160:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:25:30,161:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:30,161:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:30,659:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:30,662:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002377 seconds.
2023-11-06 09:25:30,662:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:30,662:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:25:30,662:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:25:30,663:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:30,663:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:31,097:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:31,099:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001680 seconds.
2023-11-06 09:25:31,099:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:31,099:INFO:[LightGBM] [Info] Total Bins 1376
2023-11-06 09:25:31,100:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:25:31,100:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:31,100:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:31,440:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:31,442:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000604 seconds.
2023-11-06 09:25:31,442:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:31,442:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:31,442:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:25:31,442:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:25:31,442:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:31,442:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:31,791:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:31,793:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000463 seconds.
2023-11-06 09:25:31,793:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:31,793:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:31,793:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:25:31,793:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:25:31,793:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:31,794:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:32,149:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:32,150:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000407 seconds.
2023-11-06 09:25:32,150:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:32,150:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:32,151:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:25:32,151:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 3
2023-11-06 09:25:32,151:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:32,151:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:32,545:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:32,559:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004016 seconds.
2023-11-06 09:25:32,559:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:32,559:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:32,559:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:25:32,559:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:25:32,560:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:32,560:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:33,095:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:33,112:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004257 seconds.
2023-11-06 09:25:33,112:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:33,112:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:33,112:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:25:33,113:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:25:33,114:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:33,114:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:33,635:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:33,650:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003842 seconds.
2023-11-06 09:25:33,650:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:33,651:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:33,651:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:25:33,651:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:25:33,651:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:33,651:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:34,163:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:34,179:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003453 seconds.
2023-11-06 09:25:34,179:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:34,179:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:34,179:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:25:34,180:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:25:34,180:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:34,180:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:34,713:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:34,727:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011582 seconds.
2023-11-06 09:25:34,728:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:34,728:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:25:34,728:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:25:34,729:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:34,729:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:35,197:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:35,216:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003238 seconds.
2023-11-06 09:25:35,216:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:35,216:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:35,216:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:25:35,216:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:25:35,217:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:35,217:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:35,730:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:35,743:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009577 seconds.
2023-11-06 09:25:35,743:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:35,743:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:25:35,744:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:25:35,745:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:35,745:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:36,242:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:36,247:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003945 seconds.
2023-11-06 09:25:36,247:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:36,248:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:25:36,248:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:25:36,248:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:36,248:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:36,712:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:36,716:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003491 seconds.
2023-11-06 09:25:36,716:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:36,716:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:25:36,716:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:25:36,717:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:36,717:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:37,153:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:37,156:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002992 seconds.
2023-11-06 09:25:37,156:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:37,156:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:25:37,157:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:25:37,157:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:37,157:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:37,592:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:37,596:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002969 seconds.
2023-11-06 09:25:37,596:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:37,596:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:25:37,596:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:25:37,597:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:37,597:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:38,023:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:38,026:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000794 seconds.
2023-11-06 09:25:38,027:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:38,027:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:38,027:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:25:38,027:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:25:38,027:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:38,028:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:38,496:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:38,499:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002255 seconds.
2023-11-06 09:25:38,499:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:38,499:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:25:38,499:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:25:38,500:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:38,500:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:38,921:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:38,923:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000922 seconds.
2023-11-06 09:25:38,923:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:38,923:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:38,923:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:25:38,924:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:25:38,924:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:38,924:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:39,337:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:39,339:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000640 seconds.
2023-11-06 09:25:39,339:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:39,339:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:39,339:INFO:[LightGBM] [Info] Total Bins 1530
2023-11-06 09:25:39,339:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:25:39,340:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:39,340:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:39,729:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:39,731:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.
2023-11-06 09:25:39,731:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:39,731:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:39,732:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:25:39,732:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:25:39,732:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:39,732:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:40,090:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:40,093:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001017 seconds.
2023-11-06 09:25:40,093:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:40,093:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:40,093:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:25:40,093:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:25:40,094:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:40,094:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:40,443:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:40,445:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000559 seconds.
2023-11-06 09:25:40,445:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:40,445:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:40,445:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:25:40,445:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 3
2023-11-06 09:25:40,446:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:40,446:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:40,859:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:40,872:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004450 seconds.
2023-11-06 09:25:40,872:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:40,872:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:40,872:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:25:40,873:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:25:40,873:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:40,873:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:41,398:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:41,416:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003738 seconds.
2023-11-06 09:25:41,417:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:41,417:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:41,417:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:25:41,417:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:25:41,417:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:41,418:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:41,946:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:41,963:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004100 seconds.
2023-11-06 09:25:41,963:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:41,963:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:41,963:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:25:41,964:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:25:41,964:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:41,964:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:42,495:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:42,513:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003536 seconds.
2023-11-06 09:25:42,513:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:42,513:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:42,514:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:25:42,514:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:25:42,514:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:42,514:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:43,029:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:43,044:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002873 seconds.
2023-11-06 09:25:43,044:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:43,044:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:43,044:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:25:43,044:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:25:43,045:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:43,045:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:43,558:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:43,573:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003491 seconds.
2023-11-06 09:25:43,573:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:43,574:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:43,574:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:25:43,574:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:25:43,574:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:43,575:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:44,081:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:44,088:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004620 seconds.
2023-11-06 09:25:44,088:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:44,089:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:25:44,089:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:25:44,090:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:44,090:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:44,555:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:44,561:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003984 seconds.
2023-11-06 09:25:44,561:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:44,562:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:25:44,562:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:25:44,562:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:44,562:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:45,012:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:45,017:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003693 seconds.
2023-11-06 09:25:45,017:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:45,017:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:25:45,017:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:25:45,018:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:45,018:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:45,515:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:45,518:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000966 seconds.
2023-11-06 09:25:45,518:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:45,518:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:45,518:INFO:[LightGBM] [Info] Total Bins 2205
2023-11-06 09:25:45,519:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:25:45,519:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:45,519:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:45,984:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:45,987:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000902 seconds.
2023-11-06 09:25:45,987:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:45,987:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:45,987:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:25:45,988:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:25:45,988:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:45,988:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:46,442:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:46,445:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000969 seconds.
2023-11-06 09:25:46,445:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:46,445:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:46,446:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:25:46,446:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:25:46,447:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:46,447:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:46,877:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:46,880:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002352 seconds.
2023-11-06 09:25:46,880:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:46,880:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:25:46,881:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:25:46,881:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:46,881:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:47,278:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:47,281:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000920 seconds.
2023-11-06 09:25:47,281:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:47,281:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:47,281:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:25:47,281:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:25:47,282:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:47,282:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:47,697:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:47,699:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000500 seconds.
2023-11-06 09:25:47,699:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:47,699:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:47,699:INFO:[LightGBM] [Info] Total Bins 1376
2023-11-06 09:25:47,699:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:25:47,700:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:47,700:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:48,098:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:48,101:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000637 seconds.
2023-11-06 09:25:48,101:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:48,101:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:48,101:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:25:48,101:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:25:48,102:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:48,102:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:48,480:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:48,482:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000492 seconds.
2023-11-06 09:25:48,482:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:48,482:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:48,482:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:25:48,483:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:25:48,483:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:48,483:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:48,828:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:48,829:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.
2023-11-06 09:25:48,829:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:48,829:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:48,830:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:25:48,830:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 3
2023-11-06 09:25:48,830:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:48,830:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:49,259:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:49,276:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004719 seconds.
2023-11-06 09:25:49,276:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:49,276:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:49,276:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:25:49,277:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:25:49,277:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:49,277:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:49,813:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:49,829:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004341 seconds.
2023-11-06 09:25:49,830:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:49,830:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:49,830:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:25:49,830:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:25:49,830:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:49,831:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:50,376:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:50,392:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003465 seconds.
2023-11-06 09:25:50,392:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:50,392:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:50,392:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:25:50,392:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:25:50,393:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:50,393:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:50,925:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:50,939:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003492 seconds.
2023-11-06 09:25:50,939:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:50,939:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:50,939:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:25:50,940:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:25:50,941:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:50,941:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:51,456:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:51,471:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002909 seconds.
2023-11-06 09:25:51,471:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:51,471:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:51,471:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:25:51,471:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:25:51,472:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:51,472:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:51,959:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:51,976:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003520 seconds.
2023-11-06 09:25:51,976:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:51,976:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:51,976:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:25:51,976:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:25:51,977:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:51,977:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:52,473:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:52,481:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003385 seconds.
2023-11-06 09:25:52,481:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:52,481:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:52,481:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:25:52,482:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:25:52,482:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:52,482:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:53,027:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:53,034:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004023 seconds.
2023-11-06 09:25:53,034:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:53,034:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:25:53,034:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:25:53,035:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:53,035:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:53,516:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:53,520:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003476 seconds.
2023-11-06 09:25:53,521:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:53,521:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:25:53,521:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:25:53,521:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:53,522:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:53,941:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:53,944:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000868 seconds.
2023-11-06 09:25:53,944:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:53,944:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:53,944:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:25:53,945:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:25:53,945:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:53,945:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:54,430:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:54,434:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000965 seconds.
2023-11-06 09:25:54,434:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:54,434:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:54,434:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:25:54,434:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:25:54,435:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:54,435:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:54,882:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:54,886:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000779 seconds.
2023-11-06 09:25:54,886:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:54,886:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:54,886:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:25:54,886:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:25:54,886:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:54,886:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:55,320:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:55,323:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001080 seconds.
2023-11-06 09:25:55,324:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:55,324:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:55,324:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:25:55,324:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:25:55,324:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:55,324:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:55,741:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:55,744:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000969 seconds.
2023-11-06 09:25:55,744:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:55,744:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:55,744:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:25:55,744:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:25:55,745:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:55,745:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:56,135:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:56,137:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001827 seconds.
2023-11-06 09:25:56,137:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:56,137:INFO:[LightGBM] [Info] Total Bins 1530
2023-11-06 09:25:56,137:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:25:56,138:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:56,138:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:56,480:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:56,482:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000553 seconds.
2023-11-06 09:25:56,482:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:56,482:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:56,483:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:25:56,483:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:25:56,483:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:56,483:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:56,835:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:56,837:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000789 seconds.
2023-11-06 09:25:56,837:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:56,837:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:56,837:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:25:56,837:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:25:56,838:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:56,838:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:57,176:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:57,177:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2023-11-06 09:25:57,177:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:57,177:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:57,178:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:25:57,178:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 3
2023-11-06 09:25:57,178:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:57,178:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:57,619:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:57,640:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004687 seconds.
2023-11-06 09:25:57,640:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:57,640:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:57,640:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:25:57,640:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:25:57,641:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:57,641:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:58,254:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:58,268:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010618 seconds.
2023-11-06 09:25:58,268:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:58,268:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:25:58,269:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:25:58,270:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:58,270:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:58,815:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:58,830:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003455 seconds.
2023-11-06 09:25:58,831:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:58,831:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:58,831:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:25:58,831:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:25:58,832:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:58,832:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:59,394:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:59,413:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003632 seconds.
2023-11-06 09:25:59,413:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:25:59,413:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:25:59,413:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:25:59,413:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:25:59,414:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:59,414:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:25:59,943:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:25:59,957:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011501 seconds.
2023-11-06 09:25:59,958:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:25:59,958:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:25:59,958:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:25:59,959:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:25:59,959:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:00,463:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:00,475:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009034 seconds.
2023-11-06 09:26:00,475:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:00,475:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:26:00,475:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:26:00,476:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:00,476:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:00,960:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:00,967:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003538 seconds.
2023-11-06 09:26:00,967:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:00,968:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:00,968:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:26:00,968:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:26:00,968:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:00,968:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:01,487:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:01,494:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004108 seconds.
2023-11-06 09:26:01,494:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:01,494:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:26:01,494:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:26:01,495:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:01,495:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:01,948:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:01,952:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003575 seconds.
2023-11-06 09:26:01,952:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:01,952:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:26:01,953:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:26:01,953:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:01,953:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:02,370:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:02,373:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002966 seconds.
2023-11-06 09:26:02,373:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:02,374:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:26:02,374:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:26:02,375:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:02,375:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:02,789:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:02,793:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000812 seconds.
2023-11-06 09:26:02,793:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:02,793:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:02,793:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:26:02,793:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:26:02,794:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:02,794:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:03,231:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:03,234:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002306 seconds.
2023-11-06 09:26:03,234:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:03,234:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:26:03,234:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:26:03,235:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:03,235:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:03,617:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:03,620:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000855 seconds.
2023-11-06 09:26:03,620:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:03,620:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:03,620:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:26:03,620:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:26:03,625:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:03,625:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:04,036:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:04,038:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000703 seconds.
2023-11-06 09:26:04,038:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:04,038:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:04,038:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:26:04,038:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:26:04,039:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:04,039:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:04,424:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:04,426:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001564 seconds.
2023-11-06 09:26:04,426:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:04,426:INFO:[LightGBM] [Info] Total Bins 1530
2023-11-06 09:26:04,427:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:26:04,427:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:04,427:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:04,765:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:04,767:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000774 seconds.
2023-11-06 09:26:04,767:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:04,767:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:04,767:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:26:04,767:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:26:04,768:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:04,768:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:05,122:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:05,124:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000618 seconds.
2023-11-06 09:26:05,124:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:05,124:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:05,124:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:26:05,124:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:26:05,125:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:05,125:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:05,468:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:05,470:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.
2023-11-06 09:26:05,470:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:05,470:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:05,470:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:26:05,470:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 3
2023-11-06 09:26:05,471:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:05,471:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:05,879:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:05,893:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004432 seconds.
2023-11-06 09:26:05,893:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:05,893:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:05,893:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:26:05,894:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:26:05,894:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:05,894:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:06,420:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:06,434:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003348 seconds.
2023-11-06 09:26:06,434:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:06,434:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:06,434:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:26:06,434:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:26:06,435:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:06,435:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:06,954:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:06,969:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003522 seconds.
2023-11-06 09:26:06,969:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:06,969:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:06,970:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:26:06,970:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:26:06,970:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:06,970:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:07,513:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:07,528:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003856 seconds.
2023-11-06 09:26:07,529:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:07,529:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:07,529:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:26:07,529:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:26:07,529:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:07,530:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:08,085:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:08,100:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003534 seconds.
2023-11-06 09:26:08,100:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:08,100:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:08,100:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:26:08,100:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:26:08,101:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:08,101:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:08,633:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:08,648:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003476 seconds.
2023-11-06 09:26:08,648:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:08,648:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:08,648:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:26:08,648:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:26:08,649:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:08,649:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:09,171:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:09,177:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004399 seconds.
2023-11-06 09:26:09,177:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:09,178:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:26:09,178:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:26:09,178:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:09,178:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:09,679:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:09,685:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003922 seconds.
2023-11-06 09:26:09,685:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:09,686:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:26:09,686:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:26:09,686:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:09,686:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:10,135:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:10,140:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003770 seconds.
2023-11-06 09:26:10,140:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:10,140:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:26:10,140:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:26:10,141:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:10,141:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:10,634:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:10,637:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002945 seconds.
2023-11-06 09:26:10,638:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:10,638:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:26:10,638:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:26:10,638:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:10,639:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:11,050:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:11,054:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002867 seconds.
2023-11-06 09:26:11,054:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:11,054:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:26:11,054:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:26:11,054:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:11,055:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:11,474:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:11,477:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000791 seconds.
2023-11-06 09:26:11,477:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:11,477:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:11,477:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:26:11,478:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:26:11,478:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:11,478:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:11,912:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:11,915:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000871 seconds.
2023-11-06 09:26:11,915:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:11,915:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:11,915:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:26:11,915:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:26:11,916:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:11,916:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:12,342:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:12,344:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000673 seconds.
2023-11-06 09:26:12,344:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:12,344:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:12,344:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:26:12,344:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:26:12,345:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:12,345:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:12,734:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:12,736:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000601 seconds.
2023-11-06 09:26:12,736:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:12,736:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:12,736:INFO:[LightGBM] [Info] Total Bins 1530
2023-11-06 09:26:12,736:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:26:12,737:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:12,737:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:13,121:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:13,122:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000437 seconds.
2023-11-06 09:26:13,122:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:13,123:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:13,123:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:26:13,123:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:26:13,123:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:13,123:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:13,474:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:13,476:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000806 seconds.
2023-11-06 09:26:13,476:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:13,476:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:13,476:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:26:13,477:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:26:13,477:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:13,477:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:13,807:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:13,808:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000358 seconds.
2023-11-06 09:26:13,809:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:13,809:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:13,809:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:26:13,809:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 3
2023-11-06 09:26:13,809:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:13,809:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:14,225:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:14,238:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003690 seconds.
2023-11-06 09:26:14,238:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:14,238:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:14,238:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:26:14,238:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:26:14,239:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:14,239:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:14,848:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:14,862:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003605 seconds.
2023-11-06 09:26:14,862:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:14,862:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:14,862:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:26:14,862:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:26:14,863:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:14,863:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:15,446:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:15,462:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003937 seconds.
2023-11-06 09:26:15,462:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:15,462:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:15,462:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:26:15,462:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:26:15,463:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:15,463:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:15,992:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:16,011:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003463 seconds.
2023-11-06 09:26:16,011:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:16,011:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:16,012:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:26:16,012:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:26:16,012:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:16,013:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:16,534:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:16,549:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011485 seconds.
2023-11-06 09:26:16,549:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:16,549:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:26:16,549:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:26:16,550:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:16,550:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:17,006:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:17,023:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014391 seconds.
2023-11-06 09:26:17,023:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:17,024:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:26:17,024:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:26:17,024:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:17,024:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:17,492:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:17,499:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004262 seconds.
2023-11-06 09:26:17,499:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:17,499:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:26:17,499:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:26:17,500:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:17,500:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:17,993:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:17,999:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003870 seconds.
2023-11-06 09:26:18,000:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:18,000:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:26:18,000:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:26:18,000:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:18,001:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:18,479:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:18,484:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003688 seconds.
2023-11-06 09:26:18,484:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:18,484:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:26:18,484:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:26:18,485:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:18,485:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:18,904:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:18,908:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000968 seconds.
2023-11-06 09:26:18,908:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:18,908:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:18,908:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:26:18,908:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:26:18,908:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:18,909:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:19,394:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:19,397:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001001 seconds.
2023-11-06 09:26:19,397:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:19,397:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:19,397:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:26:19,397:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:26:19,398:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:19,398:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:19,845:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:19,848:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001026 seconds.
2023-11-06 09:26:19,848:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:19,848:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:19,848:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:26:19,848:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:26:19,849:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:19,849:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:20,301:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:20,304:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002472 seconds.
2023-11-06 09:26:20,304:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:20,304:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:26:20,304:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:26:20,305:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:20,305:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:20,707:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:20,710:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000782 seconds.
2023-11-06 09:26:20,710:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:20,710:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:20,710:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:26:20,710:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:26:20,711:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:20,711:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:21,107:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:21,109:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000603 seconds.
2023-11-06 09:26:21,109:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:21,109:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:21,109:INFO:[LightGBM] [Info] Total Bins 1530
2023-11-06 09:26:21,110:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:26:21,110:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:21,110:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:21,486:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:21,488:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000468 seconds.
2023-11-06 09:26:21,488:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:21,488:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:21,488:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:26:21,489:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:26:21,489:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:21,489:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:21,847:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:21,849:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000628 seconds.
2023-11-06 09:26:21,849:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:21,849:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:21,849:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:26:21,849:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:26:21,850:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:21,850:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:22,178:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:22,179:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000354 seconds.
2023-11-06 09:26:22,179:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:22,179:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:22,179:INFO:[LightGBM] [Info] Total Bins 765
2023-11-06 09:26:22,179:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 3
2023-11-06 09:26:22,180:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:22,180:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:22,585:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:26:22,603:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014289 seconds.
2023-11-06 09:26:22,603:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:22,603:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:26:22,603:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 20
2023-11-06 09:26:22,604:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:26:22,605:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:26:23,160:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:26:23,176:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003886 seconds.
2023-11-06 09:26:23,176:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:23,176:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:23,176:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:26:23,177:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 19
2023-11-06 09:26:23,177:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:26:23,177:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:26:23,693:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:26:23,709:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003562 seconds.
2023-11-06 09:26:23,709:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:23,709:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:23,710:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:26:23,710:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 18
2023-11-06 09:26:23,710:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:26:23,711:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:26:24,235:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:26:24,254:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003292 seconds.
2023-11-06 09:26:24,254:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:24,254:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:24,254:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:26:24,254:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 17
2023-11-06 09:26:24,255:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:26:24,255:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:26:24,772:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:26:24,790:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015112 seconds.
2023-11-06 09:26:24,790:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:24,790:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:26:24,790:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 16
2023-11-06 09:26:24,791:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:26:24,792:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:26:25,256:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:26:25,271:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003489 seconds.
2023-11-06 09:26:25,271:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:25,271:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:25,272:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:26:25,272:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 15
2023-11-06 09:26:25,272:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:26:25,272:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:26:25,760:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:26:25,767:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004173 seconds.
2023-11-06 09:26:25,767:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:25,767:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:26:25,767:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 14
2023-11-06 09:26:25,768:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:26:25,768:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:26:26,251:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:26:26,257:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003680 seconds.
2023-11-06 09:26:26,257:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:26,257:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:26:26,257:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 13
2023-11-06 09:26:26,258:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:26:26,258:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:26:26,738:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:26:26,743:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003591 seconds.
2023-11-06 09:26:26,743:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:26,743:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:26:26,743:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 12
2023-11-06 09:26:26,744:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:26:26,744:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:26:27,163:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:26:27,167:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000874 seconds.
2023-11-06 09:26:27,167:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:27,167:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:27,167:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:26:27,167:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 11
2023-11-06 09:26:27,168:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:26:27,168:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:26:27,642:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:26:27,645:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000916 seconds.
2023-11-06 09:26:27,645:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:27,645:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:27,646:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:26:27,646:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 10
2023-11-06 09:26:27,646:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:26:27,647:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:26:28,097:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:26:28,100:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002550 seconds.
2023-11-06 09:26:28,100:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:28,100:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:26:28,100:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 9
2023-11-06 09:26:28,101:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:26:28,101:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:26:28,485:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:26:28,488:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000744 seconds.
2023-11-06 09:26:28,488:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:28,488:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:28,488:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:26:28,488:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 8
2023-11-06 09:26:28,489:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:26:28,489:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:26:28,900:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:26:28,903:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000656 seconds.
2023-11-06 09:26:28,903:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:28,903:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:28,903:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:26:28,903:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 7
2023-11-06 09:26:28,904:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:26:28,904:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:26:29,302:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:26:29,305:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000670 seconds.
2023-11-06 09:26:29,305:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:29,305:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:29,305:INFO:[LightGBM] [Info] Total Bins 1376
2023-11-06 09:26:29,305:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 6
2023-11-06 09:26:29,306:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:26:29,306:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:26:29,673:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:26:29,674:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000463 seconds.
2023-11-06 09:26:29,675:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:29,675:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:29,675:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:26:29,675:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 5
2023-11-06 09:26:29,675:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:26:29,675:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:26:30,037:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87966
2023-11-06 09:26:30,038:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000452 seconds.
2023-11-06 09:26:30,039:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:30,039:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:30,039:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:26:30,039:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 4
2023-11-06 09:26:30,039:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230771 -> initscore=-1.203965
2023-11-06 09:26:30,040:INFO:[LightGBM] [Info] Start training from score -1.203965
2023-11-06 09:26:30,465:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:30,481:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003811 seconds.
2023-11-06 09:26:30,481:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:30,481:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:30,481:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:26:30,482:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 20
2023-11-06 09:26:30,482:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:30,482:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:31,014:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:31,030:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013004 seconds.
2023-11-06 09:26:31,030:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:31,030:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:26:31,031:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 19
2023-11-06 09:26:31,031:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:31,031:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:31,562:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:31,574:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003114 seconds.
2023-11-06 09:26:31,574:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:31,574:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:31,574:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:26:31,574:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 18
2023-11-06 09:26:31,575:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:31,575:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:32,115:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:32,128:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003563 seconds.
2023-11-06 09:26:32,128:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:32,128:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:32,128:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:26:32,128:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 17
2023-11-06 09:26:32,129:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:32,129:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:32,673:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:32,685:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008696 seconds.
2023-11-06 09:26:32,685:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:32,685:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:26:32,685:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 16
2023-11-06 09:26:32,686:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:32,686:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:33,185:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:33,199:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003524 seconds.
2023-11-06 09:26:33,200:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:33,200:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:33,200:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:26:33,200:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 15
2023-11-06 09:26:33,201:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:33,201:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:33,743:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:33,750:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004724 seconds.
2023-11-06 09:26:33,750:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:33,750:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:26:33,750:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 14
2023-11-06 09:26:33,751:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:33,751:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:34,226:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:34,232:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004037 seconds.
2023-11-06 09:26:34,232:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:34,232:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:26:34,232:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 13
2023-11-06 09:26:34,233:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:34,233:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:34,721:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:34,725:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003601 seconds.
2023-11-06 09:26:34,726:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:34,726:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:26:34,726:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 12
2023-11-06 09:26:34,726:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:34,726:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:35,152:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:35,156:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003524 seconds.
2023-11-06 09:26:35,156:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:35,156:INFO:[LightGBM] [Info] Total Bins 2205
2023-11-06 09:26:35,157:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 11
2023-11-06 09:26:35,157:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:35,157:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:35,579:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:35,582:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000857 seconds.
2023-11-06 09:26:35,583:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:35,583:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:35,583:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:26:35,583:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 10
2023-11-06 09:26:35,583:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:35,584:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:36,040:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:36,043:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002336 seconds.
2023-11-06 09:26:36,043:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:36,043:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:26:36,043:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 9
2023-11-06 09:26:36,044:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:36,044:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:36,424:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:36,426:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002268 seconds.
2023-11-06 09:26:36,427:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:36,427:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:26:36,427:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 8
2023-11-06 09:26:36,427:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:36,428:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:36,805:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:36,808:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001971 seconds.
2023-11-06 09:26:36,808:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:36,808:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:26:36,808:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 7
2023-11-06 09:26:36,808:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:36,809:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:37,163:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:37,165:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000593 seconds.
2023-11-06 09:26:37,165:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:37,165:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:37,165:INFO:[LightGBM] [Info] Total Bins 1376
2023-11-06 09:26:37,165:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 6
2023-11-06 09:26:37,166:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:37,166:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:37,534:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:37,536:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001681 seconds.
2023-11-06 09:26:37,536:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:37,536:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:26:37,537:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 5
2023-11-06 09:26:37,537:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:37,537:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:37,869:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:37,871:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000803 seconds.
2023-11-06 09:26:37,871:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:37,871:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:37,872:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:26:37,872:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 4
2023-11-06 09:26:37,872:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:37,872:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:38,315:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:38,334:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004212 seconds.
2023-11-06 09:26:38,334:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:38,334:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:38,334:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:26:38,335:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 20
2023-11-06 09:26:38,335:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:38,335:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:38,867:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:38,886:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003989 seconds.
2023-11-06 09:26:38,886:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:38,886:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:38,886:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:26:38,887:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 19
2023-11-06 09:26:38,887:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:38,887:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:39,406:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:39,425:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003400 seconds.
2023-11-06 09:26:39,425:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:39,425:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:39,425:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:26:39,425:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 18
2023-11-06 09:26:39,426:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:39,426:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:39,954:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:39,970:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003524 seconds.
2023-11-06 09:26:39,971:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:39,971:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:39,971:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:26:39,971:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 17
2023-11-06 09:26:39,972:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:39,972:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:40,502:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:40,517:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003094 seconds.
2023-11-06 09:26:40,517:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:40,517:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:40,517:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:26:40,517:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 16
2023-11-06 09:26:40,518:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:40,518:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:41,031:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:41,048:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003009 seconds.
2023-11-06 09:26:41,048:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:41,048:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:41,048:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:26:41,049:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 15
2023-11-06 09:26:41,049:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:41,049:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:41,571:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:41,578:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004331 seconds.
2023-11-06 09:26:41,579:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:41,579:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:26:41,579:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 14
2023-11-06 09:26:41,580:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:41,580:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:42,071:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:42,078:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004179 seconds.
2023-11-06 09:26:42,078:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:42,079:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:26:42,079:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 13
2023-11-06 09:26:42,079:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:42,079:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:42,564:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:42,568:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003530 seconds.
2023-11-06 09:26:42,568:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:42,569:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:26:42,569:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 12
2023-11-06 09:26:42,569:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:42,569:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:43,023:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:43,027:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000917 seconds.
2023-11-06 09:26:43,027:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:43,027:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:43,027:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:26:43,027:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 11
2023-11-06 09:26:43,027:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:43,028:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:43,555:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:43,558:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002727 seconds.
2023-11-06 09:26:43,558:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:43,558:INFO:[LightGBM] [Info] Total Bins 2396
2023-11-06 09:26:43,558:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 10
2023-11-06 09:26:43,559:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:43,559:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:43,963:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:43,966:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000980 seconds.
2023-11-06 09:26:43,966:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:43,966:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:43,967:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:26:43,967:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 9
2023-11-06 09:26:43,967:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:43,967:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:44,441:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:44,444:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002252 seconds.
2023-11-06 09:26:44,444:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:44,444:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:26:44,444:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 8
2023-11-06 09:26:44,445:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:44,445:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:44,817:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:44,820:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001853 seconds.
2023-11-06 09:26:44,820:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:44,820:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:26:44,820:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 7
2023-11-06 09:26:44,820:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:44,820:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:45,172:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:45,174:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000648 seconds.
2023-11-06 09:26:45,174:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:45,174:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:45,174:INFO:[LightGBM] [Info] Total Bins 1376
2023-11-06 09:26:45,174:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 6
2023-11-06 09:26:45,175:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:45,175:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:45,563:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:45,565:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000465 seconds.
2023-11-06 09:26:45,565:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:45,565:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:45,565:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:26:45,565:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 5
2023-11-06 09:26:45,566:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:45,566:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:45,920:INFO:[LightGBM] [Info] Number of positive: 26389, number of negative: 87967
2023-11-06 09:26:45,923:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001105 seconds.
2023-11-06 09:26:45,923:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:45,923:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:45,923:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:26:45,923:INFO:[LightGBM] [Info] Number of data points in the train set: 114356, number of used features: 4
2023-11-06 09:26:45,924:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230762 -> initscore=-1.204014
2023-11-06 09:26:45,924:INFO:[LightGBM] [Info] Start training from score -1.204014
2023-11-06 09:26:46,350:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:46,364:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004692 seconds.
2023-11-06 09:26:46,364:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:46,364:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:46,365:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:26:46,365:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:26:46,365:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:46,365:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:46,915:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:46,935:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003818 seconds.
2023-11-06 09:26:46,935:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:46,935:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:46,935:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:26:46,936:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:26:46,936:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:46,937:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:47,473:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:47,489:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003621 seconds.
2023-11-06 09:26:47,489:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:47,489:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:47,490:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:26:47,490:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:26:47,490:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:47,491:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:48,020:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:48,033:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003576 seconds.
2023-11-06 09:26:48,033:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:48,033:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:48,034:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:26:48,034:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:26:48,034:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:48,034:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:48,548:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:48,563:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011479 seconds.
2023-11-06 09:26:48,563:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:48,563:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:26:48,563:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:26:48,564:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:48,564:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:49,035:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:49,046:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002810 seconds.
2023-11-06 09:26:49,046:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:49,046:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:49,046:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:26:49,047:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:26:49,047:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:49,047:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:49,547:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:49,554:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004392 seconds.
2023-11-06 09:26:49,554:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:49,554:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:26:49,555:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:26:49,555:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:49,555:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:50,043:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:50,050:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003776 seconds.
2023-11-06 09:26:50,050:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:50,050:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:26:50,050:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:26:50,050:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:50,051:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:50,519:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:50,524:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003659 seconds.
2023-11-06 09:26:50,524:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:50,524:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:26:50,524:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:26:50,525:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:50,525:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:50,943:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:50,946:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003094 seconds.
2023-11-06 09:26:50,946:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:50,947:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:26:50,947:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:26:50,947:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:50,948:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:51,363:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:51,366:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001014 seconds.
2023-11-06 09:26:51,366:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:51,366:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:51,366:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:26:51,367:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:26:51,367:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:51,367:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:51,822:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:51,825:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000792 seconds.
2023-11-06 09:26:51,825:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:51,825:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:51,825:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:26:51,825:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:26:51,825:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:51,826:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:52,275:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:52,277:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002113 seconds.
2023-11-06 09:26:52,278:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:52,278:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:26:52,278:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:26:52,278:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:52,279:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:52,697:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:52,699:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000738 seconds.
2023-11-06 09:26:52,699:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:52,700:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:52,700:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:26:52,700:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:26:52,700:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:52,700:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:53,116:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:53,126:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000602 seconds.
2023-11-06 09:26:53,126:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:53,126:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:53,127:INFO:[LightGBM] [Info] Total Bins 1376
2023-11-06 09:26:53,127:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:26:53,127:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:53,127:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:53,523:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:53,525:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000857 seconds.
2023-11-06 09:26:53,525:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:53,526:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:53,526:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:26:53,526:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:26:53,526:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:53,527:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:53,879:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:53,880:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000398 seconds.
2023-11-06 09:26:53,880:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:53,881:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:53,881:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:26:53,881:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:26:53,881:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:53,881:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:54,310:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:54,323:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004439 seconds.
2023-11-06 09:26:54,323:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:54,323:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:54,323:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:26:54,323:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:26:54,324:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:54,324:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:54,861:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:54,877:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004233 seconds.
2023-11-06 09:26:54,877:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:54,877:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:54,877:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:26:54,877:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:26:54,878:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:54,878:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:55,406:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:55,421:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012209 seconds.
2023-11-06 09:26:55,421:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:55,421:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:26:55,422:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:26:55,423:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:55,423:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:55,933:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:55,948:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003260 seconds.
2023-11-06 09:26:55,948:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:55,948:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:55,948:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:26:55,949:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:26:55,949:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:55,949:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:56,478:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:56,493:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011403 seconds.
2023-11-06 09:26:56,493:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:56,493:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:26:56,493:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:26:56,494:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:56,494:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:56,978:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:56,994:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003022 seconds.
2023-11-06 09:26:56,994:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:56,995:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:56,995:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:26:56,995:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:26:56,995:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:56,995:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:57,513:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:57,521:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004894 seconds.
2023-11-06 09:26:57,521:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:57,522:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:26:57,522:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:26:57,523:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:57,523:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:58,024:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:58,031:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003009 seconds.
2023-11-06 09:26:58,031:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:58,031:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:58,031:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:26:58,031:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:26:58,032:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:58,032:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:58,539:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:58,543:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003405 seconds.
2023-11-06 09:26:58,543:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:58,543:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:26:58,544:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:26:58,544:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:58,544:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:58,969:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:58,973:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000954 seconds.
2023-11-06 09:26:58,973:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:58,973:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:58,973:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:26:58,973:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:26:58,974:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:58,974:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:59,457:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:59,460:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001377 seconds.
2023-11-06 09:26:59,460:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:26:59,461:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:26:59,461:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:26:59,461:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:26:59,461:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:59,461:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:26:59,928:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:26:59,931:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003274 seconds.
2023-11-06 09:26:59,932:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:26:59,932:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:26:59,932:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:26:59,932:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:26:59,933:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:00,333:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:00,336:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001092 seconds.
2023-11-06 09:27:00,336:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:00,336:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:00,336:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:27:00,336:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:27:00,337:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:00,337:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:00,747:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:00,749:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000772 seconds.
2023-11-06 09:27:00,749:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:00,749:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:00,750:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:27:00,750:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:27:00,750:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:00,750:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:01,164:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:01,166:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001611 seconds.
2023-11-06 09:27:01,166:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:01,166:INFO:[LightGBM] [Info] Total Bins 1530
2023-11-06 09:27:01,166:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:27:01,167:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:01,167:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:01,516:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:01,518:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001460 seconds.
2023-11-06 09:27:01,518:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:01,518:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:27:01,518:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:27:01,519:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:01,519:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:01,873:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:01,875:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000613 seconds.
2023-11-06 09:27:01,875:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:01,875:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:01,875:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:27:01,875:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:27:01,875:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:01,876:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:02,322:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:02,342:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004058 seconds.
2023-11-06 09:27:02,342:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:02,342:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:02,342:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:27:02,342:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:27:02,343:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:02,343:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:02,912:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:02,928:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003775 seconds.
2023-11-06 09:27:02,928:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:02,929:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:02,929:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:27:02,929:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:27:02,929:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:02,930:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:03,514:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:03,532:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003347 seconds.
2023-11-06 09:27:03,532:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:03,532:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:03,532:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:27:03,532:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:27:03,533:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:03,533:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:04,088:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:04,102:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003025 seconds.
2023-11-06 09:27:04,102:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:04,102:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:04,102:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:27:04,102:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:27:04,103:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:04,103:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:04,632:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:04,650:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003501 seconds.
2023-11-06 09:27:04,650:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:04,650:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:04,650:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:27:04,650:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:27:04,651:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:04,651:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:05,168:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:05,182:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003025 seconds.
2023-11-06 09:27:05,182:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:05,182:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:05,182:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:27:05,183:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:27:05,183:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:05,183:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:05,695:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:05,703:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004386 seconds.
2023-11-06 09:27:05,703:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:05,703:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:27:05,703:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:27:05,704:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:05,704:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:06,220:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:06,227:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004054 seconds.
2023-11-06 09:27:06,227:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:06,227:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:27:06,227:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:27:06,228:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:06,228:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:06,724:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:06,728:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003620 seconds.
2023-11-06 09:27:06,728:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:06,728:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:27:06,728:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:27:06,729:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:06,729:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:07,155:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:07,159:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001114 seconds.
2023-11-06 09:27:07,159:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:07,159:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:07,159:INFO:[LightGBM] [Info] Total Bins 2205
2023-11-06 09:27:07,159:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:27:07,160:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:07,160:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:07,632:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:07,635:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002728 seconds.
2023-11-06 09:27:07,635:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:07,635:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:27:07,635:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:27:07,636:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:07,636:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:08,042:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:08,045:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001013 seconds.
2023-11-06 09:27:08,046:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:08,046:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:08,046:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:27:08,046:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:27:08,046:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:08,047:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:08,487:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:08,490:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002155 seconds.
2023-11-06 09:27:08,490:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:08,490:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:27:08,490:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:27:08,491:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:08,491:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:08,886:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:08,889:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001125 seconds.
2023-11-06 09:27:08,889:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:08,889:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:08,889:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:27:08,889:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:27:08,889:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:08,889:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:09,307:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:09,309:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000651 seconds.
2023-11-06 09:27:09,309:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:09,309:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:09,309:INFO:[LightGBM] [Info] Total Bins 1376
2023-11-06 09:27:09,309:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:27:09,310:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:09,310:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:09,680:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:09,682:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000793 seconds.
2023-11-06 09:27:09,683:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:09,683:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:09,683:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:27:09,683:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:27:09,683:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:09,683:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:10,042:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:10,043:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001158 seconds.
2023-11-06 09:27:10,044:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:10,044:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:27:10,044:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:27:10,044:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:10,044:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:10,458:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:10,474:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004581 seconds.
2023-11-06 09:27:10,474:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:10,474:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:10,475:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:27:10,475:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:27:10,475:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:10,475:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:11,016:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:11,032:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003680 seconds.
2023-11-06 09:27:11,032:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:11,032:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:11,032:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:27:11,032:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:27:11,033:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:11,033:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:11,553:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:11,568:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003430 seconds.
2023-11-06 09:27:11,568:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:11,568:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:11,568:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:27:11,568:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:27:11,569:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:11,569:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:12,094:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:12,112:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003248 seconds.
2023-11-06 09:27:12,113:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:12,113:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:12,113:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:27:12,113:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:27:12,114:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:12,114:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:12,635:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:12,650:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011625 seconds.
2023-11-06 09:27:12,650:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:12,651:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:27:12,651:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:27:12,651:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:12,651:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:13,134:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:13,147:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009506 seconds.
2023-11-06 09:27:13,147:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:13,147:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:27:13,148:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:27:13,148:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:13,149:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:13,638:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:13,645:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002831 seconds.
2023-11-06 09:27:13,646:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:13,646:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:13,646:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:27:13,646:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:27:13,646:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:13,647:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:14,179:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:14,185:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002480 seconds.
2023-11-06 09:27:14,185:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:14,185:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:14,185:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:27:14,186:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:27:14,186:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:14,186:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:14,731:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:14,735:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003734 seconds.
2023-11-06 09:27:14,735:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:14,735:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:27:14,735:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:27:14,736:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:14,736:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:15,191:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:15,195:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000979 seconds.
2023-11-06 09:27:15,196:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:15,196:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:15,196:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:27:15,196:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:27:15,196:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:15,197:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:15,706:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:15,710:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002775 seconds.
2023-11-06 09:27:15,710:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:15,710:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:27:15,710:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:27:15,711:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:15,711:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:16,128:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:16,131:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001015 seconds.
2023-11-06 09:27:16,131:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:16,132:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:16,132:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:27:16,132:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:27:16,132:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:16,132:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:16,572:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:16,575:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001076 seconds.
2023-11-06 09:27:16,575:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:16,575:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:16,575:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:27:16,575:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:27:16,576:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:16,576:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:16,996:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:16,998:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000775 seconds.
2023-11-06 09:27:16,999:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:16,999:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:16,999:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:27:16,999:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:27:16,999:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:16,999:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:17,386:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:17,388:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001636 seconds.
2023-11-06 09:27:17,388:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:17,388:INFO:[LightGBM] [Info] Total Bins 1530
2023-11-06 09:27:17,388:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:27:17,389:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:17,389:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:17,736:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:17,738:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000812 seconds.
2023-11-06 09:27:17,739:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:17,739:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:17,739:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:27:17,739:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:27:17,739:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:17,739:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:18,100:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:18,103:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000604 seconds.
2023-11-06 09:27:18,103:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:18,103:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:18,103:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:27:18,103:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:27:18,103:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:18,103:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:18,527:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:18,543:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003946 seconds.
2023-11-06 09:27:18,543:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:18,543:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:18,543:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:27:18,543:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:27:18,544:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:18,544:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:19,084:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:19,103:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004103 seconds.
2023-11-06 09:27:19,103:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:19,103:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:19,103:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:27:19,104:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:27:19,104:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:19,104:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:19,615:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:19,631:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003769 seconds.
2023-11-06 09:27:19,631:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:19,631:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:19,631:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:27:19,632:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:27:19,632:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:19,632:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:20,152:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:20,168:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003117 seconds.
2023-11-06 09:27:20,168:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:20,168:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:20,168:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:27:20,168:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:27:20,169:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:20,170:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:20,677:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:20,691:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011218 seconds.
2023-11-06 09:27:20,691:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:20,691:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:27:20,692:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:27:20,692:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:20,692:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:21,168:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:21,182:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011115 seconds.
2023-11-06 09:27:21,182:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:21,183:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:27:21,183:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:27:21,183:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:21,183:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:21,664:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:21,671:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004291 seconds.
2023-11-06 09:27:21,671:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:21,671:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:27:21,671:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:27:21,672:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:21,672:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:22,184:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:22,191:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003513 seconds.
2023-11-06 09:27:22,191:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:22,191:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:22,191:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:27:22,191:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:27:22,192:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:22,192:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:22,720:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:22,724:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003573 seconds.
2023-11-06 09:27:22,724:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:22,724:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:27:22,724:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:27:22,725:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:22,725:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:23,153:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:23,157:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001180 seconds.
2023-11-06 09:27:23,157:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:23,157:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:23,157:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:27:23,157:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:27:23,157:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:23,158:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:23,631:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:23,635:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000944 seconds.
2023-11-06 09:27:23,635:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:23,635:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:23,635:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:27:23,635:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:27:23,636:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:23,636:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:24,081:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:24,084:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002570 seconds.
2023-11-06 09:27:24,084:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:24,085:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:27:24,085:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:27:24,085:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:24,085:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:24,481:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:24,484:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000659 seconds.
2023-11-06 09:27:24,484:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:24,484:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:24,484:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:27:24,484:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:27:24,485:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:24,485:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:24,892:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:24,895:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000765 seconds.
2023-11-06 09:27:24,895:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:24,895:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:24,895:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:27:24,895:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:27:24,895:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:24,896:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:25,283:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:25,286:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001872 seconds.
2023-11-06 09:27:25,286:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:25,286:INFO:[LightGBM] [Info] Total Bins 1530
2023-11-06 09:27:25,286:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:27:25,287:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:25,287:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:25,641:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:25,644:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000888 seconds.
2023-11-06 09:27:25,644:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:25,644:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:25,644:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:27:25,644:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:27:25,645:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:25,645:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:26,016:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:26,018:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000588 seconds.
2023-11-06 09:27:26,018:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:26,018:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:26,018:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:27:26,018:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:27:26,019:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:26,019:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:26,470:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:26,487:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004391 seconds.
2023-11-06 09:27:26,487:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:26,487:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:26,487:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:27:26,487:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:27:26,488:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:26,488:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:27,051:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:27,066:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003443 seconds.
2023-11-06 09:27:27,066:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:27,066:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:27,066:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:27:27,066:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:27:27,067:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:27,067:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:27,639:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:27,653:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003397 seconds.
2023-11-06 09:27:27,654:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:27,654:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:27,654:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:27:27,654:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:27:27,654:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:27,655:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:28,199:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:28,214:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003594 seconds.
2023-11-06 09:27:28,214:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:28,214:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:28,214:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:27:28,214:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:27:28,215:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:28,215:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:28,769:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:28,789:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003653 seconds.
2023-11-06 09:27:28,789:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:28,789:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:28,789:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:27:28,789:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:27:28,790:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:28,790:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:29,312:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:29,329:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014347 seconds.
2023-11-06 09:27:29,329:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:29,329:INFO:[LightGBM] [Info] Total Bins 2466
2023-11-06 09:27:29,329:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 15
2023-11-06 09:27:29,330:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:29,330:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:29,814:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:29,821:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004351 seconds.
2023-11-06 09:27:29,821:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:29,821:INFO:[LightGBM] [Info] Total Bins 2464
2023-11-06 09:27:29,822:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 14
2023-11-06 09:27:29,822:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:29,822:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:30,331:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:30,337:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004237 seconds.
2023-11-06 09:27:30,337:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:30,338:INFO:[LightGBM] [Info] Total Bins 2462
2023-11-06 09:27:30,338:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 13
2023-11-06 09:27:30,338:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:30,339:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:30,876:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:30,881:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003938 seconds.
2023-11-06 09:27:30,881:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:30,881:INFO:[LightGBM] [Info] Total Bins 2460
2023-11-06 09:27:30,882:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 12
2023-11-06 09:27:30,882:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:30,883:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:31,311:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:31,315:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000958 seconds.
2023-11-06 09:27:31,315:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:31,315:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:31,315:INFO:[LightGBM] [Info] Total Bins 2401
2023-11-06 09:27:31,316:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 11
2023-11-06 09:27:31,316:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:31,316:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:31,785:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:31,789:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000978 seconds.
2023-11-06 09:27:31,789:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:31,789:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:31,789:INFO:[LightGBM] [Info] Total Bins 2146
2023-11-06 09:27:31,789:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 10
2023-11-06 09:27:31,789:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:31,790:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:32,245:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:32,248:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001070 seconds.
2023-11-06 09:27:32,248:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:32,248:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:32,248:INFO:[LightGBM] [Info] Total Bins 2141
2023-11-06 09:27:32,249:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 9
2023-11-06 09:27:32,249:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:32,250:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:32,716:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:32,718:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002229 seconds.
2023-11-06 09:27:32,719:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:32,719:INFO:[LightGBM] [Info] Total Bins 1886
2023-11-06 09:27:32,719:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 8
2023-11-06 09:27:32,719:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:32,720:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:33,134:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:33,137:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001005 seconds.
2023-11-06 09:27:33,137:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:33,137:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:33,137:INFO:[LightGBM] [Info] Total Bins 1631
2023-11-06 09:27:33,137:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 7
2023-11-06 09:27:33,138:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:33,138:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:33,574:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:33,577:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002084 seconds.
2023-11-06 09:27:33,577:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:33,577:INFO:[LightGBM] [Info] Total Bins 1530
2023-11-06 09:27:33,577:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 6
2023-11-06 09:27:33,577:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:33,577:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:33,923:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:33,924:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001453 seconds.
2023-11-06 09:27:33,925:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:33,925:INFO:[LightGBM] [Info] Total Bins 1275
2023-11-06 09:27:33,925:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 5
2023-11-06 09:27:33,925:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:33,925:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:34,261:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:34,263:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000635 seconds.
2023-11-06 09:27:34,263:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:34,264:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:34,264:INFO:[LightGBM] [Info] Total Bins 1020
2023-11-06 09:27:34,264:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 4
2023-11-06 09:27:34,264:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:34,264:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:34,715:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:34,732:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004419 seconds.
2023-11-06 09:27:34,732:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:34,732:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:34,732:INFO:[LightGBM] [Info] Total Bins 2476
2023-11-06 09:27:34,732:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 20
2023-11-06 09:27:34,733:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:34,733:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:35,286:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:35,303:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004256 seconds.
2023-11-06 09:27:35,303:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:35,303:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:35,303:INFO:[LightGBM] [Info] Total Bins 2474
2023-11-06 09:27:35,303:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 19
2023-11-06 09:27:35,304:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:35,304:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:35,883:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:35,901:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003279 seconds.
2023-11-06 09:27:35,902:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:35,902:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:35,902:INFO:[LightGBM] [Info] Total Bins 2472
2023-11-06 09:27:35,902:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 18
2023-11-06 09:27:35,903:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:35,903:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:36,555:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:36,571:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012916 seconds.
2023-11-06 09:27:36,571:INFO:You can set `force_col_wise=true` to remove the overhead.
2023-11-06 09:27:36,572:INFO:[LightGBM] [Info] Total Bins 2470
2023-11-06 09:27:36,572:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 17
2023-11-06 09:27:36,572:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:36,572:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:37,122:INFO:[LightGBM] [Info] Number of positive: 26390, number of negative: 87967
2023-11-06 09:27:37,137:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002983 seconds.
2023-11-06 09:27:37,137:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-11-06 09:27:37,137:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-11-06 09:27:37,137:INFO:[LightGBM] [Info] Total Bins 2468
2023-11-06 09:27:37,137:INFO:[LightGBM] [Info] Number of data points in the train set: 114357, number of used features: 16
2023-11-06 09:27:37,138:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230769 -> initscore=-1.203977
2023-11-06 09:27:37,138:INFO:[LightGBM] [Info] Start training from score -1.203977
2023-11-06 09:27:41,125:INFO:Initializing interpret_model()
2023-11-06 09:27:41,125:INFO:interpret_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=feature_importance, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>)
2023-11-06 09:27:41,125:INFO:Checking exceptions
2023-11-06 09:27:41,126:INFO:Soft dependency imported: shap: 0.43.0
2023-11-06 09:27:44,219:INFO:plot type: summary
2023-11-06 09:27:44,219:INFO:Creating TreeExplainer
2023-11-06 09:27:44,352:INFO:Compiling shap values
2023-11-06 09:27:56,672:INFO:Visual Rendered Successfully
2023-11-06 09:27:56,673:INFO:interpret_model() successfully completed......................................
2023-11-06 09:27:56,831:INFO:Initializing plot_model()
2023-11-06 09:27:56,831:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, system=True)
2023-11-06 09:27:56,831:INFO:Checking exceptions
2023-11-06 09:27:56,852:INFO:Preloading libraries
2023-11-06 09:27:56,861:INFO:Copying training dataset
2023-11-06 09:27:56,861:INFO:Plot type: feature
2023-11-06 09:27:56,861:WARNING:No coef_ found. Trying feature_importances_
2023-11-06 09:27:57,145:INFO:Visual Rendered Successfully
2023-11-06 09:27:57,274:INFO:plot_model() successfully completed......................................
2023-11-06 09:27:57,286:INFO:Initializing evaluate_model()
2023-11-06 09:27:57,286:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-11-06 09:27:57,314:INFO:Initializing plot_model()
2023-11-06 09:27:57,315:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, system=True)
2023-11-06 09:27:57,315:INFO:Checking exceptions
2023-11-06 09:27:57,332:INFO:Preloading libraries
2023-11-06 09:27:57,338:INFO:Copying training dataset
2023-11-06 09:27:57,338:INFO:Plot type: pipeline
2023-11-06 09:27:57,436:INFO:Visual Rendered Successfully
2023-11-06 09:27:57,570:INFO:plot_model() successfully completed......................................
2023-11-06 09:27:59,945:INFO:Initializing plot_model()
2023-11-06 09:27:59,946:INFO:plot_model(plot=feature, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, system=True)
2023-11-06 09:27:59,946:INFO:Checking exceptions
2023-11-06 09:27:59,964:INFO:Preloading libraries
2023-11-06 09:27:59,971:INFO:Copying training dataset
2023-11-06 09:27:59,971:INFO:Plot type: feature
2023-11-06 09:27:59,971:WARNING:No coef_ found. Trying feature_importances_
2023-11-06 09:28:00,216:INFO:Visual Rendered Successfully
2023-11-06 09:28:00,340:INFO:plot_model() successfully completed......................................
2023-11-06 09:40:00,245:INFO:Initializing compare_models()
2023-11-06 09:40:00,245:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-11-06 09:40:00,245:INFO:Checking exceptions
2023-11-06 09:40:00,263:INFO:Preparing display monitor
2023-11-06 09:40:00,295:INFO:Initializing Logistic Regression
2023-11-06 09:40:00,297:INFO:Total runtime is 3.336270650227865e-05 minutes
2023-11-06 09:40:00,302:INFO:SubProcess create_model() called ==================================
2023-11-06 09:40:00,302:INFO:Initializing create_model()
2023-11-06 09:40:00,302:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000240836FC940>, model_only=True, return_train_score=False, kwargs={})
2023-11-06 09:40:00,303:INFO:Checking exceptions
2023-11-06 09:40:00,303:INFO:Importing libraries
2023-11-06 09:40:00,303:INFO:Copying training dataset
2023-11-06 09:40:00,365:INFO:Defining folds
2023-11-06 09:40:00,365:INFO:Declaring metric variables
2023-11-06 09:40:00,369:INFO:Importing untrained model
2023-11-06 09:40:00,373:INFO:Logistic Regression Imported successfully
2023-11-06 09:40:00,381:INFO:Starting cross validation
2023-11-06 09:40:00,382:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-11-06 09:40:08,326:INFO:Calculating mean and std
2023-11-06 09:40:08,327:INFO:Creating metrics dataframe
2023-11-06 09:40:08,330:INFO:Uploading results into container
2023-11-06 09:40:08,331:INFO:Uploading model into container now
2023-11-06 09:40:08,331:INFO:_master_model_container: 17
2023-11-06 09:40:08,331:INFO:_display_container: 5
2023-11-06 09:40:08,332:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-11-06 09:40:08,332:INFO:create_model() successfully completed......................................
2023-11-06 09:40:08,476:INFO:SubProcess create_model() end ==================================
2023-11-06 09:40:08,476:INFO:Creating metrics dataframe
2023-11-06 09:40:08,485:INFO:Initializing K Neighbors Classifier
2023-11-06 09:40:08,485:INFO:Total runtime is 0.13649933338165285 minutes
2023-11-06 09:40:08,489:INFO:SubProcess create_model() called ==================================
2023-11-06 09:40:08,489:INFO:Initializing create_model()
2023-11-06 09:40:08,489:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002402C692760>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000240836FC940>, model_only=True, return_train_score=False, kwargs={})
2023-11-06 09:40:08,489:INFO:Checking exceptions
2023-11-06 09:40:08,489:INFO:Importing libraries
2023-11-06 09:40:08,489:INFO:Copying training dataset
2023-11-06 09:40:08,535:INFO:Defining folds
2023-11-06 09:40:08,535:INFO:Declaring metric variables
2023-11-06 09:40:08,539:INFO:Importing untrained model
2023-11-06 09:40:08,543:INFO:K Neighbors Classifier Imported successfully
2023-11-06 09:40:08,550:INFO:Starting cross validation
2023-11-06 09:40:08,551:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
